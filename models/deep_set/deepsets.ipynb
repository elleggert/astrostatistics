{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First Attempt at building a deepsets architecture"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from set_dataloader import CCD\n",
    "import time\n",
    "\n",
    "# Import NN Packages\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a deepsets architecture\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing Dataset Utility to pass data in the right format\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Build a NN sampling an equal number of CCDs per 256 pixel and pass through deep sets for regression\n",
    "\n",
    "2. Adapt NN for variable sized inputs\n",
    "\n",
    "3. Adapt NN to use 64 inputs of size 2048 to then predict density at 256\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "' Todo\\n1. Where to get the data from\\n2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\\n3. Combine larger and smaller dataset\\n4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\\n'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class SetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number Pixels of that are returned\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=10, max_ccds=30, var_set_len=False):\n",
    "\n",
    "        with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "            self.pixel2ccd_dict = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        self.ccd = CCD()\n",
    "        self.num_features = self.ccd.num_features\n",
    "\n",
    "        # Dimensions\n",
    "        self.num_pixels = num_pixels\n",
    "        self.max_ccds = max_ccds\n",
    "        self.var_set_len = var_set_len\n",
    "\n",
    "        df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "        # Randomly Sampling Pixel Indices from Dataframe\n",
    "        pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "\n",
    "        self.df = df_raw.iloc[pixel_indices]\n",
    "        self.pix_ids = self.df.pixel_id.to_numpy()\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "        self.initialise_lengths()\n",
    "\n",
    "        # Target\n",
    "        self.label = np.random.rand(self.num_pixels * self.max_ccds)\n",
    "\n",
    "        # Mask Variable Len Sets\n",
    "        #self.set_max_set_len()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        self.target = self.df[gal_type].to_numpy()\n",
    "        #print(self.target.shape)\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        #print(self.target.shape)\n",
    "\n",
    "    def initialise_lengths(self):\n",
    "        self.lengths = np.zeros(self.num_pixels, dtype=int)\n",
    "        if self.var_set_len:\n",
    "            for i, pix in enumerate(self.pix_ids):\n",
    "                c = len(self.pixel2ccd_dict[pix])\n",
    "                if c < self.max_ccds:\n",
    "                    self.lengths[i] = c\n",
    "                else:\n",
    "                    self.lengths[i] = self.max_ccds\n",
    "\n",
    "        else:\n",
    "            self.lengths.fill(self.max_ccds)\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        #self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "        self.input = np.zeros((self.num_pixels, self.max_ccds, self.num_features))\n",
    "\n",
    "        # Iterate through the pixels\n",
    "        for i, pix in enumerate(self.pix_ids):\n",
    "            ids = self.pixel2ccd_dict[pix]\n",
    "            random.shuffle(ids)\n",
    "            #print(len(ids))\n",
    "            ids = ids[:self.max_ccds]\n",
    "            #print(len(ids))\n",
    "            #print()\n",
    "            x = self.ccd.get_ccds(ids)\n",
    "            # Iterate through the CCDs for every pixel\n",
    "            for j in range(len(ids)):\n",
    "                self.input[i, j] = x[j]\n",
    "\n",
    "    def set_max_set_len(self):\n",
    "        self.index_matrix = -1 * np.ones((self.num_pixels, self.max_ccds), dtype=int)\n",
    "\n",
    "        # Getting random labels for now, in the future this will be the output densities\n",
    "\n",
    "        m = 0\n",
    "        for i in range(self.num_pixels):\n",
    "\n",
    "            for j in range(self.lengths[i]):\n",
    "                ''' This code with label == 0 is not yet needed, but this masking will become necessary when I have\n",
    "                    I have 64 subpixels per pixel and some of those are not covered by CCDs'''\n",
    "                while self.label[m] == 0:\n",
    "                    m += 1\n",
    "                self.index_matrix[i, j] = m\n",
    "                m += 1\n",
    "\n",
    "        print(self.lengths)\n",
    "        print(self.index_matrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n",
    "\n",
    "\"\"\" Todo\n",
    "1. Where to get the data from\n",
    "2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\n",
    "3. Combine larger and smaller dataset\n",
    "4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "torch.Size([30, 9])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Actual Network Architecture\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class SetNet(nn.Module):\n",
    "    def __init__(self, n_features=5, n_output=3, reduction='sum'):\n",
    "        super(SetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "\n",
    "        y = self.adder(y, mask=mask)\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n",
      "9\n",
      "tensor([[0.5417]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l)\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 3])\n",
      "tensor([[-8.7350]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = SetNet()\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#Work out masking logic\n",
    "device = 'cpu'\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "l = l.to(device)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(l, x.shape[1])\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Hyperparameters and Training Loops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=1000, var_set_len=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  2942.1800325997174\n",
      "Loss for Epoch 10 :  3.680534098879434\n",
      "Loss for Epoch 20 :  2.884592419693945\n",
      "Loss for Epoch 30 :  2.765893154341029\n",
      "Loss for Epoch 40 :  2.5631455073598772\n",
      "Loss for Epoch 50 :  2.684168670588406\n",
      "Loss for Epoch 60 :  2.5554687872645445\n",
      "Loss for Epoch 70 :  2.4053838056570385\n",
      "Loss for Epoch 80 :  2.4015086796716787\n",
      "Loss for Epoch 90 :  2.399972525483463\n",
      "\n",
      "0.39641 minutes (23.8 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  27871.49012487009\n",
      "Loss for Epoch 10 :  8.458283477695659\n",
      "Loss for Epoch 20 :  4.994630630942993\n",
      "Loss for Epoch 30 :  4.833354047266766\n",
      "Loss for Epoch 40 :  4.84361100976821\n",
      "Loss for Epoch 50 :  4.83717059326591\n",
      "Loss for Epoch 60 :  4.820220751920715\n",
      "Loss for Epoch 70 :  4.846069120801985\n",
      "Loss for Epoch 80 :  4.8225392025779\n",
      "Loss for Epoch 90 :  4.808886545091809\n",
      "\n",
      "0.42237 minutes (25.3 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  14189.960423341021\n",
      "Loss for Epoch 10 :  13.390178092289716\n",
      "Loss for Epoch 20 :  11.792379513382912\n",
      "Loss for Epoch 30 :  12.168904803926125\n",
      "Loss for Epoch 40 :  12.2246720418334\n",
      "Loss for Epoch 50 :  10.915961837163195\n",
      "Loss for Epoch 60 :  10.814511087955907\n",
      "Loss for Epoch 70 :  10.813041705056094\n",
      "Loss for Epoch 80 :  10.80818999488838\n",
      "Loss for Epoch 90 :  10.80691729253158\n",
      "\n",
      "0.38134 minutes (22.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = SetNet(n_features=traindata.num_features, reduction='max').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X, mask=mask)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to Build a Network Capable of Processing 64 Subpixels Simultaneously"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Inputs Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccd = CCD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pixels = 2\n",
    "num_subpixels = 4\n",
    "max_ccds = 5\n",
    "num_features = 9\n",
    "#df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "# Randomly Sampling Pixel Indices from Dataframe\n",
    "#pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "pix_ids = [1, 2]\n",
    "pixel2subpixel_dict = {1: [11, 12, 13, 14], 2: [21, 22, 23, 24]}\n",
    "subpixel2ccd_dict = {11: [111, 112, 113, 114], 12: [121, 122, 123, 124, 125], 13: [131, 132, 133, 134, 135],\n",
    "                     14: [141, 142, 143, 144, 145],\n",
    "                     21: [211, 212, 213, 214, 215], 22: [221, 222], 23: [231, 232, 233, 234, 235],\n",
    "                     24: [241, 242, 243, 244, 245]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "# Iterate through the pixels\n",
    "print(\"Pixids\", pix_ids)\n",
    "for pix_no, pix in enumerate(pix_ids):\n",
    "\n",
    "    subpix_ids = pixel2subpixel_dict[pix]\n",
    "    subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "    for subpix_no, subpix in enumerate(subpix_ids):\n",
    "        if subpix not in subpixel2ccd_dict:\n",
    "            continue\n",
    "        subpix_ccds = subpixel2ccd_dict[subpix]\n",
    "        random.shuffle(subpix_ccds)\n",
    "        subpix_ccds = subpix_ccds[:max_ccds]\n",
    "        x = ccd.get_ccds(subpix_ccds)\n",
    "\n",
    "        # Iterate through the CCDs for every pixel\n",
    "        for ccd_no in range(len(subpix_ccds)):\n",
    "            input[pix_no, subpix_no, ccd_no] = x[ccd_no]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Lengths Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_set_len = True\n",
    "lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "print(lengths)\n",
    "if var_set_len:\n",
    "    for pix_no, pix in enumerate(pix_ids):\n",
    "        subpix_ids = pixel2subpixel_dict[pix]\n",
    "        subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "        for subpix_no, subpix in enumerate(subpix_ids):\n",
    "            if subpix not in subpixel2ccd_dict:\n",
    "                lengths[pix_no, subpix_no] = 0\n",
    "                continue\n",
    "            c = len(subpixel2ccd_dict[subpix])\n",
    "            if c < max_ccds:\n",
    "                lengths[pix_no, subpix_no] = c\n",
    "            else:\n",
    "                lengths[pix_no, subpix_no] = max_ccds\n",
    "\n",
    "else:\n",
    "    lengths.fill(max_ccds)\n",
    "\n",
    "print(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GetItem Function\n",
    "idx = 0\n",
    "x = torch.from_numpy(input[idx]).float()\n",
    "\n",
    "#l = torch.tensor(self.lengths[idx])\n",
    "l = lengths[idx]\n",
    "\n",
    "print(x.shape)\n",
    "print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class MultiSetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number SubPixels of that are returned --> usually 64\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=1000, num_subpixels=64, max_ccds=30, num_features=9):\n",
    "\n",
    "        with open('../../bricks_data/mini_multiset.pickle', 'rb') as f:\n",
    "            self.mini_multiset = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        # Initialise DataSet\n",
    "        self.num_pixels = num_pixels\n",
    "        self.num_features = num_features\n",
    "        self.input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "        self.lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "        self.lrg = np.zeros(num_pixels)\n",
    "        self.elg = np.zeros(num_pixels)\n",
    "        self.qso = np.zeros(num_pixels)\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        if gal_type == 'lrg':\n",
    "            self.target = self.lrg\n",
    "        if gal_type == 'elg':\n",
    "            self.target = self.elg\n",
    "        if gal_type == 'qso':\n",
    "            self.target = self.qso\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        for i, pix in enumerate(self.mini_multiset):\n",
    "            if i >= self.num_pixels:\n",
    "                break\n",
    "            self.input[i] = self.mini_multiset[pix][0]\n",
    "            self.lengths[i] = self.mini_multiset[pix][1]\n",
    "            self.lrg[i] = self.mini_multiset[pix][2]\n",
    "            self.elg[i] = self.mini_multiset[pix][3]\n",
    "            self.qso[i] = self.mini_multiset[pix][4]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=10)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "' TODO\\n1. Train Loop with Batching\\n2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\\n3. How to actually feed real data into the system to see if it can learn\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class MultiSetNet(nn.Module):\n",
    "    def __init__(self, n_features=9, n_output=3, n_subpix=64, reduction='sum'):\n",
    "        super(MultiSetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_subpix, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "        y = self.adder(y, mask=mask)\n",
    "\n",
    "        y = self.mlp(y.T)\n",
    "        return y\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "1. Train Loop with Batching\n",
    "2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\n",
    "3. How to actually feed real data into the system to see if it can learn\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "tensor([[0.]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "net = MultiSetNet()\n",
    "print(x.shape)\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  21.203732424415648\n",
      "Loss for Epoch 10 :  21.21518995705992\n",
      "Loss for Epoch 20 :  21.21518995705992\n",
      "Loss for Epoch 30 :  21.21518995705992\n",
      "Loss for Epoch 40 :  21.21518995705992\n",
      "Loss for Epoch 50 :  21.21518995705992\n",
      "Loss for Epoch 60 :  21.21518995705992\n",
      "Loss for Epoch 70 :  21.21518995705992\n",
      "Loss for Epoch 80 :  21.21518995705992\n",
      "Loss for Epoch 90 :  21.21518995705992\n",
      "\n",
      "0.19455 minutes (11.7 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  38.964210975915194\n",
      "Loss for Epoch 10 :  38.91034494712949\n",
      "Loss for Epoch 20 :  38.91034494712949\n",
      "Loss for Epoch 30 :  38.91034494712949\n",
      "Loss for Epoch 40 :  38.91034494712949\n",
      "Loss for Epoch 50 :  38.91034494712949\n",
      "Loss for Epoch 60 :  38.91034494712949\n",
      "Loss for Epoch 70 :  38.91034494712949\n",
      "Loss for Epoch 80 :  38.91034494712949\n",
      "Loss for Epoch 90 :  38.91034494712949\n",
      "\n",
      "0.23638 minutes (14.2 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  18.97755779325962\n",
      "Loss for Epoch 10 :  18.832214936614037\n",
      "Loss for Epoch 20 :  19.019644618034363\n",
      "Loss for Epoch 30 :  19.00366996228695\n",
      "Loss for Epoch 40 :  18.487545117735863\n",
      "Loss for Epoch 50 :  18.563062861561775\n",
      "Loss for Epoch 60 :  18.284362956881523\n",
      "Loss for Epoch 70 :  18.3128974288702\n",
      "Loss for Epoch 80 :  18.225802645087242\n",
      "Loss for Epoch 90 :  18.286328971385956\n",
      "\n",
      "0.24793 minutes (14.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = MultiSetNet(n_features=traindata.num_features, reduction='sum').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #print(X.shape)\n",
    "            #print(labels.shape)\n",
    "            #print(set_sizes)\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.squeeze().to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            #set_sizes = set_sizes.to(device)\n",
    "\n",
    "            #mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            # Not yet doing any masking\n",
    "            predictions = model(X)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training and Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import train, multi_train, MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Set-Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  10.053878550264926\n",
      "Loss for Epoch 10 :  10.053878550264926\n",
      "Loss for Epoch 20 :  10.053878550264926\n",
      "Loss for Epoch 30 :  10.053878550264926\n",
      "Loss for Epoch 40 :  10.053878550264926\n",
      "Loss for Epoch 50 :  10.053878550264926\n",
      "Loss for Epoch 60 :  10.053878550264926\n",
      "Loss for Epoch 70 :  10.053878550264926\n",
      "Loss for Epoch 80 :  10.053878550264926\n",
      "Loss for Epoch 90 :  10.053878550264926\n",
      "\n",
      "1.7579 minutes (1.05e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  11629.811594213443\n",
      "Loss for Epoch 10 :  42.34878332098149\n",
      "Loss for Epoch 20 :  42.36339263490362\n",
      "Loss for Epoch 30 :  42.325412895846654\n",
      "Loss for Epoch 40 :  42.393384256566165\n",
      "Loss for Epoch 50 :  42.373732197336295\n",
      "Loss for Epoch 60 :  42.40096284180902\n",
      "Loss for Epoch 70 :  42.24797562570515\n",
      "Loss for Epoch 80 :  42.28472199212819\n",
      "Loss for Epoch 90 :  42.39563592875416\n",
      "\n",
      "1.7813 minutes (1.07e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  214.11590725108545\n",
      "Loss for Epoch 10 :  176.07240221574466\n",
      "Loss for Epoch 20 :  176.07240221574466\n",
      "Loss for Epoch 30 :  176.07240221574466\n",
      "Loss for Epoch 40 :  176.07240221574466\n",
      "Loss for Epoch 50 :  176.07240221574466\n",
      "Loss for Epoch 60 :  176.07240221574466\n",
      "Loss for Epoch 70 :  176.07240221574466\n",
      "Loss for Epoch 80 :  176.07240221574466\n",
      "Loss for Epoch 90 :  176.07240221574466\n",
      "\n",
      "1.7694 minutes (1.06e+02 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_train(1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 670\n",
      "Test Samples: 330\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "torch.Size([1, 64])\n",
      "tensor([[28, 23, 21, 30, 30, 30, 30, 30, 30, 30, 27, 30, 27, 27, 23, 30, 30, 30,\n",
      "         30, 30, 30, 30, 28, 30, 30, 30, 27, 30, 24, 24, 24, 24, 24, 24, 23, 21,\n",
      "         28, 26, 28, 28, 28, 21, 27, 21, 21, 21, 21, 21, 20, 22, 24, 30, 30, 24,\n",
      "         24, 28, 30, 30, 19, 26, 26, 25, 28, 30]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgareggert/astrostatistics/models/deep_set/utilities.py:214: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # set_sizes = set_sizes.to(device)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultiSetNet R^2 for lrg :  -1.4573048083786349.\n",
      "MultiSetNet MSE for lrg :  0.013348963645229783.\n",
      "\n",
      "MultiSetNet R^2 for elg :  -2.142983122931937.\n",
      "MultiSetNet MSE for elg :  0.1886151816532751.\n",
      "\n",
      "MultiSetNet R^2 for qso :  -2.0842765440713604.\n",
      "MultiSetNet MSE for qso :  0.16178952133573077.\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 1: Working out Masking Logic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from datasets import SetSequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import init\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets(gal_type='lrg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "X, Y, set_sizes = traindata.__getitem__(3)\n",
    "X = X.unsqueeze(0).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 8]) torch.Size([1]) 14\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape, set_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14]]\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-109-ec108aa3ee66>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-106-afda90f0d0a5>\u001B[0m in \u001B[0;36mget_mask\u001B[0;34m(sizes, max_size)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.int64' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "set_sizes = torch.Tensor(set_sizes).to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class InvLinear(nn.Module):\n",
    "    r\"\"\"Permutation invariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(InvLinear, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        assert reduction in ['mean', 'sum', 'max',\n",
    "                             'min'], '\\'reduction\\' should be \\'mean\\'/\\'sum\\'\\'max\\'/\\'min\\', got {}'.format(reduction)\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.beta = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                              self.out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, self.out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.beta)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.beta)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to a vector y of dimension out_features,\n",
    "        through a permutation invariant linear transformation of the form:\n",
    "            $y = \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N vectors of dimension out_features (tensor with shape (N, out_features))\n",
    "        \"\"\"\n",
    "        print(\"INVLAYER:\", X.shape)\n",
    "        N, M, _ = X.shape\n",
    "        print(N, M)\n",
    "        device = X.device\n",
    "        y = torch.zeros(N, self.out_features).to(device)\n",
    "        print(y)\n",
    "        print(y.shape)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = (Z.sum(dim=1) @ self.beta) / sizes\n",
    "\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = Z.sum(dim=1) @ self.beta\n",
    "\n",
    "        elif self.reduction == 'max':\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('-Inf')\n",
    "            y = Z.max(dim=1)[0] @ self.beta\n",
    "\n",
    "        else:  # min\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('Inf')\n",
    "            y = Z.min(dim=1)[0] @ self.beta\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y += self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, reduction={}'.format(\n",
    "            self.in_features, self.out_features,\n",
    "            self.bias is not None, self.reduction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2822, -0.2697, -0.3711]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer = InvLinear(in_features=8, out_features=3, bias=True, reduction='sum')\n",
    "\n",
    "print(layer.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000e+00, -1.5846e+29,  5.0240e+15],\n",
      "        [-4.6577e-10,  1.2612e-44,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.7819, -0.0058,  0.0651],\n",
      "        [-0.0663,  0.6536,  0.0455],\n",
      "        [ 0.6011, -0.5926, -0.6082],\n",
      "        [-0.1283, -0.3870,  0.8119]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "beta = nn.Parameter(torch.Tensor(4, 3))\n",
    "print(beta)\n",
    "init.xavier_uniform_(beta)\n",
    "print(beta)\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(8, 7),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(7, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.ReLU(inplace=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3149, 0.1904, 0.0078, 0.6765, 0.7230, 0.0260, 1.0000, 0.0000],\n",
      "        [0.1332, 0.1242, 0.0032, 0.5936, 0.6804, 0.0285, 1.0000, 2.0000],\n",
      "        [0.2082, 0.1904, 0.0082, 0.6525, 0.6998, 0.0260, 1.0000, 1.0000],\n",
      "        [0.2082, 0.2318, 0.0055, 0.6495, 0.6985, 0.0132, 1.0000, 1.0000],\n",
      "        [0.0815, 0.1531, 0.0043, 0.6496, 0.7003, 0.0126, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2069, 0.0070, 0.6758, 0.7228, 0.0274, 1.0000, 0.0000],\n",
      "        [0.3066, 0.1531, 0.0049, 0.6741, 0.7200, 0.0285, 1.0000, 0.0000],\n",
      "        [0.1199, 0.2235, 0.0036, 0.6415, 0.7069, 0.0283, 1.0000, 1.0000],\n",
      "        [0.4116, 0.1366, 0.0037, 0.5766, 0.6879, 0.0132, 1.0000, 2.0000],\n",
      "        [0.1665, 0.1490, 0.0042, 0.5767, 0.6709, 0.0281, 1.0000, 2.0000],\n",
      "        [0.4166, 0.1324, 0.0034, 0.5763, 0.6901, 0.0260, 1.0000, 2.0000],\n",
      "        [0.0865, 0.1366, 0.0053, 0.6507, 0.7010, 0.0251, 1.0000, 1.0000],\n",
      "        [0.1349, 0.1945, 0.0066, 0.6565, 0.7018, 0.0277, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2442, 0.0073, 0.6760, 0.7222, 0.0130, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.4475],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4188],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4128],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4147],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4142],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4473],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4479],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4176],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3940],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4193],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3941],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4136],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4155],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4466],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 30, 8])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    X, Y, set_sizes = batch[0], batch[1], batch[2]\n",
    "    break\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(set_sizes.shape)\n",
    "X = feature_extractor(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 11,  9, 11])\n",
      "tensor([11, 11,  9, 11])\n",
      "4 30\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-80fa19fef633>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  set_sizes = torch.tensor(set_sizes).to(device)\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes)\n",
    "set_sizes = torch.tensor(set_sizes).to(device)\n",
    "print(set_sizes)\n",
    "\n",
    "N, M, _ = X.shape\n",
    "print(N, M)\n",
    "device = X.device\n",
    "y = torch.zeros(N, 3).to(device)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#mask = torch.ones(N, M).byte().to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.],\n",
      "        [11.],\n",
      "        [ 9.],\n",
      "        [11.]])\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5127, -1.7340,  3.6416],\n",
      "        [-0.6222, -1.8766,  3.9364],\n",
      "        [-0.4870, -1.4688,  3.0810],\n",
      "        [-0.4943, -1.7375,  3.6502]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "print(sizes)\n",
    "mask = mask.unsqueeze(2).float()\n",
    "print(mask)\n",
    "print(X)\n",
    "Z = X * mask\n",
    "print(Z)\n",
    "y = Z.sum(dim=1)\n",
    "y = y @ beta\n",
    "print(y)\n",
    "y = y / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean\n",
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "Z = X * mask.unsqueeze(2).float()\n",
    "y = (Z.sum(dim=1) @ beta) / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 8])\n",
      "1 30\n",
      "tensor([[0., 0., 0.]])\n",
      "torch.Size([1, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y = layer.forward(X, mask)\n",
    "print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 2: Feeding Info later in NN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([32169, 341149, 528957, 280814, 273264, 694339, 707785, 370864, 73820, 257147, 721234, 373321, 240093, 721951, 78638, 162768, 293734, 583417, 502424, 259217, 10623, 54349, 140162, 691718, 422984, 607965, 64748, 390644, 455119, 656903, 110288, 386137, 626358, 449543, 724966, 665073, 370725, 223104, 393908, 271923, 617217, 717626, 205244, 510540, 26423, 101953, 345996, 458802, 668096, 288869, 145651, 401565, 683130, 420478, 691727, 590342, 567243, 135094, 106663, 233370, 645883, 197779, 345088, 123271, 200933, 106986, 350064, 622307, 561085, 204348, 152787, 272232, 186553, 158774, 636409, 732350, 77773, 360436, 389582, 546558, 394931, 255055, 349046, 392780, 246970, 140344, 716785, 113094, 363394, 464307, 286108, 32732, 48624, 611997, 180815, 413295, 640679, 16138, 82614, 644876, 4038, 10968, 84809, 320927, 282221, 47979, 356212, 251708, 292991, 255227, 242503, 178668, 299456, 182238, 586368, 31363, 276897, 346143, 330597, 407139, 305569, 417370, 140455, 210007, 198626, 384385, 181416, 177054, 196818, 592457, 170016, 491636, 462534, 382966, 299901, 73788, 223363, 53306, 731552, 218627, 540401, 143640, 677466, 671816, 242155, 712431, 389739, 750169, 250082, 369025, 171101, 725424, 293366, 429052, 501666, 443873, 454089, 325585, 97719, 496233, 225492, 7899, 630500, 108465, 277408, 606869, 249806, 256000, 80647, 126949, 320416, 186828, 116430, 499385, 5414, 571080, 422526, 354439, 635416, 176732, 350573, 328668, 694443, 103022, 453516, 390743, 734266, 605830, 30173, 377243, 428168, 627257, 411255, 319518, 148288, 346089, 54969, 687625, 222670, 7503, 716272, 63455, 52027, 282810, 383009, 431102, 45797, 456750, 238491, 331223, 446082, 304098, 119115, 17387, 241767, 75352, 347343, 610006, 240787, 172854, 10652, 660145, 705313, 719883, 722792, 368739, 348226, 337480, 677348, 536492, 180318, 56367, 175914, 350035, 200873, 550509, 739449, 230506, 275375, 171216, 224060, 316637, 240775, 276700, 736917, 718496, 587485, 701354, 326100, 79247, 180011, 390250, 63501, 372862, 106813, 237615, 135012, 541348, 485946, 126233, 663180, 435185, 474683, 230323, 269270, 200897, 186227, 687437, 696163, 434845, 43934, 170990, 235336, 309636, 65721, 110465, 614955, 394379, 199214, 510649, 103149, 704336, 367714, 131089, 57785, 475011, 67132, 407548, 421500, 67747, 364920, 10431, 7703, 141309, 726297, 605734, 231912, 425937, 412092, 360589, 631391, 66835, 43143, 177735, 358812, 368485, 64698, 159967, 276972, 229975, 140536, 139053, 419714, 356762, 114453, 565992, 70126, 673631, 268544, 313193, 52504, 706876, 289273, 271198, 426583, 150761, 36390, 475705, 618145, 680089, 437292, 379246, 125113, 358837, 47943, 234647, 221304, 388569, 238799, 138241, 422572, 142233, 684776, 435332, 290983, 130191, 42623, 221689, 601708, 633459, 49900, 298590, 379019, 500310, 229812, 27290, 465546, 230907, 688424, 316850, 44891, 518891, 395462, 370133, 378967, 591517, 595691, 249874, 408085, 167039, 11323, 415350, 636348, 22910, 658797, 139159, 259493, 147495, 615127, 76183, 343030, 472492, 310485, 248954, 148422, 690980, 177019, 403640, 186464, 313418, 183350, 739853, 189318, 335970, 243116, 10916, 114131, 492045, 716299, 480875, 59001, 28877, 590536, 437757, 109331, 298911, 712304, 238137, 650896, 596617, 485854, 239022, 256514, 198502, 406363, 125963, 377916, 435617, 421395, 107914, 149467, 598744, 222818, 211471, 42175, 479652, 284125, 214016, 307825, 649709, 226458, 712372, 304598, 662989, 513608, 216936, 353828, 290676, 421784, 673837, 438977, 293464, 137132, 702104, 657939, 71408, 268731, 410595, 361883, 218303, 208489, 398936, 380964, 536287, 227154, 190623, 395350, 210416, 328618, 425859, 151504, 28221, 594490, 10347, 405507, 439709, 200608, 287160, 234084, 106966, 675466, 127020, 285173, 361889, 217623, 375876, 337333, 704335, 279064, 627195, 486053, 279484, 691025, 309373, 144248, 560733, 683122, 233046, 24239, 113335, 206431, 358234, 134968, 134410, 466608, 95916, 238444, 225833, 338898, 134939, 621300, 108854, 383856, 57227, 650897, 233021, 330258, 135111, 326582, 522922, 178286, 242123, 510530, 112210, 112174, 482783, 45730, 335046, 207030, 477819, 134442, 627378, 443474, 444358, 266450, 312250, 224097, 619191, 174910, 240736, 209783, 572143, 241502, 94116, 124799, 450957, 270908, 453016, 648689, 323037, 230445, 604694, 646805, 375877, 520891, 177041, 405384, 686440, 419869, 509580, 509609, 266125, 42558, 306150, 292885, 462211, 338069, 32332, 250119, 33364, 296529, 650916, 222462, 262201, 404964, 48056, 581242, 441866, 391803, 439935, 51139, 396954, 300664, 557712, 372621, 207733, 343929, 117933, 651667, 434622, 690063, 65508, 41977, 662930, 209075, 334016, 128196, 381049, 679481, 81426, 712364, 507519, 343593, 371674, 50767, 197700, 100186, 399400, 398783, 721354, 716188, 81475, 356955, 250763, 320926, 320435, 587455, 631380, 279151, 733518, 369660, 46864, 327830, 371711, 320897, 300593, 407961, 121244, 40867, 89155, 265350, 673567, 262632, 415114, 223491, 580543, 412734, 526021, 618122, 668930, 73781, 426541, 265278, 378303, 335284, 343262, 41987, 94973, 568914, 442996, 147348, 236458, 27860, 237095, 602718, 155457, 640540, 438632, 288995, 431793, 634417, 93386, 141457, 367585, 404177, 666145, 341401, 170185, 456057, 658957, 111192, 14541, 595683, 448144, 384715, 332165, 78417, 630450, 161799, 48864, 207316, 275611, 659026, 379826, 204969, 221665, 166925, 275890, 736149, 66196, 221296, 375930, 194727, 424543, 7410, 203216, 69864, 715432, 370894, 118857, 719995, 315832, 427660, 386714, 189548, 23310, 24612, 475018, 669078, 378243, 605819, 237778, 456120, 694465, 480653, 728217, 209759, 631304, 602637, 356764, 730421, 29402, 389987, 96040, 194419, 717800, 668097, 366645, 220085, 670008, 293028, 690017, 668718, 331994, 466634, 155635, 464280, 347240, 287318, 345997, 665110, 314486, 331200, 516714, 350623, 367822, 277682, 208843, 182070, 95186, 185926, 70878, 228517, 33371, 272859, 146613, 51381, 440279, 286534, 357408, 718310, 419510, 422281, 221202, 314936, 238500, 187507, 260689, 259530, 280595, 15189, 353200, 597762, 276366, 377939, 361090, 382996, 648737, 717031, 301902, 519721, 152564, 38785, 717606, 642683, 446833, 414380, 325085, 297517, 319312, 292362, 691962, 197166, 416378, 25673, 674639, 97616, 650845, 374240, 350259, 160934, 428472, 270752, 49242, 420357, 713149, 267440, 447463, 221348, 440793, 185374, 308435, 263585, 252871, 217701, 599605, 130105, 298062, 383191, 433726, 521932, 722162, 394690, 368063, 537299, 312851, 379910, 482683, 342073, 650986, 69331, 490941, 36472, 321068, 452728, 541356, 228961, 393855, 671640, 214039, 647744, 171180, 480916, 635457, 85540, 679369, 16555, 468540, 182806, 390689, 110304, 242189, 293041, 691974, 646768, 481902, 256153, 85019, 296798, 393763, 305357, 57706, 231890, 89039, 632325, 4988, 142184, 498135, 177343, 229838, 60676, 335833, 726180, 197048, 126881, 397937, 623122, 203004, 354497, 712499, 419461, 483941, 714017, 5624, 408647, 108359, 445511, 340951, 212998, 701117, 258902, 226515, 751313, 720575, 42740, 264739, 230585, 214906, 49177, 715545, 688305, 220615, 420288, 440981, 197206, 722747, 62516, 540229, 178123, 380329, 24693, 637569, 333683, 135202, 414750, 470618, 53977, 203193, 440814, 279066, 460354, 250468, 84060, 683034, 70093, 354160, 372668, 394735, 273578, 53346, 436300, 58595, 399977, 262680, 116432, 309431, 461492, 355747, 114464, 231986, 360553, 217519, 366455, 450212, 192350, 69268, 403977, 355450, 626438, 214881, 242901, 83147, 649976, 166110, 448123, 298934, 203890, 368502, 268478, 97878, 307245, 42531, 91838, 394667, 390665, 66152, 522860, 267292, 286558, 43925, 221698, 98380, 171502, 315531, 173013, 163977, 53683, 276363, 247766, 314581, 12424, 416895, 253533, 689969, 261567, 395967, 662082, 661142, 53244, 171079, 330264, 165061, 695208, 418659, 425027, 257988, 236654, 631410, 23741, 215482, 214069, 593659, 669751, 446564, 324436, 605949, 393288, 113269, 70921, 382391])\n"
     ]
    }
   ],
   "source": [
    "with open('../../bricks_data/mini_multiset.pickle', 'rb') as f:\n",
    "    mini_multiset = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_multiset[341149]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "   pixel_id  lrg  elg  qso  stellar       EBV   airmass      fwhm  ccdskysb_g  \\\n0      1673    1    8   22        4  0.150272  1.755791  4.054279   23.362753   \n1      1675   21   45   84       13  0.231753  1.752745  4.333361   23.412788   \n2      1676    1   10   14        4  0.233339  1.752675  4.432289   23.463202   \n3      1677   16   44   82        8  0.198980  1.743200  4.533583   23.463299   \n4      1678   22   45   94       14  0.178034  1.725647  4.229492   23.385620   \n\n   ccdskysb_r  ccdskysb_z  exptime_g   exptime_r   exptime_z  meansky_g  \\\n0   21.275543   18.728977      250.0  250.000000  178.104004   0.350981   \n1   21.349841   18.934986      215.0  240.000000  160.604004   0.324769   \n2   21.424571   19.099052      180.0  230.000000  171.106506   0.288073   \n3   21.424380   19.140076      180.0  230.000000  176.439677   0.291843   \n4   21.436897   19.110413      215.0  237.916667  213.606003   0.305991   \n\n   meansky_r  meansky_z  galdepth_g  galdepth_r  galdepth_z  \n0   7.418882   3.168162   23.455763   21.988368   22.284269  \n1   5.615912   2.599613   23.448900   22.083221   22.318394  \n2   3.914232   2.233619   23.412380   22.185323   22.341307  \n3   3.932022   2.134053   23.508274   22.167623   22.373904  \n4   4.657650   2.125587   23.555042   22.131536   22.489397  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel_id</th>\n      <th>lrg</th>\n      <th>elg</th>\n      <th>qso</th>\n      <th>stellar</th>\n      <th>EBV</th>\n      <th>airmass</th>\n      <th>fwhm</th>\n      <th>ccdskysb_g</th>\n      <th>ccdskysb_r</th>\n      <th>ccdskysb_z</th>\n      <th>exptime_g</th>\n      <th>exptime_r</th>\n      <th>exptime_z</th>\n      <th>meansky_g</th>\n      <th>meansky_r</th>\n      <th>meansky_z</th>\n      <th>galdepth_g</th>\n      <th>galdepth_r</th>\n      <th>galdepth_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1673</td>\n      <td>1</td>\n      <td>8</td>\n      <td>22</td>\n      <td>4</td>\n      <td>0.150272</td>\n      <td>1.755791</td>\n      <td>4.054279</td>\n      <td>23.362753</td>\n      <td>21.275543</td>\n      <td>18.728977</td>\n      <td>250.0</td>\n      <td>250.000000</td>\n      <td>178.104004</td>\n      <td>0.350981</td>\n      <td>7.418882</td>\n      <td>3.168162</td>\n      <td>23.455763</td>\n      <td>21.988368</td>\n      <td>22.284269</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1675</td>\n      <td>21</td>\n      <td>45</td>\n      <td>84</td>\n      <td>13</td>\n      <td>0.231753</td>\n      <td>1.752745</td>\n      <td>4.333361</td>\n      <td>23.412788</td>\n      <td>21.349841</td>\n      <td>18.934986</td>\n      <td>215.0</td>\n      <td>240.000000</td>\n      <td>160.604004</td>\n      <td>0.324769</td>\n      <td>5.615912</td>\n      <td>2.599613</td>\n      <td>23.448900</td>\n      <td>22.083221</td>\n      <td>22.318394</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1676</td>\n      <td>1</td>\n      <td>10</td>\n      <td>14</td>\n      <td>4</td>\n      <td>0.233339</td>\n      <td>1.752675</td>\n      <td>4.432289</td>\n      <td>23.463202</td>\n      <td>21.424571</td>\n      <td>19.099052</td>\n      <td>180.0</td>\n      <td>230.000000</td>\n      <td>171.106506</td>\n      <td>0.288073</td>\n      <td>3.914232</td>\n      <td>2.233619</td>\n      <td>23.412380</td>\n      <td>22.185323</td>\n      <td>22.341307</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1677</td>\n      <td>16</td>\n      <td>44</td>\n      <td>82</td>\n      <td>8</td>\n      <td>0.198980</td>\n      <td>1.743200</td>\n      <td>4.533583</td>\n      <td>23.463299</td>\n      <td>21.424380</td>\n      <td>19.140076</td>\n      <td>180.0</td>\n      <td>230.000000</td>\n      <td>176.439677</td>\n      <td>0.291843</td>\n      <td>3.932022</td>\n      <td>2.134053</td>\n      <td>23.508274</td>\n      <td>22.167623</td>\n      <td>22.373904</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1678</td>\n      <td>22</td>\n      <td>45</td>\n      <td>94</td>\n      <td>14</td>\n      <td>0.178034</td>\n      <td>1.725647</td>\n      <td>4.229492</td>\n      <td>23.385620</td>\n      <td>21.436897</td>\n      <td>19.110413</td>\n      <td>215.0</td>\n      <td>237.916667</td>\n      <td>213.606003</td>\n      <td>0.305991</td>\n      <td>4.657650</td>\n      <td>2.125587</td>\n      <td>23.555042</td>\n      <td>22.131536</td>\n      <td>22.489397</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "pixel_indices = list(mini_multiset.keys())\n",
    "print(type(pixel_indices))\n",
    "df_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": "      pixel_id  lrg  elg  qso  stellar       EBV   airmass      fwhm  \\\n543       4038    3    5   10        3  0.022033  1.666107  3.983178   \n824       4988   11   53   87       19  0.022631  1.663641  4.014785   \n981       5414   26  111  131       28  0.086758  1.608878  3.886834   \n1048      5624    8   34   30        3  0.079445  1.612462  3.745160   \n1624      7410   28   89  144       50  0.022340  1.579736  3.773217   \n\n      ccdskysb_g  ccdskysb_r  ccdskysb_z   exptime_g   exptime_r   exptime_z  \\\n543    23.153124   21.511690   19.021398  178.349991  220.279004  154.104675   \n824    23.330173   21.728458   18.899693  168.636749  239.066602  164.605499   \n981    23.339233   22.588595   18.705573  245.333333  159.204346  113.437663   \n1048   23.339503   22.554344   18.694237  245.333333  155.087667  193.354248   \n1624   23.560570   21.782827   18.753662  132.887339  192.038330  136.852997   \n\n      meansky_g  meansky_r  meansky_z  galdepth_g  galdepth_r  galdepth_z  \n543    0.430785   3.830448  36.929248   23.374599   22.211005   20.834969  \n824    0.351809   2.172054   2.673824   23.417444   22.606612   22.245291  \n981    0.364677   0.855940   3.263647   23.577209   22.891256   21.872681  \n1048   0.333853   0.880755   3.367463   23.589432   22.908417   22.235054  \n1624   0.283643   1.962406   3.032580   23.457815   22.636429   22.186062  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel_id</th>\n      <th>lrg</th>\n      <th>elg</th>\n      <th>qso</th>\n      <th>stellar</th>\n      <th>EBV</th>\n      <th>airmass</th>\n      <th>fwhm</th>\n      <th>ccdskysb_g</th>\n      <th>ccdskysb_r</th>\n      <th>ccdskysb_z</th>\n      <th>exptime_g</th>\n      <th>exptime_r</th>\n      <th>exptime_z</th>\n      <th>meansky_g</th>\n      <th>meansky_r</th>\n      <th>meansky_z</th>\n      <th>galdepth_g</th>\n      <th>galdepth_r</th>\n      <th>galdepth_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>543</th>\n      <td>4038</td>\n      <td>3</td>\n      <td>5</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0.022033</td>\n      <td>1.666107</td>\n      <td>3.983178</td>\n      <td>23.153124</td>\n      <td>21.511690</td>\n      <td>19.021398</td>\n      <td>178.349991</td>\n      <td>220.279004</td>\n      <td>154.104675</td>\n      <td>0.430785</td>\n      <td>3.830448</td>\n      <td>36.929248</td>\n      <td>23.374599</td>\n      <td>22.211005</td>\n      <td>20.834969</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>4988</td>\n      <td>11</td>\n      <td>53</td>\n      <td>87</td>\n      <td>19</td>\n      <td>0.022631</td>\n      <td>1.663641</td>\n      <td>4.014785</td>\n      <td>23.330173</td>\n      <td>21.728458</td>\n      <td>18.899693</td>\n      <td>168.636749</td>\n      <td>239.066602</td>\n      <td>164.605499</td>\n      <td>0.351809</td>\n      <td>2.172054</td>\n      <td>2.673824</td>\n      <td>23.417444</td>\n      <td>22.606612</td>\n      <td>22.245291</td>\n    </tr>\n    <tr>\n      <th>981</th>\n      <td>5414</td>\n      <td>26</td>\n      <td>111</td>\n      <td>131</td>\n      <td>28</td>\n      <td>0.086758</td>\n      <td>1.608878</td>\n      <td>3.886834</td>\n      <td>23.339233</td>\n      <td>22.588595</td>\n      <td>18.705573</td>\n      <td>245.333333</td>\n      <td>159.204346</td>\n      <td>113.437663</td>\n      <td>0.364677</td>\n      <td>0.855940</td>\n      <td>3.263647</td>\n      <td>23.577209</td>\n      <td>22.891256</td>\n      <td>21.872681</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>5624</td>\n      <td>8</td>\n      <td>34</td>\n      <td>30</td>\n      <td>3</td>\n      <td>0.079445</td>\n      <td>1.612462</td>\n      <td>3.745160</td>\n      <td>23.339503</td>\n      <td>22.554344</td>\n      <td>18.694237</td>\n      <td>245.333333</td>\n      <td>155.087667</td>\n      <td>193.354248</td>\n      <td>0.333853</td>\n      <td>0.880755</td>\n      <td>3.367463</td>\n      <td>23.589432</td>\n      <td>22.908417</td>\n      <td>22.235054</td>\n    </tr>\n    <tr>\n      <th>1624</th>\n      <td>7410</td>\n      <td>28</td>\n      <td>89</td>\n      <td>144</td>\n      <td>50</td>\n      <td>0.022340</td>\n      <td>1.579736</td>\n      <td>3.773217</td>\n      <td>23.560570</td>\n      <td>21.782827</td>\n      <td>18.753662</td>\n      <td>132.887339</td>\n      <td>192.038330</td>\n      <td>136.852997</td>\n      <td>0.283643</td>\n      <td>1.962406</td>\n      <td>3.032580</td>\n      <td>23.457815</td>\n      <td>22.636429</td>\n      <td>22.186062</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw[df_raw.pixel_id.isin(pixel_indices)]\n",
    "print(len(df))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "stellar = df.stellar.to_numpy()\n",
    "ebv = df.EBV.to_numpy()\n",
    "pixel_id = df.pixel_id.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5\n",
      "1000\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_multiset))\n",
    "print(len(mini_multiset[341149]))\n",
    "\n",
    "for i, pix in enumerate(pixel_id):\n",
    "    mini_multiset[pix].append(stellar[i])\n",
    "    mini_multiset[pix].append(ebv[i])\n",
    "\n",
    "print(len(mini_multiset))\n",
    "print(len(mini_multiset[341149]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "with open(f'../../bricks_data/mini_multiset.pickle', 'wb') as f:\n",
    "    pickle.dump(mini_multiset, f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 3: MultiBatching in Multisets\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 4: Clean-Up everything and Deploy remotely\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}