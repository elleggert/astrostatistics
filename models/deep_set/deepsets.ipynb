{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First Attempt at building a deepsets architecture"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy import NaN\n",
    "\n",
    "from set_dataloader import CCD\n",
    "import time\n",
    "\n",
    "# Import NN Packages\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a deepsets architecture\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing Dataset Utility to pass data in the right format\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Build a NN sampling an equal number of CCDs per 256 pixel and pass through deep sets for regression\n",
    "\n",
    "2. Adapt NN for variable sized inputs\n",
    "\n",
    "3. Adapt NN to use 64 inputs of size 2048 to then predict density at 256\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "' Todo\\n1. Where to get the data from\\n2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\\n3. Combine larger and smaller dataset\\n4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\\n'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class SetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number Pixels of that are returned\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=10, max_ccds=30, var_set_len=False):\n",
    "\n",
    "        with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "            self.pixel2ccd_dict = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        self.ccd = CCD()\n",
    "        self.num_features = self.ccd.num_features\n",
    "\n",
    "        # Dimensions\n",
    "        self.num_pixels = num_pixels\n",
    "        self.max_ccds = max_ccds\n",
    "        self.var_set_len = var_set_len\n",
    "\n",
    "        df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "        # Randomly Sampling Pixel Indices from Dataframe\n",
    "        pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "\n",
    "        self.df = df_raw.iloc[pixel_indices]\n",
    "        self.pix_ids = self.df.pixel_id.to_numpy()\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "        self.initialise_lengths()\n",
    "\n",
    "        # Target\n",
    "        self.label = np.random.rand(self.num_pixels * self.max_ccds)\n",
    "\n",
    "        # Mask Variable Len Sets\n",
    "        #self.set_max_set_len()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        self.target = self.df[gal_type].to_numpy()\n",
    "        #print(self.target.shape)\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        #print(self.target.shape)\n",
    "\n",
    "    def initialise_lengths(self):\n",
    "        self.lengths = np.zeros(self.num_pixels, dtype=int)\n",
    "        if self.var_set_len:\n",
    "            for i, pix in enumerate(self.pix_ids):\n",
    "                c = len(self.pixel2ccd_dict[pix])\n",
    "                if c < self.max_ccds:\n",
    "                    self.lengths[i] = c\n",
    "                else:\n",
    "                    self.lengths[i] = self.max_ccds\n",
    "\n",
    "        else:\n",
    "            self.lengths.fill(self.max_ccds)\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        #self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "        self.input = np.zeros((self.num_pixels, self.max_ccds, self.num_features))\n",
    "\n",
    "        # Iterate through the pixels\n",
    "        for i, pix in enumerate(self.pix_ids):\n",
    "            ids = self.pixel2ccd_dict[pix]\n",
    "            random.shuffle(ids)\n",
    "            #print(len(ids))\n",
    "            ids = ids[:self.max_ccds]\n",
    "            #print(len(ids))\n",
    "            #print()\n",
    "            x = self.ccd.get_ccds(ids)\n",
    "            # Iterate through the CCDs for every pixel\n",
    "            for j in range(len(ids)):\n",
    "                self.input[i, j] = x[j]\n",
    "\n",
    "    def set_max_set_len(self):\n",
    "        self.index_matrix = -1 * np.ones((self.num_pixels, self.max_ccds), dtype=int)\n",
    "\n",
    "        # Getting random labels for now, in the future this will be the output densities\n",
    "\n",
    "        m = 0\n",
    "        for i in range(self.num_pixels):\n",
    "\n",
    "            for j in range(self.lengths[i]):\n",
    "                ''' This code with label == 0 is not yet needed, but this masking will become necessary when I have\n",
    "                    I have 64 subpixels per pixel and some of those are not covered by CCDs'''\n",
    "                while self.label[m] == 0:\n",
    "                    m += 1\n",
    "                self.index_matrix[i, j] = m\n",
    "                m += 1\n",
    "\n",
    "        print(self.lengths)\n",
    "        print(self.index_matrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n",
    "\n",
    "\"\"\" Todo\n",
    "1. Where to get the data from\n",
    "2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\n",
    "3. Combine larger and smaller dataset\n",
    "4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "torch.Size([30, 9])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Actual Network Architecture\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class SetNet(nn.Module):\n",
    "    def __init__(self, n_features=5, n_output=3, reduction='sum'):\n",
    "        super(SetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "\n",
    "        y = self.adder(y, mask=mask)\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n",
      "9\n",
      "tensor([[0.5417]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l)\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 3])\n",
      "tensor([[-8.7350]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = SetNet()\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#Work out masking logic\n",
    "device = 'cpu'\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "l = l.to(device)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(l, x.shape[1])\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Hyperparameters and Training Loops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=1000, var_set_len=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  2942.1800325997174\n",
      "Loss for Epoch 10 :  3.680534098879434\n",
      "Loss for Epoch 20 :  2.884592419693945\n",
      "Loss for Epoch 30 :  2.765893154341029\n",
      "Loss for Epoch 40 :  2.5631455073598772\n",
      "Loss for Epoch 50 :  2.684168670588406\n",
      "Loss for Epoch 60 :  2.5554687872645445\n",
      "Loss for Epoch 70 :  2.4053838056570385\n",
      "Loss for Epoch 80 :  2.4015086796716787\n",
      "Loss for Epoch 90 :  2.399972525483463\n",
      "\n",
      "0.39641 minutes (23.8 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  27871.49012487009\n",
      "Loss for Epoch 10 :  8.458283477695659\n",
      "Loss for Epoch 20 :  4.994630630942993\n",
      "Loss for Epoch 30 :  4.833354047266766\n",
      "Loss for Epoch 40 :  4.84361100976821\n",
      "Loss for Epoch 50 :  4.83717059326591\n",
      "Loss for Epoch 60 :  4.820220751920715\n",
      "Loss for Epoch 70 :  4.846069120801985\n",
      "Loss for Epoch 80 :  4.8225392025779\n",
      "Loss for Epoch 90 :  4.808886545091809\n",
      "\n",
      "0.42237 minutes (25.3 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  14189.960423341021\n",
      "Loss for Epoch 10 :  13.390178092289716\n",
      "Loss for Epoch 20 :  11.792379513382912\n",
      "Loss for Epoch 30 :  12.168904803926125\n",
      "Loss for Epoch 40 :  12.2246720418334\n",
      "Loss for Epoch 50 :  10.915961837163195\n",
      "Loss for Epoch 60 :  10.814511087955907\n",
      "Loss for Epoch 70 :  10.813041705056094\n",
      "Loss for Epoch 80 :  10.80818999488838\n",
      "Loss for Epoch 90 :  10.80691729253158\n",
      "\n",
      "0.38134 minutes (22.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = SetNet(n_features=traindata.num_features, reduction='max').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X, mask=mask)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to Build a Network Capable of Processing 64 Subpixels Simultaneously"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Inputs Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccd = CCD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pixels = 2\n",
    "num_subpixels = 4\n",
    "max_ccds = 5\n",
    "num_features = 9\n",
    "#df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "# Randomly Sampling Pixel Indices from Dataframe\n",
    "#pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "pix_ids = [1, 2]\n",
    "pixel2subpixel_dict = {1: [11, 12, 13, 14], 2: [21, 22, 23, 24]}\n",
    "subpixel2ccd_dict = {11: [111, 112, 113, 114], 12: [121, 122, 123, 124, 125], 13: [131, 132, 133, 134, 135],\n",
    "                     14: [141, 142, 143, 144, 145],\n",
    "                     21: [211, 212, 213, 214, 215], 22: [221, 222], 23: [231, 232, 233, 234, 235],\n",
    "                     24: [241, 242, 243, 244, 245]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "# Iterate through the pixels\n",
    "print(\"Pixids\", pix_ids)\n",
    "for pix_no, pix in enumerate(pix_ids):\n",
    "\n",
    "    subpix_ids = pixel2subpixel_dict[pix]\n",
    "    subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "    for subpix_no, subpix in enumerate(subpix_ids):\n",
    "        if subpix not in subpixel2ccd_dict:\n",
    "            continue\n",
    "        subpix_ccds = subpixel2ccd_dict[subpix]\n",
    "        random.shuffle(subpix_ccds)\n",
    "        subpix_ccds = subpix_ccds[:max_ccds]\n",
    "        x = ccd.get_ccds(subpix_ccds)\n",
    "\n",
    "        # Iterate through the CCDs for every pixel\n",
    "        for ccd_no in range(len(subpix_ccds)):\n",
    "            input[pix_no, subpix_no, ccd_no] = x[ccd_no]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Lengths Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_set_len = True\n",
    "lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "print(lengths)\n",
    "if var_set_len:\n",
    "    for pix_no, pix in enumerate(pix_ids):\n",
    "        subpix_ids = pixel2subpixel_dict[pix]\n",
    "        subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "        for subpix_no, subpix in enumerate(subpix_ids):\n",
    "            if subpix not in subpixel2ccd_dict:\n",
    "                lengths[pix_no, subpix_no] = 0\n",
    "                continue\n",
    "            c = len(subpixel2ccd_dict[subpix])\n",
    "            if c < max_ccds:\n",
    "                lengths[pix_no, subpix_no] = c\n",
    "            else:\n",
    "                lengths[pix_no, subpix_no] = max_ccds\n",
    "\n",
    "else:\n",
    "    lengths.fill(max_ccds)\n",
    "\n",
    "print(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GetItem Function\n",
    "idx = 0\n",
    "x = torch.from_numpy(input[idx]).float()\n",
    "\n",
    "#l = torch.tensor(self.lengths[idx])\n",
    "l = lengths[idx]\n",
    "\n",
    "print(x.shape)\n",
    "print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class MultiSetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number SubPixels of that are returned --> usually 64\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=1000, num_subpixels=64, max_ccds=30, num_features=9):\n",
    "\n",
    "        with open('../../bricks_data/mini_multiset.pickle', 'rb') as f:\n",
    "            self.mini_multiset = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        # Initialise DataSet\n",
    "        self.num_pixels = num_pixels\n",
    "        self.num_features = num_features\n",
    "        self.input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "        self.lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "        self.lrg = np.zeros(num_pixels)\n",
    "        self.elg = np.zeros(num_pixels)\n",
    "        self.qso = np.zeros(num_pixels)\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        if gal_type == 'lrg':\n",
    "            self.target = self.lrg\n",
    "        if gal_type == 'elg':\n",
    "            self.target = self.elg\n",
    "        if gal_type == 'qso':\n",
    "            self.target = self.qso\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        for i, pix in enumerate(self.mini_multiset):\n",
    "            if i >= self.num_pixels:\n",
    "                break\n",
    "            self.input[i] = self.mini_multiset[pix][0]\n",
    "            self.lengths[i] = self.mini_multiset[pix][1]\n",
    "            self.lrg[i] = self.mini_multiset[pix][2]\n",
    "            self.elg[i] = self.mini_multiset[pix][3]\n",
    "            self.qso[i] = self.mini_multiset[pix][4]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=10)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "' TODO\\n1. Train Loop with Batching\\n2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\\n3. How to actually feed real data into the system to see if it can learn\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class MultiSetNet(nn.Module):\n",
    "    def __init__(self, n_features=9, n_output=3, n_subpix=64, reduction='sum'):\n",
    "        super(MultiSetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_subpix, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "        y = self.adder(y, mask=mask)\n",
    "\n",
    "        y = self.mlp(y.T)\n",
    "        return y\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "1. Train Loop with Batching\n",
    "2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\n",
    "3. How to actually feed real data into the system to see if it can learn\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "tensor([[0.]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "net = MultiSetNet()\n",
    "print(x.shape)\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  21.203732424415648\n",
      "Loss for Epoch 10 :  21.21518995705992\n",
      "Loss for Epoch 20 :  21.21518995705992\n",
      "Loss for Epoch 30 :  21.21518995705992\n",
      "Loss for Epoch 40 :  21.21518995705992\n",
      "Loss for Epoch 50 :  21.21518995705992\n",
      "Loss for Epoch 60 :  21.21518995705992\n",
      "Loss for Epoch 70 :  21.21518995705992\n",
      "Loss for Epoch 80 :  21.21518995705992\n",
      "Loss for Epoch 90 :  21.21518995705992\n",
      "\n",
      "0.19455 minutes (11.7 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  38.964210975915194\n",
      "Loss for Epoch 10 :  38.91034494712949\n",
      "Loss for Epoch 20 :  38.91034494712949\n",
      "Loss for Epoch 30 :  38.91034494712949\n",
      "Loss for Epoch 40 :  38.91034494712949\n",
      "Loss for Epoch 50 :  38.91034494712949\n",
      "Loss for Epoch 60 :  38.91034494712949\n",
      "Loss for Epoch 70 :  38.91034494712949\n",
      "Loss for Epoch 80 :  38.91034494712949\n",
      "Loss for Epoch 90 :  38.91034494712949\n",
      "\n",
      "0.23638 minutes (14.2 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  18.97755779325962\n",
      "Loss for Epoch 10 :  18.832214936614037\n",
      "Loss for Epoch 20 :  19.019644618034363\n",
      "Loss for Epoch 30 :  19.00366996228695\n",
      "Loss for Epoch 40 :  18.487545117735863\n",
      "Loss for Epoch 50 :  18.563062861561775\n",
      "Loss for Epoch 60 :  18.284362956881523\n",
      "Loss for Epoch 70 :  18.3128974288702\n",
      "Loss for Epoch 80 :  18.225802645087242\n",
      "Loss for Epoch 90 :  18.286328971385956\n",
      "\n",
      "0.24793 minutes (14.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = MultiSetNet(n_features=traindata.num_features, reduction='sum').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #print(X.shape)\n",
    "            #print(labels.shape)\n",
    "            #print(set_sizes)\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.squeeze().to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            #set_sizes = set_sizes.to(device)\n",
    "\n",
    "            #mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            # Not yet doing any masking\n",
    "            predictions = model(X)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training and Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import train, multi_train, MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Set-Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  10.053878550264926\n",
      "Loss for Epoch 10 :  10.053878550264926\n",
      "Loss for Epoch 20 :  10.053878550264926\n",
      "Loss for Epoch 30 :  10.053878550264926\n",
      "Loss for Epoch 40 :  10.053878550264926\n",
      "Loss for Epoch 50 :  10.053878550264926\n",
      "Loss for Epoch 60 :  10.053878550264926\n",
      "Loss for Epoch 70 :  10.053878550264926\n",
      "Loss for Epoch 80 :  10.053878550264926\n",
      "Loss for Epoch 90 :  10.053878550264926\n",
      "\n",
      "1.7579 minutes (1.05e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  11629.811594213443\n",
      "Loss for Epoch 10 :  42.34878332098149\n",
      "Loss for Epoch 20 :  42.36339263490362\n",
      "Loss for Epoch 30 :  42.325412895846654\n",
      "Loss for Epoch 40 :  42.393384256566165\n",
      "Loss for Epoch 50 :  42.373732197336295\n",
      "Loss for Epoch 60 :  42.40096284180902\n",
      "Loss for Epoch 70 :  42.24797562570515\n",
      "Loss for Epoch 80 :  42.28472199212819\n",
      "Loss for Epoch 90 :  42.39563592875416\n",
      "\n",
      "1.7813 minutes (1.07e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  214.11590725108545\n",
      "Loss for Epoch 10 :  176.07240221574466\n",
      "Loss for Epoch 20 :  176.07240221574466\n",
      "Loss for Epoch 30 :  176.07240221574466\n",
      "Loss for Epoch 40 :  176.07240221574466\n",
      "Loss for Epoch 50 :  176.07240221574466\n",
      "Loss for Epoch 60 :  176.07240221574466\n",
      "Loss for Epoch 70 :  176.07240221574466\n",
      "Loss for Epoch 80 :  176.07240221574466\n",
      "Loss for Epoch 90 :  176.07240221574466\n",
      "\n",
      "1.7694 minutes (1.06e+02 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_train(1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 670\n",
      "Test Samples: 330\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "torch.Size([1, 64])\n",
      "tensor([[28, 23, 21, 30, 30, 30, 30, 30, 30, 30, 27, 30, 27, 27, 23, 30, 30, 30,\n",
      "         30, 30, 30, 30, 28, 30, 30, 30, 27, 30, 24, 24, 24, 24, 24, 24, 23, 21,\n",
      "         28, 26, 28, 28, 28, 21, 27, 21, 21, 21, 21, 21, 20, 22, 24, 30, 30, 24,\n",
      "         24, 28, 30, 30, 19, 26, 26, 25, 28, 30]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgareggert/astrostatistics/models/deep_set/utilities.py:214: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # set_sizes = set_sizes.to(device)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultiSetNet R^2 for lrg :  -1.4573048083786349.\n",
      "MultiSetNet MSE for lrg :  0.013348963645229783.\n",
      "\n",
      "MultiSetNet R^2 for elg :  -2.142983122931937.\n",
      "MultiSetNet MSE for elg :  0.1886151816532751.\n",
      "\n",
      "MultiSetNet R^2 for qso :  -2.0842765440713604.\n",
      "MultiSetNet MSE for qso :  0.16178952133573077.\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 1: Working out Masking Logic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from datasets import SetSequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import init\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets(gal_type='lrg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "X, Y, set_sizes = traindata.__getitem__(3)\n",
    "X = X.unsqueeze(0).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 8]) torch.Size([1]) 14\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape, set_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14]]\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-109-ec108aa3ee66>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-106-afda90f0d0a5>\u001B[0m in \u001B[0;36mget_mask\u001B[0;34m(sizes, max_size)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.int64' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "set_sizes = torch.Tensor(set_sizes).to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class InvLinear(nn.Module):\n",
    "    r\"\"\"Permutation invariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(InvLinear, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        assert reduction in ['mean', 'sum', 'max',\n",
    "                             'min'], '\\'reduction\\' should be \\'mean\\'/\\'sum\\'\\'max\\'/\\'min\\', got {}'.format(reduction)\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.beta = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                              self.out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, self.out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.beta)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.beta)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to a vector y of dimension out_features,\n",
    "        through a permutation invariant linear transformation of the form:\n",
    "            $y = \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N vectors of dimension out_features (tensor with shape (N, out_features))\n",
    "        \"\"\"\n",
    "        print(\"INVLAYER:\", X.shape)\n",
    "        N, M, _ = X.shape\n",
    "        print(N, M)\n",
    "        device = X.device\n",
    "        y = torch.zeros(N, self.out_features).to(device)\n",
    "        print(y)\n",
    "        print(y.shape)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = (Z.sum(dim=1) @ self.beta) / sizes\n",
    "\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = Z.sum(dim=1) @ self.beta\n",
    "\n",
    "        elif self.reduction == 'max':\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('-Inf')\n",
    "            y = Z.max(dim=1)[0] @ self.beta\n",
    "\n",
    "        else:  # min\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('Inf')\n",
    "            y = Z.min(dim=1)[0] @ self.beta\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y += self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, reduction={}'.format(\n",
    "            self.in_features, self.out_features,\n",
    "            self.bias is not None, self.reduction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2822, -0.2697, -0.3711]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer = InvLinear(in_features=8, out_features=3, bias=True, reduction='sum')\n",
    "\n",
    "print(layer.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000e+00, -1.5846e+29,  5.0240e+15],\n",
      "        [-4.6577e-10,  1.2612e-44,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.7819, -0.0058,  0.0651],\n",
      "        [-0.0663,  0.6536,  0.0455],\n",
      "        [ 0.6011, -0.5926, -0.6082],\n",
      "        [-0.1283, -0.3870,  0.8119]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "beta = nn.Parameter(torch.Tensor(4, 3))\n",
    "print(beta)\n",
    "init.xavier_uniform_(beta)\n",
    "print(beta)\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(8, 7),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(7, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.ReLU(inplace=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3149, 0.1904, 0.0078, 0.6765, 0.7230, 0.0260, 1.0000, 0.0000],\n",
      "        [0.1332, 0.1242, 0.0032, 0.5936, 0.6804, 0.0285, 1.0000, 2.0000],\n",
      "        [0.2082, 0.1904, 0.0082, 0.6525, 0.6998, 0.0260, 1.0000, 1.0000],\n",
      "        [0.2082, 0.2318, 0.0055, 0.6495, 0.6985, 0.0132, 1.0000, 1.0000],\n",
      "        [0.0815, 0.1531, 0.0043, 0.6496, 0.7003, 0.0126, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2069, 0.0070, 0.6758, 0.7228, 0.0274, 1.0000, 0.0000],\n",
      "        [0.3066, 0.1531, 0.0049, 0.6741, 0.7200, 0.0285, 1.0000, 0.0000],\n",
      "        [0.1199, 0.2235, 0.0036, 0.6415, 0.7069, 0.0283, 1.0000, 1.0000],\n",
      "        [0.4116, 0.1366, 0.0037, 0.5766, 0.6879, 0.0132, 1.0000, 2.0000],\n",
      "        [0.1665, 0.1490, 0.0042, 0.5767, 0.6709, 0.0281, 1.0000, 2.0000],\n",
      "        [0.4166, 0.1324, 0.0034, 0.5763, 0.6901, 0.0260, 1.0000, 2.0000],\n",
      "        [0.0865, 0.1366, 0.0053, 0.6507, 0.7010, 0.0251, 1.0000, 1.0000],\n",
      "        [0.1349, 0.1945, 0.0066, 0.6565, 0.7018, 0.0277, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2442, 0.0073, 0.6760, 0.7222, 0.0130, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.4475],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4188],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4128],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4147],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4142],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4473],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4479],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4176],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3940],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4193],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3941],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4136],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4155],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4466],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 30, 8])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    X, Y, set_sizes = batch[0], batch[1], batch[2]\n",
    "    break\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(set_sizes.shape)\n",
    "X = feature_extractor(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 11,  9, 11])\n",
      "tensor([11, 11,  9, 11])\n",
      "4 30\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-80fa19fef633>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  set_sizes = torch.tensor(set_sizes).to(device)\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes)\n",
    "set_sizes = torch.tensor(set_sizes).to(device)\n",
    "print(set_sizes)\n",
    "\n",
    "N, M, _ = X.shape\n",
    "print(N, M)\n",
    "device = X.device\n",
    "y = torch.zeros(N, 3).to(device)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#mask = torch.ones(N, M).byte().to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.],\n",
      "        [11.],\n",
      "        [ 9.],\n",
      "        [11.]])\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5127, -1.7340,  3.6416],\n",
      "        [-0.6222, -1.8766,  3.9364],\n",
      "        [-0.4870, -1.4688,  3.0810],\n",
      "        [-0.4943, -1.7375,  3.6502]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "print(sizes)\n",
    "mask = mask.unsqueeze(2).float()\n",
    "print(mask)\n",
    "print(X)\n",
    "Z = X * mask\n",
    "print(Z)\n",
    "y = Z.sum(dim=1)\n",
    "y = y @ beta\n",
    "print(y)\n",
    "y = y / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean\n",
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "Z = X * mask.unsqueeze(2).float()\n",
    "y = (Z.sum(dim=1) @ beta) / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 8])\n",
      "1 30\n",
      "tensor([[0., 0., 0.]])\n",
      "torch.Size([1, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y = layer.forward(X, mask)\n",
    "print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 2: Feeding Info later in NN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "from datasets import MultiSetSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence()\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    print(len(batch))\n",
    "    X1, X2, Y, L = batch[0], batch[1], batch[2], batch[3]\n",
    "    break\n",
    "X = X1.squeeze()\n",
    "\n",
    "X2 = X2.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(L, X.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['models'])\n",
    "from models import MultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "X1,X2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([66, 1])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.3807]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "X1,X2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([66, 1])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.3487]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model = MultiSetNet()\n",
    "\n",
    "print(X.shape)\n",
    "X1 = model.feature_extractor(X)\n",
    "print(X1.shape)\n",
    "X1 = model.adder(X1, mask=mask)\n",
    "print(\"X1,X2\")\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "X1 = torch.cat((X1, X2), dim=0)\n",
    "print(X1.shape)\n",
    "X1 = model.mlp(X1.T)\n",
    "print(X1.shape)\n",
    "print(X1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3487]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "y = model.forward(X, X2, mask=mask)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training a model with new Multisets architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'deepset_layers' from '/Users/edgareggert/astrostatistics/models/deep_set/deepset_layers.py'>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "importlib.reload(sys.modules['models'])\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "importlib.reload(sys.modules['deepset_layers'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "from trainer import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 670\n",
      "Test Samples: 330\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-39-9b24b891e092>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/utilities.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mgal\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgalaxy_types\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m             \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMultiSetNet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_features\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraindata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Model {gal} params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/models.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, n_features, n_output, n_subpix, reduction)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         )\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInvLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         self.mlp = nn.Sequential(\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/deepset_layers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, in_features, out_features, bias, reduction)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0min_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mInvLinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0min_features\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-1887f338d018>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/utilities.py\u001B[0m in \u001B[0;36mtest\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgal\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgalaxy_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    263\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m             \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "trainer.test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "trainer.count_parameters()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 3: MultiBatching in Multisets\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 4: Clean-Up everything and Deploy remotely\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin by Increasing Number of Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['set_dataloader'])\n",
    "\n",
    "from set_dataloader import CCD\n",
    "\n",
    "ccd = CCD()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544600\n",
      "0 5231831\n",
      "16384 593758\n",
      "16400 2\n",
      "16416 94\n",
      "16448 2660\n",
      "16480 44\n",
      "16496 11\n",
      "16512 10\n",
      "16544 16\n",
      "16896 26\n",
      "16928 1\n",
      "16992 1\n",
      "18432 232\n",
      "18464 2\n",
      "18496 2\n",
      "18528 6\n",
      "18544 1\n",
      "18560 1\n",
      "18944 23\n",
      "18976 11\n",
      "19040 45\n",
      "20480 206\n",
      "20512 9\n",
      "22528 5\n",
      "23040 1\n",
      "49152 11637\n",
      "49160 1894\n",
      "49184 48\n",
      "49192 13\n",
      "49216 216804\n",
      "49224 196\n",
      "49232 4896\n",
      "49248 1632\n",
      "49256 2\n",
      "49264 2029\n",
      "49280 80\n",
      "49288 60\n",
      "49312 1\n",
      "49328 1\n",
      "49408 1165\n",
      "49416 240\n",
      "49440 5\n",
      "49448 1\n",
      "49456 1\n",
      "49472 1440\n",
      "49480 2\n",
      "49488 64\n",
      "49504 13\n",
      "49520 2\n",
      "49664 8797\n",
      "49672 122\n",
      "49696 15\n",
      "49704 1\n",
      "49728 3706\n",
      "49736 4\n",
      "49744 17\n",
      "49760 256\n",
      "49776 25\n",
      "49824 1\n",
      "49920 1248\n",
      "49928 8\n",
      "49952 7\n",
      "49984 453\n",
      "50000 7\n",
      "50016 33\n",
      "50032 5\n",
      "50176 2\n",
      "50184 61\n",
      "50208 9\n",
      "50216 21\n",
      "50240 29\n",
      "50248 6\n",
      "50256 334\n",
      "50272 89\n",
      "50280 4\n",
      "50288 156\n",
      "50432 12\n",
      "50440 9\n",
      "50464 9\n",
      "50472 9\n",
      "50480 1\n",
      "50496 213\n",
      "50512 23\n",
      "50528 188\n",
      "50544 87\n",
      "50592 14\n",
      "50608 5\n",
      "50696 9\n",
      "50720 2\n",
      "50728 4\n",
      "50752 334\n",
      "50784 555\n",
      "50800 176\n",
      "50848 2\n",
      "50944 13\n",
      "50952 4\n",
      "50976 6\n",
      "50984 1\n",
      "51008 24\n",
      "51024 1\n",
      "51040 35\n",
      "51056 4\n",
      "51200 489\n",
      "51208 572\n",
      "51232 30\n",
      "51240 4\n",
      "51264 10815\n",
      "51272 78\n",
      "51280 2012\n",
      "51296 948\n",
      "51304 1\n",
      "51312 777\n",
      "51328 1\n",
      "51456 13\n",
      "51464 156\n",
      "51488 1\n",
      "51496 3\n",
      "51520 419\n",
      "51528 6\n",
      "51536 13\n",
      "51552 66\n",
      "51568 2\n",
      "51712 233\n",
      "51720 80\n",
      "51744 11\n",
      "51752 6\n",
      "51776 570\n",
      "51784 17\n",
      "51792 5\n",
      "51808 161\n",
      "51816 3\n",
      "51824 8\n",
      "51968 2\n",
      "51976 22\n",
      "52000 2\n",
      "52008 1\n",
      "52032 102\n",
      "52064 24\n",
      "52072 1\n",
      "52080 5\n",
      "52224 9\n",
      "52232 122\n",
      "52256 1\n",
      "52264 17\n",
      "52288 132\n",
      "52296 178\n",
      "52304 6\n",
      "52320 105\n",
      "52328 92\n",
      "52336 11\n",
      "52360 4\n",
      "52384 2\n",
      "52392 1\n",
      "52480 4\n",
      "52488 67\n",
      "52512 1\n",
      "52520 15\n",
      "52528 2\n",
      "52544 76\n",
      "52552 39\n",
      "52560 11\n",
      "52576 57\n",
      "52584 3\n",
      "52592 21\n",
      "52616 5\n",
      "52648 3\n",
      "52656 1\n",
      "52736 12\n",
      "52744 19\n",
      "52768 18\n",
      "52776 6\n",
      "52800 385\n",
      "52808 16\n",
      "52816 3\n",
      "52832 466\n",
      "52840 4\n",
      "52848 14\n",
      "52992 3\n",
      "53000 12\n",
      "53024 2\n",
      "53032 1\n",
      "53056 120\n",
      "53064 15\n",
      "53088 71\n",
      "53096 4\n",
      "53104 4\n",
      "53248 1200\n",
      "53256 4\n",
      "53312 35\n",
      "53328 13\n",
      "53336 8\n",
      "53360 15\n",
      "53504 4\n",
      "53512 1\n",
      "53760 497\n",
      "53768 4\n",
      "53824 59\n",
      "53840 103\n",
      "53848 4\n",
      "53856 3\n",
      "53872 31\n",
      "53896 4\n",
      "54016 4\n",
      "54048 1\n",
      "54080 6\n",
      "54272 3\n",
      "54384 4\n",
      "54392 1\n",
      "54848 3\n",
      "54880 1\n",
      "54896 4\n",
      "55104 1\n",
      "55296 61\n",
      "55304 58\n",
      "55336 1\n",
      "55360 70\n",
      "55368 7\n",
      "55560 5\n",
      "55808 288\n",
      "55816 12\n",
      "55840 2\n",
      "55872 82\n",
      "55880 7\n",
      "55904 6\n",
      "56064 11\n",
      "56096 1\n",
      "56128 2\n",
      "56160 1\n",
      "56320 2\n",
      "56328 32\n",
      "56352 2\n",
      "56360 2\n",
      "56384 21\n",
      "56392 23\n",
      "56416 12\n",
      "56424 22\n",
      "56488 2\n",
      "56576 3\n",
      "56584 11\n",
      "56616 5\n",
      "56640 3\n",
      "56648 2\n",
      "56672 1\n",
      "56680 2\n",
      "56712 1\n",
      "56744 1\n",
      "56832 5\n",
      "56840 16\n",
      "56864 1\n",
      "56872 2\n",
      "56896 11\n",
      "56928 7\n",
      "56936 4\n",
      "57096 2\n",
      "57152 2\n",
      "57160 9\n",
      "57184 2\n",
      "81920 5538\n",
      "81936 3\n",
      "81952 1\n",
      "81984 22\n",
      "114688 402261\n",
      "114704 2\n",
      "114720 25\n",
      "114752 221532\n",
      "114768 6588\n",
      "114784 2017\n",
      "114800 1079\n",
      "114816 14\n",
      "114848 5\n",
      "115008 321\n",
      "115040 44\n",
      "115200 1463\n",
      "115232 4\n",
      "115264 773\n",
      "115296 58\n",
      "115328 2\n",
      "115360 1\n",
      "115776 63\n",
      "115792 5\n",
      "115808 39\n",
      "115824 9\n",
      "115872 1\n",
      "116336 4\n",
      "116544 1\n",
      "116560 20\n",
      "116576 1\n",
      "116592 14\n",
      "116736 810\n",
      "116768 62\n",
      "116800 15922\n",
      "116816 3621\n",
      "116832 1113\n",
      "116848 618\n",
      "117056 59\n",
      "117312 101\n",
      "117344 29\n",
      "117824 30\n",
      "117840 2\n",
      "117856 29\n",
      "117872 1\n",
      "118592 1\n",
      "118608 9\n",
      "118624 1\n",
      "118640 9\n",
      "147456 233\n",
      "147488 1\n",
      "147552 7\n",
      "180224 2\n",
      "180288 144\n",
      "180304 31\n",
      "180320 12\n",
      "180336 42\n",
      "180544 5\n",
      "180560 2\n",
      "180736 1\n",
      "180816 1\n",
      "180832 1\n",
      "180848 1\n",
      "181104 1\n",
      "181344 1\n",
      "181360 1\n",
      "181600 4\n",
      "181616 1\n",
      "181824 2\n",
      "181840 1\n",
      "181856 1\n",
      "181872 2\n",
      "182272 2\n",
      "182336 62\n",
      "182352 31\n",
      "182368 9\n",
      "182384 46\n",
      "182592 1\n",
      "182624 1\n",
      "182640 1\n",
      "182704 1\n",
      "182848 2\n",
      "182880 3\n",
      "182896 1\n",
      "183376 1\n",
      "183408 1\n",
      "183600 1\n",
      "183632 1\n",
      "183648 1\n",
      "183664 1\n",
      "183728 1\n",
      "183840 1\n",
      "183872 5\n",
      "183888 1\n",
      "183904 5\n",
      "183920 7\n",
      "212992 1\n",
      "245760 45\n",
      "245824 132\n",
      "245840 26\n",
      "245856 20\n",
      "245872 30\n",
      "246080 2\n",
      "246272 2\n",
      "246304 1\n",
      "246336 1\n",
      "246368 1\n",
      "246864 1\n",
      "246896 1\n",
      "247808 1\n",
      "247872 35\n",
      "247888 28\n",
      "247904 20\n",
      "247920 37\n",
      "248384 1\n",
      "248416 1\n",
      "249680 1\n"
     ]
    }
   ],
   "source": [
    "ccd_cuts = ccd.ccd_cuts\n",
    "m = ccd_cuts > 0\n",
    "ccd_cuts_pos = ccd_cuts[m]\n",
    "print(len(ccd_cuts_pos))\n",
    "\n",
    "unique, counts = np.unique(ccd_cuts, return_counts=True)\n",
    "\n",
    "for i in range(len(unique)):\n",
    "    print(unique[i], counts[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49216\n"
     ]
    },
    {
     "data": {
      "text/plain": "'0b111100101001100000'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ccd_cuts[6])\n",
    "bin(ccd_cuts[6])\n",
    "\n",
    "bin(248416)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "65536\n",
      "131072\n",
      "262143\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(18):\n",
    "    t = 2 ** i\n",
    "    print(t)\n",
    "    c += t\n",
    "\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 1005\n",
      "Test Samples: 495\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9  9  9  9  6  6  6  6  6  7  7  7  7  7  9  9  9  9  8  8 12  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9 12  9  9  9  9  9  9  3  6  6  6  6\n",
      "  6 12 12 12  6  9 12 12 12  9 12 11  5  9  9 10]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.traindata.lengths[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../bricks_data/multiset.pickle', 'rb') as f:\n",
    "    mini_multiset = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import MultiSetSequence\n",
    "data = MultiSetSequence(dict=mini_multiset, num_pixels=20000)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19989\n"
     ]
    }
   ],
   "source": [
    "print(data.num_pixels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}