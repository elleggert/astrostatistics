{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First Attempt at building a deepsets architecture"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import healpy as hp\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experimenting with input sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For DECAM, BASS, MzLS\n",
    "with open('../../bricks_data/pixel2ccd_2048_non_inclusive.pickle', 'rb') as f:\n",
    "    subpixel2ccd_dict = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(subpixel2ccd_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min = 1000\n",
    "max = 0\n",
    "aggregate = 0\n",
    "index_max_sub = 0\n",
    "lens = np.zeros(len(subpixel2ccd_dict))\n",
    "\n",
    "for i,pix in enumerate(subpixel2ccd_dict.keys()):\n",
    "    no_ccds = len(subpixel2ccd_dict[pix])\n",
    "    lens[i] = no_ccds\n",
    "    aggregate += no_ccds\n",
    "    if no_ccds > max:\n",
    "        max = no_ccds\n",
    "        index_max_sub = pix\n",
    "    if no_ccds < min:\n",
    "        min = no_ccds\n",
    "\n",
    "print(\"Mean CCD's per subpixel:\", lens.mean())\n",
    "print(\"Max CCD's per subpixel:\", max)\n",
    "print(\"Min CCD's per subpixel:\", min)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(lens, bins=[0,30,50,100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "    pixel2ccd_dict = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min = 1000\n",
    "max = 0\n",
    "aggregate = 0\n",
    "index_max = 0\n",
    "lens = np.zeros(len(pixel2ccd_dict))\n",
    "\n",
    "for i,pix in enumerate(pixel2ccd_dict.keys()):\n",
    "    no_ccds = len(pixel2ccd_dict[pix])\n",
    "    lens[i] = no_ccds\n",
    "    aggregate += no_ccds\n",
    "    if no_ccds > max:\n",
    "        max = no_ccds\n",
    "        index_max = pix\n",
    "    if no_ccds < min:\n",
    "        min = no_ccds\n",
    "\n",
    "print(\"Mean CCD's per pixel:\", lens.mean())\n",
    "print(\"Max CCD's per pixel:\", max)\n",
    "print(\"Min CCD's per pixel:\", min)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(lens, bins=[0,30,50,100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decamCCD = fits.open('../../bricks_data/ccds-annotated-decam-dr9.fits')\n",
    "mosaicCCD = fits.open('../../bricks_data/ccds-annotated-mosaic-dr9.fits')\n",
    "bassCCD = fits.open('../../bricks_data/ccds-annotated-90prime-dr9.fits')\n",
    "#print(decamCCD[1].columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataDecam = decamCCD[1].data\n",
    "dataMosaic = mosaicCCD[1].data\n",
    "dataBass = bassCCD[1].data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ra0 = np.concatenate((dataDecam.field('ra0'), dataMosaic.field('ra0'), dataBass.field('ra0')), axis=0)\n",
    "dec0 = np.concatenate((dataDecam.field('dec0'), dataMosaic.field('dec0'), dataBass.field('dec0')), axis=0)\n",
    "\n",
    "ra1 = np.concatenate((dataDecam.field('ra1'), dataMosaic.field('ra1'), dataBass.field('ra1')), axis=0)\n",
    "dec1 = np.concatenate((dataDecam.field('dec1'), dataMosaic.field('dec1'), dataBass.field('dec1')), axis=0)\n",
    "\n",
    "ra2 = np.concatenate((dataDecam.field('ra2'), dataMosaic.field('ra2'), dataBass.field('ra2')), axis=0)\n",
    "dec2 = np.concatenate((dataDecam.field('dec2'), dataMosaic.field('dec2'), dataBass.field('dec2')), axis=0)\n",
    "\n",
    "ra3 = np.concatenate((dataDecam.field('ra3'), dataMosaic.field('ra3'), dataBass.field('ra3')), axis=0)\n",
    "dec3 = np.concatenate((dataDecam.field('dec3'), dataMosaic.field('dec3'), dataBass.field('dec3')), axis=0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting the Pixel - CCD Relationship for the most populated pixel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Validating everything went as intended visually\n",
    "\n",
    "NSIDE = 256\n",
    "pixel_number = index_max\n",
    "# print(pixel2ccd_dict.keys())\n",
    "print(len(pixel2ccd_dict.keys()))\n",
    "\n",
    "\n",
    "ccd = pixel2ccd_dict[pixel_number]\n",
    "print(\"Number of CCDs that are cutting pixel number \", pixel_number, \":\", len(ccd))\n",
    "for cc in ccd:\n",
    "#coord = [[x0,y0], [x1,y1], [x2,y2], [x3,y3], [x0,y0]]\n",
    "    xs = [ra0[cc],ra1[cc], ra2[cc], ra3[cc],ra0[cc] ]\n",
    "    ys = [dec0[cc],dec1[cc], dec2[cc], dec3[cc],dec0[cc]]\n",
    "    plt.plot(xs,ys)\n",
    "#if i > 3:\n",
    "    #break\n",
    "\n",
    "pixel_boundary = hp.boundaries(nside=NSIDE, pix=pixel_number, step=1)\n",
    "pixel_boundary_raDec = hp.vec2ang(pixel_boundary.transpose(),lonlat=True)\n",
    "pixel_boundary_raDec = list(pixel_boundary_raDec)\n",
    "pixel_boundary_raDec[0] = np.append(pixel_boundary_raDec[0],pixel_boundary_raDec[0][0])\n",
    "pixel_boundary_raDec[1] = np.append(pixel_boundary_raDec[1],pixel_boundary_raDec[1][0])\n",
    "\n",
    "\n",
    "plt.plot(pixel_boundary_raDec[0],pixel_boundary_raDec[1], c='black', label=\"Pixel Boundary\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Validating everything went as intended visually\n",
    "\n",
    "NSIDE = 2048\n",
    "pixel_number = index_max_sub\n",
    "# print(pixel2ccd_dict.keys())\n",
    "print(len(subpixel2ccd_dict.keys()))\n",
    "\n",
    "\n",
    "ccd_sub = subpixel2ccd_dict[pixel_number]\n",
    "print(\"Number of CCDs that are cutting pixel number \", pixel_number, \":\", len(ccd))\n",
    "for cc in ccd_sub:\n",
    "#coord = [[x0,y0], [x1,y1], [x2,y2], [x3,y3], [x0,y0]]\n",
    "    xs = [ra0[cc],ra1[cc], ra2[cc], ra3[cc],ra0[cc] ]\n",
    "    ys = [dec0[cc],dec1[cc], dec2[cc], dec3[cc],dec0[cc]]\n",
    "    plt.plot(xs,ys)\n",
    "#if i > 3:\n",
    "    #break\n",
    "\n",
    "pixel_boundary = hp.boundaries(nside=NSIDE, pix=pixel_number, step=1)\n",
    "pixel_boundary_raDec = hp.vec2ang(pixel_boundary.transpose(),lonlat=True)\n",
    "pixel_boundary_raDec = list(pixel_boundary_raDec)\n",
    "pixel_boundary_raDec[0] = np.append(pixel_boundary_raDec[0],pixel_boundary_raDec[0][0])\n",
    "pixel_boundary_raDec[1] = np.append(pixel_boundary_raDec[1],pixel_boundary_raDec[1][0])\n",
    "\n",
    "\n",
    "plt.plot(pixel_boundary_raDec[0],pixel_boundary_raDec[1], c='black', label=\"Pixel Boundary\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = [x for x in ccd_sub if x not in ccd]\n",
    "\n",
    "print(len(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a deepsets architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "# Import NN Packages\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(torch.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing Dataset Utility to pass data in the right format\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Build a NN sampling an equal number of CCDs per 256 pixel and pass through deep sets for regression\n",
    "\n",
    "2. Adapt NN for variable sized inputs\n",
    "\n",
    "3. Adapt NN to use 64 inputs of size 2048 to then predict density at 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparing Data to use\n",
    "df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pixels = 10\n",
    "gal_type = 'lrg'\n",
    "num_features = 5\n",
    "max_ccds = 30\n",
    "\n",
    "ids = random.sample(range(len(df_raw)),num_pixels)\n",
    "print(ids)\n",
    "df = df_raw.iloc[ids]\n",
    "print(df.head())\n",
    "labels = df[gal_type].to_numpy()\n",
    "pix_ids = df.pixel_id.to_numpy()\n",
    "print(labels)\n",
    "print(pix_ids)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids = [4257974, 4842643, 4842704, 4949516, 5640882, 5668149, 5817353, 5823130, 5958363]\n",
    "\n",
    "print(len(pixel2ccd_dict))\n",
    "for i in pix_ids:\n",
    "    print(len(pixel2ccd_dict[i]))\n",
    "    print(pixel2ccd_dict[i])\n",
    "\n",
    "from set_dataloader import CCD\n",
    "ccd = CCD()\n",
    "x = ccd.get_ccds(ids)\n",
    "\n",
    "print(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = -1*np.ones((num_pixels,max_ccds,num_features))\n",
    "\n",
    "# Iterate through the pixels\n",
    "for i,pix in enumerate(pix_ids):\n",
    "    ids = pixel2ccd_dict[pix]\n",
    "    print(len(ids))\n",
    "    ids = ids[:30]\n",
    "    print(len(ids))\n",
    "    print()\n",
    "    x = ccd.get_ccds(ids)\n",
    "    # Iterate through the CCDs for every pixel\n",
    "    for j in range(len(ids)):\n",
    "        dataset[i,j] = x[j]\n",
    "print(dataset)\n",
    "print()\n",
    "print(dataset[3])\n",
    "print()\n",
    "print(dataset[3,2,2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from set_dataloader import CCD\n",
    "# noinspection PyAttributeOutsideInit\n",
    "class SetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number Pixels of that are returned\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gal_type = 'lrg', num_pixels = 10, max_ccds = 30, var_set_len = False):\n",
    "\n",
    "        with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "            self.pixel2ccd_dict = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "\n",
    "        self.ccd = CCD()\n",
    "        self.num_features = self.ccd.num_features\n",
    "\n",
    "        self.gal_type = gal_type\n",
    "\n",
    "        # Dimensions\n",
    "        self.num_pixels = num_pixels\n",
    "        self.max_ccds = max_ccds\n",
    "        self.var_set_len = var_set_len\n",
    "\n",
    "        df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "        # Randomly Sampling Pixel Indices from Dataframe\n",
    "        pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "        print(pixel_indices)\n",
    "\n",
    "\n",
    "\n",
    "        self.df = df_raw.iloc[pixel_indices]\n",
    "        self.pix_ids = self.df.pixel_id.to_numpy()\n",
    "\n",
    "        # Features and inputs:\n",
    "        self.target = self.df[gal_type].to_numpy()\n",
    "\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "        self.initialise_lengths()\n",
    "\n",
    "        print(self.lengths)\n",
    "        # Target\n",
    "        self.label = np.random.rand(self.num_pixels*self.max_ccds)\n",
    "\n",
    "\n",
    "        # Mask Variable Len Sets\n",
    "        #self.set_max_set_len()\n",
    "\n",
    "    def initialise_lengths(self):\n",
    "        self.lengths = np.zeros(self.num_pixels, dtype=int)\n",
    "        if self.var_set_len:\n",
    "            for i, pix in enumerate(self.pix_ids):\n",
    "                c = len(self.pixel2ccd_dict[pix])\n",
    "                if c < self.max_ccds:\n",
    "                    self.lengths[i] = c\n",
    "                else:\n",
    "                    self.lengths[i] = self.max_ccds\n",
    "\n",
    "        else:\n",
    "            self.lengths.fill(self.max_ccds)\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "        # Iterate through the pixels\n",
    "        for i, pix in enumerate(self.pix_ids):\n",
    "            ids = self.pixel2ccd_dict[pix]\n",
    "            print(len(ids))\n",
    "            ids = ids[:30]\n",
    "            print(len(ids))\n",
    "            print()\n",
    "            x = self.ccd.get_ccds(ids)\n",
    "            # Iterate through the CCDs for every pixel\n",
    "            for j in range(len(ids)):\n",
    "                self.input[i, j] = x[j]\n",
    "\n",
    "    def set_max_set_len(self):\n",
    "        self.index_matrix =  -1*np.ones((self.num_pixels, self.max_ccds), dtype=int)\n",
    "\n",
    "        # Getting random labels for now, in the future this will be the output densities\n",
    "\n",
    "        m = 0\n",
    "        for i in range(self.num_pixels):\n",
    "\n",
    "            for j in range(self.lengths[i]):\n",
    "                ''' This code with label == 0 is not yet needed, but this masking will become necessary when I have\n",
    "                    I have 64 subpixels per pixel and some of those are not covered by CCDs'''\n",
    "                while self.label[m] == 0:\n",
    "                    m += 1\n",
    "                self.index_matrix[i, j] = m\n",
    "                m += 1\n",
    "\n",
    "        print(self.lengths)\n",
    "        print(self.index_matrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        y = torch.tensor(self.target[idx]).float()\n",
    "        l = self.lengths[idx]\n",
    "        return x,y,l\n",
    "\n",
    "\n",
    "\"\"\" Todo\n",
    "1. Where to get the data from\n",
    "2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\n",
    "3. Combine larger and smaller dataset\n",
    "4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36438, 139395, 248569, 212638, 61172]\n",
      "10\n",
      "10\n",
      "\n",
      "11\n",
      "11\n",
      "\n",
      "21\n",
      "21\n",
      "\n",
      "30\n",
      "30\n",
      "\n",
      "18\n",
      "18\n",
      "\n",
      "[10 11 21 30 18]\n",
      "here\n",
      "tensor([[  2.0000,   1.0000, 100.0000,   2.1900,   1.1626],\n",
      "        [  2.0000,   1.0000, 250.0000,   2.2200,   1.0982],\n",
      "        [  0.0000,   1.0000, 200.0000,   2.1800,   1.6697],\n",
      "        [  1.0000,   1.0000,  67.0000,   2.1700,   1.1360],\n",
      "        [  1.0000,   1.0000,  94.0000,   2.3800,   1.5646],\n",
      "        [  0.0000,   1.0000, 200.0000,   2.1900,   1.6412],\n",
      "        [  2.0000,   2.0000,  80.1030,   1.0031,   0.7991],\n",
      "        [  2.0000,   2.0000,  80.1050,   1.0075,   0.8777],\n",
      "        [  2.0000,   2.0000,  80.1040,   1.0046,   1.0297],\n",
      "        [  2.0000,   2.0000, 113.1040,   1.0007,   1.6532],\n",
      "        [  1.0000,   0.0000, 237.6000,   1.0200,   0.8096],\n",
      "        [  0.0000,   0.0000, 145.0000,   1.0000,   0.7624],\n",
      "        [  1.0000,   0.0000, 152.8000,   1.0200,   0.8725],\n",
      "        [  0.0000,   0.0000,  93.9310,   1.0000,   0.7310],\n",
      "        [  1.0000,   0.0000,  68.2910,   1.0100,   0.5528],\n",
      "        [  0.0000,   0.0000, 237.2000,   1.0600,   0.9563],\n",
      "        [  1.0000,   0.0000,  86.0750,   1.0100,   0.6943],\n",
      "        [  0.0000,   0.0000, 106.7400,   1.0500,   0.7257],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "        [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]])\n",
      "tensor(5.)\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "print(\"here\")\n",
    "x,y,l = traindata.__getitem__(4)\n",
    "print(x)\n",
    "print(y)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DensitySurvey(Dataset):\n",
    "    def __init__(self, df, galaxy_type, scaler_in=None, scaler_out=None):\n",
    "        self.data = df\n",
    "        # Extracting Targets and Input\n",
    "        self.target = self.data[galaxy_type].to_numpy(copy=True)\n",
    "        self.input = self.data.drop(columns=['lrg','elg','qso']).to_numpy(copy=True)\n",
    "\n",
    "        # Scaling, when scaler is passed (test-set) use the existing scaler\n",
    "        self.scaler_in = scaler_in\n",
    "        self.scaler_out = scaler_out\n",
    "        if self.scaler_in is None:\n",
    "            self.scaler_in = preprocessing.MinMaxScaler()\n",
    "            self.scaler_out = preprocessing.MinMaxScaler()\n",
    "            self.input = self.scaler_in.fit_transform(self.input)\n",
    "            self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        else:\n",
    "            self.input = self.scaler_in.transform(self.input)\n",
    "            self.target = self.scaler_out.transform(self.target.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.input[idx]).float(), torch.tensor(self.target[idx]).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dens = DensitySurvey"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}