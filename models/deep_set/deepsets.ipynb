{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First Attempt at building a deepsets architecture"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy import NaN\n",
    "\n",
    "from lightning import LitVarDeepSet, DeepDataModule\n",
    "from set_dataloader import CCD\n",
    "import time\n",
    "\n",
    "# Import NN Packages\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "from models import VarMultiSetNet\n",
    "from util import get_dataset, get_mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "Val_loss=0.0864.ckpt R-2 0.7168382883831987\n",
      "6400\n",
      "Val_loss=0.1429.ckpt R-2 0.32612371680268437\n",
      "6400\n",
      "Val_loss=0.3350.ckpt R-2 -2.3251484338884545\n",
      "6400\n",
      "Val_loss=0.0874.ckpt R-2 0.7095262906684832\n",
      "6400\n",
      "Val_loss=0.0143.ckpt R-2 0.7042203408124708\n",
      "6400\n",
      "Val_loss=0.1800.ckpt R-2 0.04358960218156993\n",
      "6400\n",
      "Val_loss=0.1118.ckpt R-2 0.5438152389356572\n",
      "6400\n",
      "Val_loss=0.3350-v1.ckpt R-2 -2.3251484338884545\n",
      "6400\n",
      "Val_loss=0.0871.ckpt R-2 0.7149399414464737\n",
      "Best Validation Set R-Squared:  0.7168382883831987\n",
      "Filename:  Val_loss=0.0864.ckpt\n",
      "Best Model: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-484ece415af4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best Model: \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'trained_models/{gal}/{best_file}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hyper_parameters'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    605\u001B[0m                     \u001B[0mopened_file\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseek\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_position\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 607\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0m_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_zipfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    608\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_legacy_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m    880\u001B[0m     \u001B[0munpickler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mUnpicklerWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    881\u001B[0m     \u001B[0munpickler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpersistent_load\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpersistent_load\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 882\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munpickler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    883\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_loaded_sparse_tensors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mpersistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m    855\u001B[0m         \u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    856\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mloaded_storages\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 857\u001B[0;31m             \u001B[0mload_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_maybe_decode_ascii\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    858\u001B[0m         \u001B[0mstorage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloaded_storages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    859\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mstorage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload_tensor\u001B[0;34m(data_type, size, key, location)\u001B[0m\n\u001B[1;32m    844\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    845\u001B[0m         \u001B[0mstorage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip_file\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_storage_from_record\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 846\u001B[0;31m         \u001B[0mloaded_storages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrestore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    847\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    848\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpersistent_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msaved_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mdefault_restore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_package_registry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    176\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_cuda_deserialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 151\u001B[0;31m         \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate_cuda_device\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    152\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_torch_load_uninitialized\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m             \u001B[0mstorage_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 135\u001B[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001B[0m\u001B[1;32m    136\u001B[0m                            \u001B[0;34m'device but torch.cuda.is_available() is False. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m                            \u001B[0;34m'If you are running on a CPU-only machine, '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "gal = 'qso'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "num_pixels = 20000\n",
    "max_set_len = 30\n",
    "path_to_data = '../../bricks_data/multiset.pickle'\n",
    "traindata, valdata = get_dataset(num_pixels=num_pixels, max_set_len=max_set_len,\n",
    "                                 gal=gal,\n",
    "                                 path_to_data=path_to_data)\n",
    "\n",
    "valloader = DataLoader(\n",
    "    valdata, batch_size=128, shuffle=False, drop_last=True, num_workers=0)\n",
    "\n",
    "best_score = 0\n",
    "best_file = \"\"\n",
    "for filename in os.listdir(f'trained_models/{gal}/'):\n",
    "    if \"nan\" in filename:\n",
    "        os.remove(f'trained_models/{gal}/{filename}')\n",
    "        continue\n",
    "\n",
    "    # all init args were saved to the checkpoint\n",
    "    #checkpoint = torch.load(f'trained_models/{gal}/{filename}')\n",
    "    #print(checkpoint['hyper_parameters'])\n",
    "\n",
    "    model = LitVarDeepSet.load_from_checkpoint(checkpoint_path=f'trained_models/{gal}/{filename}',\n",
    "                                               hmap_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    y_gold = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X1, X2, labels, set_sizes) in enumerate(valloader):\n",
    "            # Extract inputs and associated labels from dataloader batch\n",
    "            X1 = X1.to(device)\n",
    "\n",
    "            X2 = X2.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X1.shape[2])\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X1, X2, mask=mask)\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            # Get predictions and append to label array + count number of correct and total\n",
    "            y_pred = np.append(y_pred, predictions.cpu().detach().numpy())\n",
    "            y_gold = np.append(y_gold, labels.cpu().detach().numpy())\n",
    "\n",
    "        print(len(y_pred))\n",
    "        r2 = metrics.r2_score(y_gold, y_pred)\n",
    "        if r2 > best_score:\n",
    "            best_score = r2\n",
    "            best_file = filename\n",
    "        print(filename, \"R-2\", r2)\n",
    "\n",
    "print(\"Best Validation Set R-Squared: \", best_score)\n",
    "print(\"Filename: \", best_file)\n",
    "print(\"Best Model: \")\n",
    "\n",
    "checkpoint = torch.load(f'trained_models/{gal}/{best_file}', map_location=torch.device('cpu'))\n",
    "print(checkpoint['hyper_parameters']['model'])\n",
    "\n",
    "#Clean-Up all unnecessary models\n",
    "for filename in os.listdir(f'trained_models/{gal}/'):\n",
    "    if filename == best_file:\n",
    "        continue\n",
    "    os.remove(f'trained_models/{gal}/{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Performance of Trained Model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(15, 224),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(224, 219),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(219, 50),\n",
    "    nn.ReLU(inplace=False)\n",
    ")\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(64 + 2, 247),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(247, 198),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(198, 35),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(35, 1),\n",
    "    nn.ReLU(inplace=False)\n",
    ")\n",
    "\n",
    "lr = 0.00011649895667343224\n",
    "criterion = nn.L1Loss()\n",
    "batch_size = 16\n",
    "no_epochs = 130\n",
    "\n",
    "model = VarMultiSetNet(feature_extractor=feature_extractor, mlp=mlp,\n",
    "                       med_layer=50, reduction='sum')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_models/{}.pt\".format(14))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/14.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "max_set_len = 30\n",
    "gal = 'qso'\n",
    "traindata, valdata = get_dataset(num_pixels=3000, max_set_len=max_set_len, gal=gal)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "num_workers = 0 if device == 'cpu:0' else 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\" | Model params: {sum(p.numel() for p in model.parameters() if p.requires_grad)} |\")\n",
    "\n",
    "print()\n",
    "optimiser = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, shuffle=True,\n",
    "                                          num_workers=num_workers, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "mse, r2 = 0, 0\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (X1, X2, labels, set_sizes) in enumerate(trainloader):\n",
    "        # Extract inputs and associated labels from dataloader batch\n",
    "        X1 = X1.to(device)\n",
    "\n",
    "        X2 = X2.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        set_sizes = set_sizes.to(device)\n",
    "\n",
    "        mask = get_mask(set_sizes, X1.shape[2])\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        predictions = model(X1, X2, mask=mask)\n",
    "\n",
    "        # Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform one step of gradient descent\n",
    "        optimiser.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    y_gold = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X1, X2, labels, set_sizes) in enumerate(valloader):\n",
    "            # Extract inputs and associated labels from dataloader batch\n",
    "            X1 = X1.to(device)\n",
    "\n",
    "            X2 = X2.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X1.shape[2])\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X1, X2, mask=mask)\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            # Get predictions and append to label array + count number of correct and total\n",
    "            y_pred = np.append(y_pred, predictions.cpu().detach().numpy())\n",
    "            y_gold = np.append(y_gold, labels.cpu().detach().numpy())\n",
    "\n",
    "    try:\n",
    "        r2 = metrics.r2_score(y_gold, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_gold, y_pred)\n",
    "    except:\n",
    "        print(\"++++++++++++++++++++\")\n",
    "        print(\"        NaN         \")\n",
    "        print(\"++++++++++++++++++++\")\n",
    "\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"R-2: \", r2)\n",
    "    print(\"MSE: \", mse)\n",
    "    print()\n",
    "    # Handle pruning based on the intermediate value.\n",
    "\n",
    "torch.save(model, \"trained_models/{}.pt\".format(14))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('++++++++ Session Characteristics +++++++')\n",
    "print()\n",
    "print(f\"Gal Type: {gal}\")\n",
    "print(f\"Training Samples: {traindata.num_pixels}\")\n",
    "print(f\"Validation Samples: {valdata.num_pixels}\")\n",
    "print(f\"Maximum Set Lengths: {max_set_len}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print()\n",
    "print('+++++++++++++++++++++++++++++++++++++++')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/14.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "max_set_len = 30\n",
    "gal = 'qso'\n",
    "batch_size\n",
    "traindata, valdata = get_dataset(num_pixels=20000, max_set_len=max_set_len, gal=gal)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, shuffle=True,\n",
    "                                          num_workers=num_workers, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "mse, r2 = 0, 0\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "num_workers = 0 if device == 'cpu:0' else 8\n",
    "print(f\"Training Samples: {traindata.num_pixels}\")\n",
    "print(f\"Validation Samples: {valdata.num_pixels}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = np.array([])\n",
    "y_gold = np.array([])\n",
    "y_set_sizes = np.array([])\n",
    "x2 = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X1, X2, labels, set_sizes) in enumerate(trainloader):\n",
    "        # Extract inputs and associated labels from dataloader batch\n",
    "        X1 = X1.to(device)\n",
    "\n",
    "        X2 = X2.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        set_sizes = set_sizes.to(device)\n",
    "\n",
    "        mask = get_mask(set_sizes, X1.shape[2])\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        predictions = model(X1, X2, mask=mask)\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        # Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, predictions.cpu().detach().numpy())\n",
    "        y_gold = np.append(y_gold, labels.cpu().detach().numpy())\n",
    "        y_set_sizes = np.append(y_set_sizes, set_sizes.cpu().detach().numpy())\n",
    "        x2 = np.append(x2, X2.cpu().detach().numpy())\n",
    "\n",
    "    r2 = metrics.r2_score(y_gold, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_gold, y_pred)\n",
    "\n",
    "    diff = y_gold - y_pred\n",
    "\n",
    "print(\"R-2: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(diff)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_data = '../../bricks_data/multiset.pickle'\n",
    "with open(path_to_data, 'rb') as f:\n",
    "    mini_multiset = pickle.load(f)\n",
    "    f.close()\n",
    "df = pd.DataFrame.from_dict(mini_multiset, orient='index')\n",
    "train_df, test_df = train_test_split(df, test_size=0.33, random_state=99, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zscore = lambda x: abs((x - x.median()) / x.std())\n",
    "df['Z_LRG'] = df[2].transform(zscore)\n",
    "df['Z_ELG'] = df[3].transform(zscore)\n",
    "df['Z_QSO'] = df[4].transform(zscore)\n",
    "\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[(df['Z_LRG'] < 3)]\n",
    "print(df.shape)\n",
    "df = df[(df['Z_ELG'] < 3)]\n",
    "print(df.shape)\n",
    "df = df[(df['Z_QSO'] < 3)]\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(columns=['Z_ELG', 'Z_LRG', 'Z_QSO'], inplace=True)\n",
    "df.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "from util import get_dataset\n",
    "\n",
    "traindata, valdata = get_dataset(num_pixels=20000, max_set_len=30, gal='qso')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=16, shuffle=True,\n",
    "                                          num_workers=0, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=16, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "d = trainloader.dataset[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13204, 64, 30, 15])\n",
      "tensor([0.0755, 0.0827])\n",
      "tensor(0.3341)\n",
      "14.805192791956983\n"
     ]
    }
   ],
   "source": [
    "x1, x2, train_labels, set_sizes = d\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.mean(axis=0))\n",
    "print(train_labels.mean())\n",
    "print(set_sizes.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "d = valloader.dataset[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6505, 64, 30, 15])\n",
      "tensor([0.0737, 0.0825])\n",
      "tensor(0.3349)\n",
      "14.788465603382013\n"
     ]
    }
   ],
   "source": [
    "x1, x2, test_labels, set_sizes = d\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.mean(axis=0))\n",
    "print(test_labels.mean())\n",
    "print(set_sizes.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13204,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.numpy().flatten().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels = train_labels.numpy().flatten()\n",
    "plt.hist(train_labels, range=[0, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_labels = test_labels.numpy().flatten()\n",
    "plt.hist(test_labels, range=[0, 1])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shared = np.append(train_labels, test_labels)\n",
    "print(len(shared))\n",
    "plt.hist(shared)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diff = np.abs(diff)\n",
    "\n",
    "print(diff.mean())\n",
    "print(np.median(diff))\n",
    "print(diff.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diff = np.abs(diff)\n",
    "\n",
    "print(diff.mean())\n",
    "print(np.median(diff))\n",
    "print(diff.max())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a deepsets architecture\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing Dataset Utility to pass data in the right format\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Build a NN sampling an equal number of CCDs per 256 pixel and pass through deep sets for regression\n",
    "\n",
    "2. Adapt NN for variable sized inputs\n",
    "\n",
    "3. Adapt NN to use 64 inputs of size 2048 to then predict density at 256\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class SetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number Pixels of that are returned\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=10, max_ccds=30, var_set_len=False):\n",
    "\n",
    "        with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "            self.pixel2ccd_dict = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        self.ccd = CCD()\n",
    "        self.num_features = self.ccd.num_features\n",
    "\n",
    "        # Dimensions\n",
    "        self.num_pixels = num_pixels\n",
    "        self.max_ccds = max_ccds\n",
    "        self.var_set_len = var_set_len\n",
    "\n",
    "        df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "        # Randomly Sampling Pixel Indices from Dataframe\n",
    "        pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "\n",
    "        self.df = df_raw.iloc[pixel_indices]\n",
    "        self.pix_ids = self.df.pixel_id.to_numpy()\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "        self.initialise_lengths()\n",
    "\n",
    "        # Target\n",
    "        self.label = np.random.rand(self.num_pixels * self.max_ccds)\n",
    "\n",
    "        # Mask Variable Len Sets\n",
    "        #self.set_max_set_len()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        self.target = self.df[gal_type].to_numpy()\n",
    "        #print(self.target.shape)\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        #print(self.target.shape)\n",
    "\n",
    "    def initialise_lengths(self):\n",
    "        self.lengths = np.zeros(self.num_pixels, dtype=int)\n",
    "        if self.var_set_len:\n",
    "            for i, pix in enumerate(self.pix_ids):\n",
    "                c = len(self.pixel2ccd_dict[pix])\n",
    "                if c < self.max_ccds:\n",
    "                    self.lengths[i] = c\n",
    "                else:\n",
    "                    self.lengths[i] = self.max_ccds\n",
    "\n",
    "        else:\n",
    "            self.lengths.fill(self.max_ccds)\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        #self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "        self.input = np.zeros((self.num_pixels, self.max_ccds, self.num_features))\n",
    "\n",
    "        # Iterate through the pixels\n",
    "        for i, pix in enumerate(self.pix_ids):\n",
    "            ids = self.pixel2ccd_dict[pix]\n",
    "            random.shuffle(ids)\n",
    "            #print(len(ids))\n",
    "            ids = ids[:self.max_ccds]\n",
    "            #print(len(ids))\n",
    "            #print()\n",
    "            x = self.ccd.get_ccds(ids)\n",
    "            # Iterate through the CCDs for every pixel\n",
    "            for j in range(len(ids)):\n",
    "                self.input[i, j] = x[j]\n",
    "\n",
    "    def set_max_set_len(self):\n",
    "        self.index_matrix = -1 * np.ones((self.num_pixels, self.max_ccds), dtype=int)\n",
    "\n",
    "        # Getting random labels for now, in the future this will be the output densities\n",
    "\n",
    "        m = 0\n",
    "        for i in range(self.num_pixels):\n",
    "\n",
    "            for j in range(self.lengths[i]):\n",
    "                ''' This code with label == 0 is not yet needed, but this masking will become necessary when I have\n",
    "                    I have 64 subpixels per pixel and some of those are not covered by CCDs'''\n",
    "                while self.label[m] == 0:\n",
    "                    m += 1\n",
    "                self.index_matrix[i, j] = m\n",
    "                m += 1\n",
    "\n",
    "        print(self.lengths)\n",
    "        print(self.index_matrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n",
    "\n",
    "\"\"\" Todo\n",
    "1. Where to get the data from\n",
    "2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\n",
    "3. Combine larger and smaller dataset\n",
    "4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Actual Network Architecture\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class SetNet(nn.Module):\n",
    "    def __init__(self, n_features=5, n_output=3, reduction='sum'):\n",
    "        super(SetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "\n",
    "        y = self.adder(y, mask=mask)\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l)\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = SetNet()\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Work out masking logic\n",
    "device = 'cpu'\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "l = l.to(device)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(l, x.shape[1])\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Hyperparameters and Training Loops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=1000, var_set_len=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = SetNet(n_features=traindata.num_features, reduction='max').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X, mask=mask)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to Build a Network Capable of Processing 64 Subpixels Simultaneously"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Inputs Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccd = CCD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pixels = 2\n",
    "num_subpixels = 4\n",
    "max_ccds = 5\n",
    "num_features = 9\n",
    "#df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "# Randomly Sampling Pixel Indices from Dataframe\n",
    "#pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "pix_ids = [1, 2]\n",
    "pixel2subpixel_dict = {1: [11, 12, 13, 14], 2: [21, 22, 23, 24]}\n",
    "subpixel2ccd_dict = {11: [111, 112, 113, 114], 12: [121, 122, 123, 124, 125], 13: [131, 132, 133, 134, 135],\n",
    "                     14: [141, 142, 143, 144, 145],\n",
    "                     21: [211, 212, 213, 214, 215], 22: [221, 222], 23: [231, 232, 233, 234, 235],\n",
    "                     24: [241, 242, 243, 244, 245]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "# Iterate through the pixels\n",
    "print(\"Pixids\", pix_ids)\n",
    "for pix_no, pix in enumerate(pix_ids):\n",
    "\n",
    "    subpix_ids = pixel2subpixel_dict[pix]\n",
    "    subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "    for subpix_no, subpix in enumerate(subpix_ids):\n",
    "        if subpix not in subpixel2ccd_dict:\n",
    "            continue\n",
    "        subpix_ccds = subpixel2ccd_dict[subpix]\n",
    "        random.shuffle(subpix_ccds)\n",
    "        subpix_ccds = subpix_ccds[:max_ccds]\n",
    "        x = ccd.get_ccds(subpix_ccds)\n",
    "\n",
    "        # Iterate through the CCDs for every pixel\n",
    "        for ccd_no in range(len(subpix_ccds)):\n",
    "            input[pix_no, subpix_no, ccd_no] = x[ccd_no]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Lengths Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_set_len = True\n",
    "lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "print(lengths)\n",
    "if var_set_len:\n",
    "    for pix_no, pix in enumerate(pix_ids):\n",
    "        subpix_ids = pixel2subpixel_dict[pix]\n",
    "        subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "        for subpix_no, subpix in enumerate(subpix_ids):\n",
    "            if subpix not in subpixel2ccd_dict:\n",
    "                lengths[pix_no, subpix_no] = 0\n",
    "                continue\n",
    "            c = len(subpixel2ccd_dict[subpix])\n",
    "            if c < max_ccds:\n",
    "                lengths[pix_no, subpix_no] = c\n",
    "            else:\n",
    "                lengths[pix_no, subpix_no] = max_ccds\n",
    "\n",
    "else:\n",
    "    lengths.fill(max_ccds)\n",
    "\n",
    "print(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GetItem Function\n",
    "idx = 0\n",
    "x = torch.from_numpy(input[idx]).float()\n",
    "\n",
    "#l = torch.tensor(self.lengths[idx])\n",
    "l = lengths[idx]\n",
    "\n",
    "print(x.shape)\n",
    "print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class MultiSetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number SubPixels of that are returned --> usually 64\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=1000, num_subpixels=64, max_ccds=30, num_features=9):\n",
    "\n",
    "        with open('../../bricks_data/mini_multiset.pickle', 'rb') as f:\n",
    "            self.mini_multiset = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        # Initialise DataSet\n",
    "        self.num_pixels = num_pixels\n",
    "        self.num_features = num_features\n",
    "        self.input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "        self.lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "        self.lrg = np.zeros(num_pixels)\n",
    "        self.elg = np.zeros(num_pixels)\n",
    "        self.qso = np.zeros(num_pixels)\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        if gal_type == 'lrg':\n",
    "            self.target = self.lrg\n",
    "        if gal_type == 'elg':\n",
    "            self.target = self.elg\n",
    "        if gal_type == 'qso':\n",
    "            self.target = self.qso\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        for i, pix in enumerate(self.mini_multiset):\n",
    "            if i >= self.num_pixels:\n",
    "                break\n",
    "            self.input[i] = self.mini_multiset[pix][0]\n",
    "            self.lengths[i] = self.mini_multiset[pix][1]\n",
    "            self.lrg[i] = self.mini_multiset[pix][2]\n",
    "            self.elg[i] = self.mini_multiset[pix][3]\n",
    "            self.qso[i] = self.mini_multiset[pix][4]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=10)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class MultiSetNet(nn.Module):\n",
    "    def __init__(self, n_features=9, n_output=3, n_subpix=64, reduction='sum'):\n",
    "        super(MultiSetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_subpix, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "        y = self.adder(y, mask=mask)\n",
    "\n",
    "        y = self.mlp(y.T)\n",
    "        return y\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "1. Train Loop with Batching\n",
    "2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\n",
    "3. How to actually feed real data into the system to see if it can learn\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = MultiSetNet()\n",
    "print(x.shape)\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = MultiSetNet(n_features=traindata.num_features, reduction='sum').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #print(X.shape)\n",
    "            #print(labels.shape)\n",
    "            #print(set_sizes)\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.squeeze().to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            #set_sizes = set_sizes.to(device)\n",
    "\n",
    "            #mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            # Not yet doing any masking\n",
    "            predictions = model(X)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training and Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import train, multi_train, MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Set-Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_train(1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 1: Working out Masking Logic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import SetSequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import init\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets(gal_type='lrg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "X, Y, set_sizes = traindata.__getitem__(3)\n",
    "X = X.unsqueeze(0).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape, set_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(set_sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "set_sizes = torch.Tensor(set_sizes).to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InvLinear(nn.Module):\n",
    "    r\"\"\"Permutation invariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(InvLinear, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        assert reduction in ['mean', 'sum', 'max',\n",
    "                             'min'], '\\'reduction\\' should be \\'mean\\'/\\'sum\\'\\'max\\'/\\'min\\', got {}'.format(reduction)\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.beta = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                              self.out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, self.out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.beta)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.beta)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to a vector y of dimension out_features,\n",
    "        through a permutation invariant linear transformation of the form:\n",
    "            $y = \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N vectors of dimension out_features (tensor with shape (N, out_features))\n",
    "        \"\"\"\n",
    "        print(\"INVLAYER:\", X.shape)\n",
    "        N, M, _ = X.shape\n",
    "        print(N, M)\n",
    "        device = X.device\n",
    "        y = torch.zeros(N, self.out_features).to(device)\n",
    "        print(y)\n",
    "        print(y.shape)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = (Z.sum(dim=1) @ self.beta) / sizes\n",
    "\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = Z.sum(dim=1) @ self.beta\n",
    "\n",
    "        elif self.reduction == 'max':\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('-Inf')\n",
    "            y = Z.max(dim=1)[0] @ self.beta\n",
    "\n",
    "        else:  # min\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('Inf')\n",
    "            y = Z.min(dim=1)[0] @ self.beta\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y += self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, reduction={}'.format(\n",
    "            self.in_features, self.out_features,\n",
    "            self.bias is not None, self.reduction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer = InvLinear(in_features=8, out_features=3, bias=True, reduction='sum')\n",
    "\n",
    "print(layer.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "beta = nn.Parameter(torch.Tensor(4, 3))\n",
    "print(beta)\n",
    "init.xavier_uniform_(beta)\n",
    "print(beta)\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(8, 7),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(7, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.ReLU(inplace=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in trainloader:\n",
    "    X, Y, set_sizes = batch[0], batch[1], batch[2]\n",
    "    break\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(set_sizes.shape)\n",
    "X = feature_extractor(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(set_sizes)\n",
    "set_sizes = torch.tensor(set_sizes).to(device)\n",
    "print(set_sizes)\n",
    "\n",
    "N, M, _ = X.shape\n",
    "print(N, M)\n",
    "device = X.device\n",
    "y = torch.zeros(N, 3).to(device)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#mask = torch.ones(N, M).byte().to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "print(sizes)\n",
    "mask = mask.unsqueeze(2).float()\n",
    "print(mask)\n",
    "print(X)\n",
    "Z = X * mask\n",
    "print(Z)\n",
    "y = Z.sum(dim=1)\n",
    "y = y @ beta\n",
    "print(y)\n",
    "y = y / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean\n",
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "Z = X * mask.unsqueeze(2).float()\n",
    "y = (Z.sum(dim=1) @ beta) / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = layer.forward(X, mask)\n",
    "print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 2: Feeding Info later in NN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "from datasets import MultiSetSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence()\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in trainloader:\n",
    "    print(len(batch))\n",
    "    X1, X2, Y, L = batch[0], batch[1], batch[2], batch[3]\n",
    "    break\n",
    "X = X1.squeeze()\n",
    "\n",
    "X2 = X2.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(L, X.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['models'])\n",
    "from models import MultiSetNet, VarMultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MultiSetNet()\n",
    "\n",
    "print(X.shape)\n",
    "X1 = model.feature_extractor(X)\n",
    "print(X1.shape)\n",
    "X1 = model.adder(X1, mask=mask)\n",
    "print(\"X1,X2\")\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "X1 = torch.cat((X1, X2), dim=0)\n",
    "print(X1.shape)\n",
    "X1 = model.mlp(X1.T)\n",
    "print(X1.shape)\n",
    "print(X1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = model.forward(X, X2, mask=mask)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training a model with new Multisets architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "importlib.reload(sys.modules['models'])\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "importlib.reload(sys.modules['deepset_layers'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "from trainer import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.count_parameters()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 3: MultiBatching in Multisets\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 4: Clean-Up everything and Deploy remotely\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin by Increasing Number of Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['set_dataloader'])\n",
    "\n",
    "from set_dataloader import CCD\n",
    "\n",
    "ccd = CCD()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccd_cuts = ccd.ccd_cuts\n",
    "m = ccd_cuts > 0\n",
    "ccd_cuts_pos = ccd_cuts[m]\n",
    "print(len(ccd_cuts_pos))\n",
    "\n",
    "unique, counts = np.unique(ccd_cuts, return_counts=True)\n",
    "\n",
    "for i in range(len(unique)):\n",
    "    print(unique[i], counts[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ccd_cuts[6])\n",
    "bin(ccd_cuts[6])\n",
    "\n",
    "bin(248416)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(18):\n",
    "    t = 2 ** i\n",
    "    print(t)\n",
    "    c += t\n",
    "\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(trainer.traindata.lengths[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../bricks_data/multiset.pickle', 'rb') as f:\n",
    "    mini_multiset = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import MultiSetSequence\n",
    "\n",
    "data = MultiSetSequence(dict=mini_multiset, num_pixels=20000)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.num_pixels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}