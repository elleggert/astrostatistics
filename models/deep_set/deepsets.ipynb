{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First Attempt at building a deepsets architecture"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy import NaN\n",
    "\n",
    "from set_dataloader import CCD\n",
    "import time\n",
    "\n",
    "# Import NN Packages\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "from models import VarMultiSetNet\n",
    "from util import get_dataset, get_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Performance of Trained Model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(15, 224),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(224, 219),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(219, 50),\n",
    "    nn.ReLU(inplace=False)\n",
    ")\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(64 + 2, 247),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(247, 198),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(198, 35),\n",
    "    nn.ReLU(inplace=False),\n",
    "    nn.Linear(35, 1),\n",
    "    nn.ReLU(inplace=False)\n",
    ")\n",
    "\n",
    "lr = 0.00011649895667343224\n",
    "criterion = nn.L1Loss()\n",
    "batch_size = 16\n",
    "no_epochs = 130\n",
    "\n",
    "model = VarMultiSetNet(feature_extractor=feature_extractor, mlp=mlp,\n",
    "                       med_layer=50, reduction='sum')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_models/{}.pt\".format(14))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/14.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "max_set_len = 30\n",
    "gal = 'qso'\n",
    "traindata, valdata = get_dataset(num_pixels=3000, max_set_len=max_set_len, gal=gal)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "num_workers = 0 if device == 'cpu:0' else 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Model params: 136564 |\n",
      "\n",
      "R-2:  -0.026618383182568817\n",
      "MSE:  0.02640719139235231\n",
      "R-2:  -0.06533579094969744\n",
      "MSE:  0.027403099914809086\n",
      "R-2:  -0.08399028848673562\n",
      "MSE:  0.02788294022826773\n",
      "R-2:  0.05304433127716124\n",
      "MSE:  0.024358067217261147\n",
      "R-2:  0.06184028880680936\n",
      "MSE:  0.024131813199439692\n",
      "R-2:  -0.01975588386154148\n",
      "MSE:  0.02623067075336037\n",
      "R-2:  0.09468924106126408\n",
      "MSE:  0.02328685602408453\n",
      "R-2:  0.0974531228018467\n",
      "MSE:  0.0232157620759291\n",
      "R-2:  -0.005785736055645474\n",
      "MSE:  0.025871323626002203\n",
      "R-2:  0.04052929602482158\n",
      "MSE:  0.024679985211916614\n",
      "R-2:  0.18823424409037703\n",
      "MSE:  0.020880644680849055\n",
      "R-2:  0.21392052778650383\n",
      "MSE:  0.02021992924770134\n",
      "R-2:  0.21109615076952293\n",
      "MSE:  0.02029257928560575\n",
      "R-2:  0.23321542153696007\n",
      "MSE:  0.019723616342623748\n",
      "R-2:  0.28816698604170754\n",
      "MSE:  0.01831012472299433\n",
      "R-2:  0.35146915981175775\n",
      "MSE:  0.01668183455628651\n",
      "R-2:  0.352299978448648\n",
      "MSE:  0.016660463823874063\n",
      "R-2:  0.37125275653309786\n",
      "MSE:  0.01617295098902563\n",
      "R-2:  0.34418283582486375\n",
      "MSE:  0.016869257025258978\n",
      "R-2:  0.42099003699947946\n",
      "MSE:  0.014893583790730225\n",
      "R-2:  0.31348798000462497\n",
      "MSE:  0.017658805455020105\n",
      "R-2:  0.3414872927926659\n",
      "MSE:  0.01693859313098592\n",
      "R-2:  0.3016316914775047\n",
      "MSE:  0.01796377883701626\n",
      "R-2:  0.47549887269200664\n",
      "MSE:  0.013491480262986487\n",
      "R-2:  0.431434339404001\n",
      "MSE:  0.014624930221815163\n",
      "R-2:  0.475164718776536\n",
      "MSE:  0.01350007553708725\n",
      "R-2:  0.49159745976569025\n",
      "MSE:  0.013077384356498507\n",
      "R-2:  0.42940840775048705\n",
      "MSE:  0.01467704224883373\n",
      "R-2:  0.4288286239896604\n",
      "MSE:  0.014691955736639065\n",
      "R-2:  0.5020228519695553\n",
      "MSE:  0.012809217205220403\n",
      "R-2:  0.520434520563659\n",
      "MSE:  0.012335623059253705\n",
      "R-2:  0.518855767406817\n",
      "MSE:  0.01237623253737815\n",
      "R-2:  0.49774943040009056\n",
      "MSE:  0.012919140291669743\n",
      "R-2:  0.5374532996243806\n",
      "MSE:  0.011897857514351406\n",
      "R-2:  0.5180751257948916\n",
      "MSE:  0.01239631259126443\n",
      "R-2:  0.317356811476572\n",
      "MSE:  0.01755928943736635\n",
      "R-2:  0.4479629676275507\n",
      "MSE:  0.01419977258183679\n",
      "R-2:  0.5014330196113936\n",
      "MSE:  0.01282438916807099\n",
      "R-2:  0.5167017811353383\n",
      "MSE:  0.012431638449311177\n",
      "R-2:  0.5190127723654863\n",
      "MSE:  0.012372193977324052\n",
      "R-2:  0.5433551519264603\n",
      "MSE:  0.011746047118333299\n",
      "R-2:  0.5000808898830806\n",
      "MSE:  0.012859169325048268\n",
      "R-2:  0.5212282523181608\n",
      "MSE:  0.012315206294174612\n",
      "R-2:  0.5359496116539271\n",
      "MSE:  0.011936536128216716\n",
      "R-2:  0.5049887413791503\n",
      "MSE:  0.012732927114792715\n",
      "R-2:  0.528252536870056\n",
      "MSE:  0.0121345241345768\n",
      "R-2:  0.5151128470600426\n",
      "MSE:  0.012472509806110857\n",
      "R-2:  0.555713284786765\n",
      "MSE:  0.011428165045461687\n",
      "R-2:  0.5112205094215634\n",
      "MSE:  0.012572630461133938\n",
      "R-2:  0.5369587052520051\n",
      "MSE:  0.011910579718109745\n",
      "R-2:  0.5557494120701876\n",
      "MSE:  0.011427235761412758\n",
      "R-2:  0.5594120107094547\n",
      "MSE:  0.01133302456780383\n",
      "R-2:  0.5273149877497351\n",
      "MSE:  0.01215864024185251\n",
      "R-2:  0.5443171256611503\n",
      "MSE:  0.011721302748913746\n",
      "R-2:  0.5546065790898365\n",
      "MSE:  0.01145663228278428\n",
      "R-2:  0.5149669712450726\n",
      "MSE:  0.01247626209676582\n",
      "R-2:  0.5356359914917046\n",
      "MSE:  0.011944603222848935\n",
      "R-2:  0.5281039009695273\n",
      "MSE:  0.01213834742153263\n",
      "R-2:  0.5620282435157324\n",
      "MSE:  0.011265728519365506\n",
      "R-2:  0.5388842349619489\n",
      "MSE:  0.011861050280087682\n",
      "R-2:  0.5008401424117748\n",
      "MSE:  0.012839639451856052\n",
      "R-2:  0.542268416619462\n",
      "MSE:  0.011774000667300314\n",
      "R-2:  0.5365017098647145\n",
      "MSE:  0.011922334781973095\n",
      "R-2:  0.5193853046678454\n",
      "MSE:  0.012362611515165389\n",
      "R-2:  0.5589402343580132\n",
      "MSE:  0.011345159835018003\n",
      "R-2:  0.5568351882106827\n",
      "MSE:  0.01139930688460615\n",
      "R-2:  0.54012322335979\n",
      "MSE:  0.011829180400986877\n",
      "R-2:  0.4755760328255626\n",
      "MSE:  0.013489495511448768\n",
      "R-2:  0.5580725503365045\n",
      "MSE:  0.011367478837287408\n",
      "R-2:  0.5393146848689756\n",
      "MSE:  0.011849978032341215\n",
      "R-2:  0.5543778263692128\n",
      "MSE:  0.011462516374647415\n",
      "R-2:  0.5531213704383278\n",
      "MSE:  0.011494835562367472\n",
      "R-2:  0.5584055982713918\n",
      "MSE:  0.011358912011772235\n",
      "R-2:  0.5540684936248981\n",
      "MSE:  0.011470473186172373\n",
      "R-2:  0.534965545928544\n",
      "MSE:  0.011961848758867539\n",
      "R-2:  0.54835539940205\n",
      "MSE:  0.011617428252491757\n",
      "R-2:  0.5471434710529073\n",
      "MSE:  0.011648602079489102\n",
      "R-2:  0.5165670027016518\n",
      "MSE:  0.01243510528757574\n",
      "R-2:  0.5534447952480588\n",
      "MSE:  0.01148651626768942\n",
      "R-2:  0.5554281137663732\n",
      "MSE:  0.011435500357042305\n",
      "R-2:  0.5572423768598249\n",
      "MSE:  0.01138883297456632\n",
      "R-2:  0.5431773243010292\n",
      "MSE:  0.011750621289433813\n",
      "R-2:  0.5323470056834265\n",
      "MSE:  0.012029204160401487\n",
      "R-2:  0.5679733011758789\n",
      "MSE:  0.011112806773523227\n",
      "R-2:  0.4613728353083385\n",
      "MSE:  0.0138548372600136\n",
      "R-2:  0.5446562674252418\n",
      "MSE:  0.011712579174876685\n",
      "R-2:  0.5540258610620354\n",
      "MSE:  0.011471569802271892\n",
      "R-2:  0.5444677121160973\n",
      "MSE:  0.011717429288821834\n",
      "R-2:  0.5668296635872997\n",
      "MSE:  0.01114222399142992\n",
      "R-2:  0.5585315109976179\n",
      "MSE:  0.011355673221668089\n",
      "R-2:  0.5349582729249257\n",
      "MSE:  0.011962035838703328\n",
      "R-2:  0.5451726059921618\n",
      "MSE:  0.011699297656073524\n",
      "R-2:  0.5487951452234021\n",
      "MSE:  0.011606116890588776\n",
      "R-2:  0.5441236008611252\n",
      "MSE:  0.011726280690588228\n",
      "R-2:  0.5612389312802138\n",
      "MSE:  0.011286031603367422\n",
      "R-2:  0.518712198114605\n",
      "MSE:  0.012379925498501403\n",
      "R-2:  0.5312317555705947\n",
      "MSE:  0.012057891181462412\n",
      "R-2:  0.5666165945284865\n",
      "MSE:  0.011147704660301664\n",
      "R-2:  0.5732901341371982\n",
      "MSE:  0.010976044537515462\n",
      "R-2:  0.5601483709837887\n",
      "MSE:  0.011314083540625084\n",
      "R-2:  0.5366388463835661\n",
      "MSE:  0.011918807287862805\n",
      "R-2:  0.5563218252718659\n",
      "MSE:  0.011412511862815335\n",
      "R-2:  0.5716314693451621\n",
      "MSE:  0.011018709542678598\n",
      "R-2:  0.5731257192597976\n",
      "MSE:  0.010980273699204353\n",
      "R-2:  0.5748918208677463\n",
      "MSE:  0.010934845150540669\n",
      "R-2:  0.5583536836945898\n",
      "MSE:  0.011360247384475587\n",
      "R-2:  0.5961475988146749\n",
      "MSE:  0.010388093401660222\n",
      "R-2:  0.5851239097606642\n",
      "MSE:  0.010671650243684229\n",
      "R-2:  0.5767909429725641\n",
      "MSE:  0.01088599498214226\n",
      "R-2:  0.5450796546954497\n",
      "MSE:  0.011701688595806002\n",
      "R-2:  0.5831575624027162\n",
      "MSE:  0.010722229613658305\n",
      "R-2:  0.5475721982713294\n",
      "MSE:  0.011637574143600319\n",
      "R-2:  0.5964806413860846\n",
      "MSE:  0.010379526714107102\n",
      "R-2:  0.6038708437298355\n",
      "MSE:  0.010189432234097252\n",
      "R-2:  0.5570433832050637\n",
      "MSE:  0.011393951588856909\n",
      "R-2:  0.5920865761216185\n",
      "MSE:  0.010492553058004749\n",
      "R-2:  0.5812823685699828\n",
      "MSE:  0.010770464287077298\n",
      "R-2:  0.6157614045200408\n",
      "MSE:  0.009883577283812858\n",
      "R-2:  0.5765763760744811\n",
      "MSE:  0.010891514179184663\n",
      "R-2:  0.6061343605277871\n",
      "MSE:  0.010131208923193727\n",
      "R-2:  0.5934676337163864\n",
      "MSE:  0.010457028803981711\n",
      "R-2:  0.6081619468019283\n",
      "MSE:  0.010079054335196028\n",
      "R-2:  0.6016234052667583\n",
      "MSE:  0.010247241970031486\n",
      "R-2:  0.6358650172405458\n",
      "MSE:  0.009366462105003814\n",
      "R-2:  0.6211506602267907\n",
      "MSE:  0.009744952153733572\n",
      "R-2:  0.6106629521721143\n",
      "MSE:  0.010014722224486045\n",
      "R-2:  0.6295982828571371\n",
      "MSE:  0.0095276581803699\n",
      "R-2:  0.6205542565484279\n",
      "MSE:  0.009760293147368228\n",
      "R-2:  0.6129367293602971\n",
      "MSE:  0.00995623499069449\n",
      "R-2:  0.6105920007932498\n",
      "MSE:  0.010016547271331026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\" | Model params: {sum(p.numel() for p in model.parameters() if p.requires_grad)} |\")\n",
    "\n",
    "print()\n",
    "optimiser = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, shuffle=True,\n",
    "                                          num_workers=num_workers, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "mse, r2 = 0, 0\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (X1, X2, labels, set_sizes) in enumerate(trainloader):\n",
    "        # Extract inputs and associated labels from dataloader batch\n",
    "        X1 = X1.to(device)\n",
    "\n",
    "        X2 = X2.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        set_sizes = set_sizes.to(device)\n",
    "\n",
    "        mask = get_mask(set_sizes, X1.shape[2])\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        predictions = model(X1, X2, mask=mask)\n",
    "\n",
    "        # Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform one step of gradient descent\n",
    "        optimiser.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    y_gold = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X1, X2, labels, set_sizes) in enumerate(valloader):\n",
    "            # Extract inputs and associated labels from dataloader batch\n",
    "            X1 = X1.to(device)\n",
    "\n",
    "            X2 = X2.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X1.shape[2])\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X1, X2, mask=mask)\n",
    "            # Predict outputs (forward pass)\n",
    "\n",
    "            # Get predictions and append to label array + count number of correct and total\n",
    "            y_pred = np.append(y_pred, predictions.cpu().detach().numpy())\n",
    "            y_gold = np.append(y_gold, labels.cpu().detach().numpy())\n",
    "\n",
    "    try:\n",
    "        r2 = metrics.r2_score(y_gold, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_gold, y_pred)\n",
    "    except:\n",
    "        print(\"++++++++++++++++++++\")\n",
    "        print(\"        NaN         \")\n",
    "        print(\"++++++++++++++++++++\")\n",
    "\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"R-2: \", r2)\n",
    "    print(\"MSE: \", mse)\n",
    "    print()\n",
    "    # Handle pruning based on the intermediate value.\n",
    "\n",
    "torch.save(model, \"trained_models/{}.pt\".format(14))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++ Session Characteristics +++++++\n",
      "\n",
      "Gal Type: qso\n",
      "Training Samples: 2008\n",
      "Validation Samples: 990\n",
      "Maximum Set Lengths: 30\n",
      "Device: cpu:0\n",
      "Number of Workers: 0\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "print('++++++++ Session Characteristics +++++++')\n",
    "print()\n",
    "print(f\"Gal Type: {gal}\")\n",
    "print(f\"Training Samples: {traindata.num_pixels}\")\n",
    "print(f\"Validation Samples: {valdata.num_pixels}\")\n",
    "print(f\"Maximum Set Lengths: {max_set_len}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of Workers: {num_workers}\")\n",
    "print()\n",
    "print('+++++++++++++++++++++++++++++++++++++++')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 13394\n",
      "Validation Samples: 6595\n",
      "Training Samples: 13394\n",
      "Validation Samples: 6595\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('trained_models/14.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "max_set_len = 30\n",
    "gal = 'qso'\n",
    "traindata, valdata = get_dataset(num_pixels=20000, max_set_len=max_set_len, gal=gal)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, shuffle=True,\n",
    "                                          num_workers=num_workers, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "mse, r2 = 0, 0\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "num_workers = 0 if device == 'cpu:0' else 8\n",
    "print(f\"Training Samples: {traindata.num_pixels}\")\n",
    "print(f\"Validation Samples: {valdata.num_pixels}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-2:  0.5308065964837925\n",
      "MSE:  0.007209734480148055\n",
      "[-0.09881625 -0.03531551  0.07321015 ... -0.00868121 -0.06905782\n",
      " -0.04350576]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = np.array([])\n",
    "y_gold = np.array([])\n",
    "y_set_sizes = np.array([])\n",
    "x2 = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X1, X2, labels, set_sizes) in enumerate(trainloader):\n",
    "        # Extract inputs and associated labels from dataloader batch\n",
    "        X1 = X1.to(device)\n",
    "\n",
    "        X2 = X2.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        set_sizes = set_sizes.to(device)\n",
    "\n",
    "        mask = get_mask(set_sizes, X1.shape[2])\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        predictions = model(X1, X2, mask=mask)\n",
    "        # Predict outputs (forward pass)\n",
    "\n",
    "        # Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, predictions.cpu().detach().numpy())\n",
    "        y_gold = np.append(y_gold, labels.cpu().detach().numpy())\n",
    "        y_set_sizes = np.append(y_set_sizes, set_sizes.cpu().detach().numpy())\n",
    "        x2 = np.append(x2, X2.cpu().detach().numpy())\n",
    "\n",
    "    r2 = metrics.r2_score(y_gold, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_gold, y_pred)\n",
    "\n",
    "    diff = y_gold - y_pred\n",
    "\n",
    "print(\"R-2: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(diff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "traindata, valdata = get_dataset(num_pixels=20000, max_set_len=30, gal='qso')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=16, shuffle=True,\n",
    "                                          num_workers=0, drop_last=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdata, batch_size=16, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "d = trainloader.dataset[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13392, 64, 30, 15])\n",
      "tensor([0.0763, 0.0831])\n",
      "tensor(0.0907)\n",
      "14.80072641315711\n"
     ]
    }
   ],
   "source": [
    "x1,x2,train_labels,set_sizes = d\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.mean(axis=0))\n",
    "print(train_labels.mean())\n",
    "print(set_sizes.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "d = valloader.dataset[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6597, 64, 30, 15])\n",
      "tensor([0.0780, 0.0827])\n",
      "tensor(0.2252)\n",
      "14.815517470062149\n"
     ]
    }
   ],
   "source": [
    "x1,x2,test_labels,set_sizes = d\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.mean(axis=0))\n",
    "print(test_labels.mean())\n",
    "print(set_sizes.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13392,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.numpy().flatten().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels = train_labels.numpy().flatten()\n",
    "plt.hist(train_labels, range=[0,1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_labels = test_labels.numpy().flatten()\n",
    "plt.hist(test_labels, range=[0,1])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19989\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shared = np.append(train_labels, test_labels)\n",
    "print(len(shared))\n",
    "plt.hist(shared, range=[0,1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diff = np.abs(diff)\n",
    "\n",
    "print(diff.mean())\n",
    "print(np.median(diff))\n",
    "print(diff.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06455788083512315\n",
      "0.049366846680641174\n",
      "0.7136873006820679\n"
     ]
    }
   ],
   "source": [
    "diff = np.abs(diff)\n",
    "\n",
    "print(diff.mean())\n",
    "print(np.median(diff))\n",
    "print(diff.max())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a deepsets architecture\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing Dataset Utility to pass data in the right format\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Build a NN sampling an equal number of CCDs per 256 pixel and pass through deep sets for regression\n",
    "\n",
    "2. Adapt NN for variable sized inputs\n",
    "\n",
    "3. Adapt NN to use 64 inputs of size 2048 to then predict density at 256\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "' Todo\\n1. Where to get the data from\\n2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\\n3. Combine larger and smaller dataset\\n4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\\n'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class SetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number Pixels of that are returned\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=10, max_ccds=30, var_set_len=False):\n",
    "\n",
    "        with open('../../bricks_data/pixel2ccd_256_non_inclusive.pickle', 'rb') as f:\n",
    "            self.pixel2ccd_dict = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        self.ccd = CCD()\n",
    "        self.num_features = self.ccd.num_features\n",
    "\n",
    "        # Dimensions\n",
    "        self.num_pixels = num_pixels\n",
    "        self.max_ccds = max_ccds\n",
    "        self.var_set_len = var_set_len\n",
    "\n",
    "        df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "        # Randomly Sampling Pixel Indices from Dataframe\n",
    "        pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "\n",
    "        self.df = df_raw.iloc[pixel_indices]\n",
    "        self.pix_ids = self.df.pixel_id.to_numpy()\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "        self.initialise_lengths()\n",
    "\n",
    "        # Target\n",
    "        self.label = np.random.rand(self.num_pixels * self.max_ccds)\n",
    "\n",
    "        # Mask Variable Len Sets\n",
    "        #self.set_max_set_len()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        self.target = self.df[gal_type].to_numpy()\n",
    "        #print(self.target.shape)\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        #print(self.target.shape)\n",
    "\n",
    "    def initialise_lengths(self):\n",
    "        self.lengths = np.zeros(self.num_pixels, dtype=int)\n",
    "        if self.var_set_len:\n",
    "            for i, pix in enumerate(self.pix_ids):\n",
    "                c = len(self.pixel2ccd_dict[pix])\n",
    "                if c < self.max_ccds:\n",
    "                    self.lengths[i] = c\n",
    "                else:\n",
    "                    self.lengths[i] = self.max_ccds\n",
    "\n",
    "        else:\n",
    "            self.lengths.fill(self.max_ccds)\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        #self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "        self.input = np.zeros((self.num_pixels, self.max_ccds, self.num_features))\n",
    "\n",
    "        # Iterate through the pixels\n",
    "        for i, pix in enumerate(self.pix_ids):\n",
    "            ids = self.pixel2ccd_dict[pix]\n",
    "            random.shuffle(ids)\n",
    "            #print(len(ids))\n",
    "            ids = ids[:self.max_ccds]\n",
    "            #print(len(ids))\n",
    "            #print()\n",
    "            x = self.ccd.get_ccds(ids)\n",
    "            # Iterate through the CCDs for every pixel\n",
    "            for j in range(len(ids)):\n",
    "                self.input[i, j] = x[j]\n",
    "\n",
    "    def set_max_set_len(self):\n",
    "        self.index_matrix = -1 * np.ones((self.num_pixels, self.max_ccds), dtype=int)\n",
    "\n",
    "        # Getting random labels for now, in the future this will be the output densities\n",
    "\n",
    "        m = 0\n",
    "        for i in range(self.num_pixels):\n",
    "\n",
    "            for j in range(self.lengths[i]):\n",
    "                ''' This code with label == 0 is not yet needed, but this masking will become necessary when I have\n",
    "                    I have 64 subpixels per pixel and some of those are not covered by CCDs'''\n",
    "                while self.label[m] == 0:\n",
    "                    m += 1\n",
    "                self.index_matrix[i, j] = m\n",
    "                m += 1\n",
    "\n",
    "        print(self.lengths)\n",
    "        print(self.index_matrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n",
    "\n",
    "\"\"\" Todo\n",
    "1. Where to get the data from\n",
    "2. Scaling --> import an already scaled dataset, this will have to be prepared but should be same for Neural Net\n",
    "3. Combine larger and smaller dataset\n",
    "4. Build 64 input channels instead of one, so one more dimension of tensors( NO of Pixels,no_of_subpixels,no_ccds, no_features)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "torch.Size([30, 9])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Actual Network Architecture\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class SetNet(nn.Module):\n",
    "    def __init__(self, n_features=5, n_output=3, reduction='sum'):\n",
    "        super(SetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "\n",
    "        y = self.adder(y, mask=mask)\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n",
      "9\n",
      "tensor([[0.5417]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "traindata = SetSequence(var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l)\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 3])\n",
      "tensor([[-8.7350]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = SetNet()\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#Work out masking logic\n",
    "device = 'cpu'\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "l = l.to(device)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(l, x.shape[1])\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Hyperparameters and Training Loops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=1000, var_set_len=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  2942.1800325997174\n",
      "Loss for Epoch 10 :  3.680534098879434\n",
      "Loss for Epoch 20 :  2.884592419693945\n",
      "Loss for Epoch 30 :  2.765893154341029\n",
      "Loss for Epoch 40 :  2.5631455073598772\n",
      "Loss for Epoch 50 :  2.684168670588406\n",
      "Loss for Epoch 60 :  2.5554687872645445\n",
      "Loss for Epoch 70 :  2.4053838056570385\n",
      "Loss for Epoch 80 :  2.4015086796716787\n",
      "Loss for Epoch 90 :  2.399972525483463\n",
      "\n",
      "0.39641 minutes (23.8 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  27871.49012487009\n",
      "Loss for Epoch 10 :  8.458283477695659\n",
      "Loss for Epoch 20 :  4.994630630942993\n",
      "Loss for Epoch 30 :  4.833354047266766\n",
      "Loss for Epoch 40 :  4.84361100976821\n",
      "Loss for Epoch 50 :  4.83717059326591\n",
      "Loss for Epoch 60 :  4.820220751920715\n",
      "Loss for Epoch 70 :  4.846069120801985\n",
      "Loss for Epoch 80 :  4.8225392025779\n",
      "Loss for Epoch 90 :  4.808886545091809\n",
      "\n",
      "0.42237 minutes (25.3 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  14189.960423341021\n",
      "Loss for Epoch 10 :  13.390178092289716\n",
      "Loss for Epoch 20 :  11.792379513382912\n",
      "Loss for Epoch 30 :  12.168904803926125\n",
      "Loss for Epoch 40 :  12.2246720418334\n",
      "Loss for Epoch 50 :  10.915961837163195\n",
      "Loss for Epoch 60 :  10.814511087955907\n",
      "Loss for Epoch 70 :  10.813041705056094\n",
      "Loss for Epoch 80 :  10.80818999488838\n",
      "Loss for Epoch 90 :  10.80691729253158\n",
      "\n",
      "0.38134 minutes (22.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = SetNet(n_features=traindata.num_features, reduction='max').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            set_sizes = set_sizes.to(device)\n",
    "\n",
    "            mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            predictions = model(X, mask=mask)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to Build a Network Capable of Processing 64 Subpixels Simultaneously"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Inputs Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccd = CCD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pixels = 2\n",
    "num_subpixels = 4\n",
    "max_ccds = 5\n",
    "num_features = 9\n",
    "#df_raw = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "# Randomly Sampling Pixel Indices from Dataframe\n",
    "#pixel_indices = random.sample(range(len(df_raw)), num_pixels)\n",
    "pix_ids = [1, 2]\n",
    "pixel2subpixel_dict = {1: [11, 12, 13, 14], 2: [21, 22, 23, 24]}\n",
    "subpixel2ccd_dict = {11: [111, 112, 113, 114], 12: [121, 122, 123, 124, 125], 13: [131, 132, 133, 134, 135],\n",
    "                     14: [141, 142, 143, 144, 145],\n",
    "                     21: [211, 212, 213, 214, 215], 22: [221, 222], 23: [231, 232, 233, 234, 235],\n",
    "                     24: [241, 242, 243, 244, 245]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#self.input = -1 * np.ones((self.num_pixels, self.max_ccds, self.num_features))\n",
    "input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "# Iterate through the pixels\n",
    "print(\"Pixids\", pix_ids)\n",
    "for pix_no, pix in enumerate(pix_ids):\n",
    "\n",
    "    subpix_ids = pixel2subpixel_dict[pix]\n",
    "    subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "    for subpix_no, subpix in enumerate(subpix_ids):\n",
    "        if subpix not in subpixel2ccd_dict:\n",
    "            continue\n",
    "        subpix_ccds = subpixel2ccd_dict[subpix]\n",
    "        random.shuffle(subpix_ccds)\n",
    "        subpix_ccds = subpix_ccds[:max_ccds]\n",
    "        x = ccd.get_ccds(subpix_ccds)\n",
    "\n",
    "        # Iterate through the CCDs for every pixel\n",
    "        for ccd_no in range(len(subpix_ccds)):\n",
    "            input[pix_no, subpix_no, ccd_no] = x[ccd_no]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Lengths Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_set_len = True\n",
    "lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "print(lengths)\n",
    "if var_set_len:\n",
    "    for pix_no, pix in enumerate(pix_ids):\n",
    "        subpix_ids = pixel2subpixel_dict[pix]\n",
    "        subpix_ids = subpix_ids[:num_subpixels]\n",
    "\n",
    "        for subpix_no, subpix in enumerate(subpix_ids):\n",
    "            if subpix not in subpixel2ccd_dict:\n",
    "                lengths[pix_no, subpix_no] = 0\n",
    "                continue\n",
    "            c = len(subpixel2ccd_dict[subpix])\n",
    "            if c < max_ccds:\n",
    "                lengths[pix_no, subpix_no] = c\n",
    "            else:\n",
    "                lengths[pix_no, subpix_no] = max_ccds\n",
    "\n",
    "else:\n",
    "    lengths.fill(max_ccds)\n",
    "\n",
    "print(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GetItem Function\n",
    "idx = 0\n",
    "x = torch.from_numpy(input[idx]).float()\n",
    "\n",
    "#l = torch.tensor(self.lengths[idx])\n",
    "l = lengths[idx]\n",
    "\n",
    "print(x.shape)\n",
    "print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class MultiSetSequence(Dataset):\n",
    "    \"\"\"Processes and Returns a Dataset of Variable Sized Input Sets of Dimensions\n",
    "    N = Number SubPixels of that are returned --> usually 64\n",
    "    M = Max Size of each Individual Set of CCDs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels=1000, num_subpixels=64, max_ccds=30, num_features=9):\n",
    "\n",
    "        with open('../../bricks_data/mini_multiset.pickle', 'rb') as f:\n",
    "            self.mini_multiset = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        # Initialise DataSet\n",
    "        self.num_pixels = num_pixels\n",
    "        self.num_features = num_features\n",
    "        self.input = np.zeros((num_pixels, num_subpixels, max_ccds, num_features))\n",
    "        self.lengths = np.zeros((num_pixels, num_subpixels), dtype=int)\n",
    "        self.lrg = np.zeros(num_pixels)\n",
    "        self.elg = np.zeros(num_pixels)\n",
    "        self.qso = np.zeros(num_pixels)\n",
    "\n",
    "        self.initialise_inputs()\n",
    "\n",
    "    def set_targets(self, gal_type):\n",
    "        # Features and inputs:\n",
    "        self.target = None\n",
    "        if gal_type == 'lrg':\n",
    "            self.target = self.lrg\n",
    "        if gal_type == 'elg':\n",
    "            self.target = self.elg\n",
    "        if gal_type == 'qso':\n",
    "            self.target = self.qso\n",
    "        self.scaler_out = preprocessing.MinMaxScaler()\n",
    "        self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "\n",
    "    def initialise_inputs(self):\n",
    "        for i, pix in enumerate(self.mini_multiset):\n",
    "            if i >= self.num_pixels:\n",
    "                break\n",
    "            self.input[i] = self.mini_multiset[pix][0]\n",
    "            self.lengths[i] = self.mini_multiset[pix][1]\n",
    "            self.lrg[i] = self.mini_multiset[pix][2]\n",
    "            self.elg[i] = self.mini_multiset[pix][3]\n",
    "            self.qso[i] = self.mini_multiset[pix][4]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pixels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.input[idx]).float()\n",
    "        #x = x.unsqueeze(0)\n",
    "        y = torch.tensor(self.target[idx, 0]).float()\n",
    "        #print(y.shape)\n",
    "        y = y.unsqueeze(-1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #l = torch.tensor(self.lengths[idx])\n",
    "        l = self.lengths[idx]\n",
    "\n",
    "        return x, y, l\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=10)\n",
    "traindata.set_targets('lrg')\n",
    "x, y, l = traindata.__getitem__(3)\n",
    "print(l.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "' TODO\\n1. Train Loop with Batching\\n2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\\n3. How to actually feed real data into the system to see if it can learn\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepset_layers import InvLinear\n",
    "\n",
    "\n",
    "class MultiSetNet(nn.Module):\n",
    "    def __init__(self, n_features=9, n_output=3, n_subpix=64, reduction='sum'):\n",
    "        super(MultiSetNet, self).__init__()\n",
    "\n",
    "        # Takes an Input Tensor and applies transformations to last layer --> features\n",
    "        # Output of Feature Layer: Tensor with Max.CCDs elements, which can now be passed to Set Layer\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(n_features, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(5, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.adder = InvLinear(3, 1, reduction=reduction, bias=True)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_subpix, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Invariant Layer Influenced by Code from DPernes, but adapted for the current regression task instead of CNN\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        y = self.feature_extractor(X)\n",
    "        y = self.adder(y, mask=mask)\n",
    "\n",
    "        y = self.mlp(y.T)\n",
    "        return y\n",
    "\n",
    "\n",
    "\"\"\" TODO\n",
    "1. Train Loop with Batching\n",
    "2. Masking Procedure, need to mask out singular values on top of those that have no CCDs\n",
    "3. How to actually feed real data into the system to see if it can learn\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "tensor([[0.]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "net = MultiSetNet()\n",
    "print(x.shape)\n",
    "y = net.forward(x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100  #very low, but computational power not sufficient for more iterations\n",
    "batch = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['lrg', 'elg', 'qso']\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence(num_pixels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  21.203732424415648\n",
      "Loss for Epoch 10 :  21.21518995705992\n",
      "Loss for Epoch 20 :  21.21518995705992\n",
      "Loss for Epoch 30 :  21.21518995705992\n",
      "Loss for Epoch 40 :  21.21518995705992\n",
      "Loss for Epoch 50 :  21.21518995705992\n",
      "Loss for Epoch 60 :  21.21518995705992\n",
      "Loss for Epoch 70 :  21.21518995705992\n",
      "Loss for Epoch 80 :  21.21518995705992\n",
      "Loss for Epoch 90 :  21.21518995705992\n",
      "\n",
      "0.19455 minutes (11.7 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  38.964210975915194\n",
      "Loss for Epoch 10 :  38.91034494712949\n",
      "Loss for Epoch 20 :  38.91034494712949\n",
      "Loss for Epoch 30 :  38.91034494712949\n",
      "Loss for Epoch 40 :  38.91034494712949\n",
      "Loss for Epoch 50 :  38.91034494712949\n",
      "Loss for Epoch 60 :  38.91034494712949\n",
      "Loss for Epoch 70 :  38.91034494712949\n",
      "Loss for Epoch 80 :  38.91034494712949\n",
      "Loss for Epoch 90 :  38.91034494712949\n",
      "\n",
      "0.23638 minutes (14.2 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  18.97755779325962\n",
      "Loss for Epoch 10 :  18.832214936614037\n",
      "Loss for Epoch 20 :  19.019644618034363\n",
      "Loss for Epoch 30 :  19.00366996228695\n",
      "Loss for Epoch 40 :  18.487545117735863\n",
      "Loss for Epoch 50 :  18.563062861561775\n",
      "Loss for Epoch 60 :  18.284362956881523\n",
      "Loss for Epoch 70 :  18.3128974288702\n",
      "Loss for Epoch 80 :  18.225802645087242\n",
      "Loss for Epoch 90 :  18.286328971385956\n",
      "\n",
      "0.24793 minutes (14.9 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = MultiSetNet(n_features=traindata.num_features, reduction='sum').to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata.set_targets(gal_type=gal)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle=True)\n",
    "\n",
    "        for i, (X, labels, set_sizes) in enumerate(trainloader):\n",
    "            #print(X.shape)\n",
    "            #print(labels.shape)\n",
    "            #print(set_sizes)\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            X = X.squeeze().to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            #set_sizes = set_sizes.to(device)\n",
    "\n",
    "            #mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "\n",
    "            # Not yet doing any masking\n",
    "            predictions = model(X)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed / 60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training and Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import train, multi_train, MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Set-Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "Loss for Epoch 0 :  10.053878550264926\n",
      "Loss for Epoch 10 :  10.053878550264926\n",
      "Loss for Epoch 20 :  10.053878550264926\n",
      "Loss for Epoch 30 :  10.053878550264926\n",
      "Loss for Epoch 40 :  10.053878550264926\n",
      "Loss for Epoch 50 :  10.053878550264926\n",
      "Loss for Epoch 60 :  10.053878550264926\n",
      "Loss for Epoch 70 :  10.053878550264926\n",
      "Loss for Epoch 80 :  10.053878550264926\n",
      "Loss for Epoch 90 :  10.053878550264926\n",
      "\n",
      "1.7579 minutes (1.05e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  elg\n",
      "\n",
      "Loss for Epoch 0 :  11629.811594213443\n",
      "Loss for Epoch 10 :  42.34878332098149\n",
      "Loss for Epoch 20 :  42.36339263490362\n",
      "Loss for Epoch 30 :  42.325412895846654\n",
      "Loss for Epoch 40 :  42.393384256566165\n",
      "Loss for Epoch 50 :  42.373732197336295\n",
      "Loss for Epoch 60 :  42.40096284180902\n",
      "Loss for Epoch 70 :  42.24797562570515\n",
      "Loss for Epoch 80 :  42.28472199212819\n",
      "Loss for Epoch 90 :  42.39563592875416\n",
      "\n",
      "1.7813 minutes (1.07e+02 seconds) taken to train the model\n",
      "\n",
      "GALAXY TYPE:  qso\n",
      "\n",
      "Loss for Epoch 0 :  214.11590725108545\n",
      "Loss for Epoch 10 :  176.07240221574466\n",
      "Loss for Epoch 20 :  176.07240221574466\n",
      "Loss for Epoch 30 :  176.07240221574466\n",
      "Loss for Epoch 40 :  176.07240221574466\n",
      "Loss for Epoch 50 :  176.07240221574466\n",
      "Loss for Epoch 60 :  176.07240221574466\n",
      "Loss for Epoch 70 :  176.07240221574466\n",
      "Loss for Epoch 80 :  176.07240221574466\n",
      "Loss for Epoch 90 :  176.07240221574466\n",
      "\n",
      "1.7694 minutes (1.06e+02 seconds) taken to train the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_train(1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 670\n",
      "Test Samples: 330\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  lrg\n",
      "\n",
      "torch.Size([1, 64])\n",
      "tensor([[28, 23, 21, 30, 30, 30, 30, 30, 30, 30, 27, 30, 27, 27, 23, 30, 30, 30,\n",
      "         30, 30, 30, 30, 28, 30, 30, 30, 27, 30, 24, 24, 24, 24, 24, 24, 23, 21,\n",
      "         28, 26, 28, 28, 28, 21, 27, 21, 21, 21, 21, 21, 20, 22, 24, 30, 30, 24,\n",
      "         24, 28, 30, 30, 19, 26, 26, 25, 28, 30]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgareggert/astrostatistics/models/deep_set/utilities.py:214: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # set_sizes = set_sizes.to(device)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultiSetNet R^2 for lrg :  -1.4573048083786349.\n",
      "MultiSetNet MSE for lrg :  0.013348963645229783.\n",
      "\n",
      "MultiSetNet R^2 for elg :  -2.142983122931937.\n",
      "MultiSetNet MSE for elg :  0.1886151816532751.\n",
      "\n",
      "MultiSetNet R^2 for qso :  -2.0842765440713604.\n",
      "MultiSetNet MSE for qso :  0.16178952133573077.\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 1: Working out Masking Logic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from datasets import SetSequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import init\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets(gal_type='lrg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "X, Y, set_sizes = traindata.__getitem__(3)\n",
    "X = X.unsqueeze(0).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 8]) torch.Size([1]) 14\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape, set_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14]]\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-109-ec108aa3ee66>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-106-afda90f0d0a5>\u001B[0m in \u001B[0;36mget_mask\u001B[0;34m(sizes, max_size)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msizes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.int64' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1).to(sizes.device) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "set_sizes = torch.Tensor(set_sizes).to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "print(type(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class InvLinear(nn.Module):\n",
    "    r\"\"\"Permutation invariant linear layer.\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        reduction: Permutation invariant operation that maps the input set into a single\n",
    "            vector. Currently, the following are supported: mean, sum, max and min.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, reduction='mean'):\n",
    "        super(InvLinear, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        assert reduction in ['mean', 'sum', 'max',\n",
    "                             'min'], '\\'reduction\\' should be \\'mean\\'/\\'sum\\'\\'max\\'/\\'min\\', got {}'.format(reduction)\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.beta = nn.Parameter(torch.Tensor(self.in_features,\n",
    "                                              self.out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, self.out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.beta)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.beta)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, X, mask=None):\n",
    "        r\"\"\"\n",
    "        Maps the input set X = {x_1, ..., x_M} to a vector y of dimension out_features,\n",
    "        through a permutation invariant linear transformation of the form:\n",
    "            $y = \\beta reduction(X) + bias$\n",
    "        Inputs:\n",
    "        X: N sets of size at most M where each element has dimension in_features\n",
    "           (tensor with shape (N, M, in_features))\n",
    "        mask: binary mask to indicate which elements in X are valid (byte tensor\n",
    "            with shape (N, M) or None); if None, all sets have the maximum size M.\n",
    "            Default: ``None``.\n",
    "        Outputs:\n",
    "        Y: N vectors of dimension out_features (tensor with shape (N, out_features))\n",
    "        \"\"\"\n",
    "        print(\"INVLAYER:\", X.shape)\n",
    "        N, M, _ = X.shape\n",
    "        print(N, M)\n",
    "        device = X.device\n",
    "        y = torch.zeros(N, self.out_features).to(device)\n",
    "        print(y)\n",
    "        print(y.shape)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.ones(N, M).byte().to(device)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = (Z.sum(dim=1) @ self.beta) / sizes\n",
    "\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            Z = X * mask.unsqueeze(2).float()\n",
    "            y = Z.sum(dim=1) @ self.beta\n",
    "\n",
    "        elif self.reduction == 'max':\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('-Inf')\n",
    "            y = Z.max(dim=1)[0] @ self.beta\n",
    "\n",
    "        else:  # min\n",
    "            Z = X.clone()\n",
    "            Z[~mask] = float('Inf')\n",
    "            y = Z.min(dim=1)[0] @ self.beta\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y += self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, reduction={}'.format(\n",
    "            self.in_features, self.out_features,\n",
    "            self.bias is not None, self.reduction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2822, -0.2697, -0.3711]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer = InvLinear(in_features=8, out_features=3, bias=True, reduction='sum')\n",
    "\n",
    "print(layer.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000e+00, -1.5846e+29,  5.0240e+15],\n",
      "        [-4.6577e-10,  1.2612e-44,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.7819, -0.0058,  0.0651],\n",
      "        [-0.0663,  0.6536,  0.0455],\n",
      "        [ 0.6011, -0.5926, -0.6082],\n",
      "        [-0.1283, -0.3870,  0.8119]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "beta = nn.Parameter(torch.Tensor(4, 3))\n",
    "print(beta)\n",
    "init.xavier_uniform_(beta)\n",
    "print(beta)\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(8, 7),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(7, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.ReLU(inplace=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3149, 0.1904, 0.0078, 0.6765, 0.7230, 0.0260, 1.0000, 0.0000],\n",
      "        [0.1332, 0.1242, 0.0032, 0.5936, 0.6804, 0.0285, 1.0000, 2.0000],\n",
      "        [0.2082, 0.1904, 0.0082, 0.6525, 0.6998, 0.0260, 1.0000, 1.0000],\n",
      "        [0.2082, 0.2318, 0.0055, 0.6495, 0.6985, 0.0132, 1.0000, 1.0000],\n",
      "        [0.0815, 0.1531, 0.0043, 0.6496, 0.7003, 0.0126, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2069, 0.0070, 0.6758, 0.7228, 0.0274, 1.0000, 0.0000],\n",
      "        [0.3066, 0.1531, 0.0049, 0.6741, 0.7200, 0.0285, 1.0000, 0.0000],\n",
      "        [0.1199, 0.2235, 0.0036, 0.6415, 0.7069, 0.0283, 1.0000, 1.0000],\n",
      "        [0.4116, 0.1366, 0.0037, 0.5766, 0.6879, 0.0132, 1.0000, 2.0000],\n",
      "        [0.1665, 0.1490, 0.0042, 0.5767, 0.6709, 0.0281, 1.0000, 2.0000],\n",
      "        [0.4166, 0.1324, 0.0034, 0.5763, 0.6901, 0.0260, 1.0000, 2.0000],\n",
      "        [0.0865, 0.1366, 0.0053, 0.6507, 0.7010, 0.0251, 1.0000, 1.0000],\n",
      "        [0.1349, 0.1945, 0.0066, 0.6565, 0.7018, 0.0277, 1.0000, 1.0000],\n",
      "        [0.3332, 0.2442, 0.0073, 0.6760, 0.7222, 0.0130, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.4475],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4188],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4128],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4147],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4142],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4473],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4479],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4176],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3940],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4193],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3941],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4136],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4155],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4466],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "        [0.0407, 0.0000, 0.0000, 0.3793]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "traindata = SetSequence(num_pixels=10, var_set_len=True)\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 30, 8])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    X, Y, set_sizes = batch[0], batch[1], batch[2]\n",
    "    break\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(set_sizes.shape)\n",
    "X = feature_extractor(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 11,  9, 11])\n",
      "tensor([11, 11,  9, 11])\n",
      "4 30\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-80fa19fef633>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  set_sizes = torch.tensor(set_sizes).to(device)\n"
     ]
    }
   ],
   "source": [
    "print(set_sizes)\n",
    "set_sizes = torch.tensor(set_sizes).to(device)\n",
    "print(set_sizes)\n",
    "\n",
    "N, M, _ = X.shape\n",
    "print(N, M)\n",
    "device = X.device\n",
    "y = torch.zeros(N, 3).to(device)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#mask = torch.ones(N, M).byte().to(device)\n",
    "mask = get_mask(set_sizes, X.shape[1])\n",
    "\n",
    "print(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.],\n",
      "        [11.],\n",
      "        [ 9.],\n",
      "        [11.]])\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793],\n",
      "         [0.0407, 0.0000, 0.0000, 0.3793]]], grad_fn=<ReluBackward1>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.4102],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4108],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4089],\n",
      "         [0.0251, 0.0000, 0.0000, 0.3924],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4251],\n",
      "         [0.0271, 0.0000, 0.0000, 0.3918],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4093],\n",
      "         [0.0272, 0.0000, 0.0000, 0.3917],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3913],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4240],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4286],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4498],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4337],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4481],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4495],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4151],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4493],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4552],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4499],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4496],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.4147],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4094],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4133],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4095],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4410],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4124],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4072],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4449],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0111, 0.0000, 0.0000, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4299],\n",
      "         [0.0215, 0.0000, 0.0000, 0.3955],\n",
      "         [0.0234, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0236, 0.0000, 0.0000, 0.3942],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4014],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4117],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0246, 0.0000, 0.0000, 0.3936],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4278],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5127, -1.7340,  3.6416],\n",
      "        [-0.6222, -1.8766,  3.9364],\n",
      "        [-0.4870, -1.4688,  3.0810],\n",
      "        [-0.4943, -1.7375,  3.6502]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "print(sizes)\n",
    "mask = mask.unsqueeze(2).float()\n",
    "print(mask)\n",
    "print(X)\n",
    "Z = X * mask\n",
    "print(Z)\n",
    "y = Z.sum(dim=1)\n",
    "y = y @ beta\n",
    "print(y)\n",
    "y = y / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean\n",
    "sizes = mask.float().sum(dim=1).unsqueeze(1)\n",
    "Z = X * mask.unsqueeze(2).float()\n",
    "y = (Z.sum(dim=1) @ beta) / sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVLAYER: torch.Size([1, 30, 8])\n",
      "1 30\n",
      "tensor([[0., 0., 0.]])\n",
      "torch.Size([1, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y = layer.forward(X, mask)\n",
    "print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 2: Feeding Info later in NN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "from datasets import MultiSetSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [],
   "source": [
    "traindata = MultiSetSequence()\n",
    "traindata.set_targets('lrg')\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    print(len(batch))\n",
    "    X1, X2, Y, L = batch[0], batch[1], batch[2], batch[3]\n",
    "    break\n",
    "X = X1.squeeze()\n",
    "\n",
    "X2 = X2.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def get_mask(sizes, max_size):\n",
    "    return (torch.arange(max_size).reshape(1, -1) < sizes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "mask = get_mask(L, X.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['models'])\n",
    "from models import MultiSetNet, VarMultiSetNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "X1,X2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([66, 1])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.3807]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 9])\n",
      "torch.Size([64, 30, 3])\n",
      "X1,X2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([66, 1])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.3487]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model = MultiSetNet()\n",
    "\n",
    "print(X.shape)\n",
    "X1 = model.feature_extractor(X)\n",
    "print(X1.shape)\n",
    "X1 = model.adder(X1, mask=mask)\n",
    "print(\"X1,X2\")\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "X1 = torch.cat((X1, X2), dim=0)\n",
    "print(X1.shape)\n",
    "X1 = model.mlp(X1.T)\n",
    "print(X1.shape)\n",
    "print(X1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3487]], grad_fn=<ReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "y = model.forward(X, X2, mask=mask)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training a model with new Multisets architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'deepset_layers' from '/Users/edgareggert/astrostatistics/models/deep_set/deepset_layers.py'>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "importlib.reload(sys.modules['models'])\n",
    "importlib.reload(sys.modules['datasets'])\n",
    "importlib.reload(sys.modules['deepset_layers'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['trainer'])\n",
    "from trainer import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 670\n",
      "Test Samples: 330\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-39-9b24b891e092>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/utilities.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mgal\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgalaxy_types\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m             \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMultiSetNet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_features\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraindata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Model {gal} params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/models.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, n_features, n_output, n_subpix, reduction)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         )\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInvLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         self.mlp = nn.Sequential(\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/deepset_layers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, in_features, out_features, bias, reduction)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0min_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mInvLinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0min_features\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-1887f338d018>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/astrostatistics/models/deep_set/utilities.py\u001B[0m in \u001B[0;36mtest\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgal\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgalaxy_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    263\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m             \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "trainer.test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "trainer.count_parameters()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 3: MultiBatching in Multisets\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Todo 4: Clean-Up everything and Deploy remotely\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin by Increasing Number of Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['set_dataloader'])\n",
    "\n",
    "from set_dataloader import CCD\n",
    "\n",
    "ccd = CCD()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544600\n",
      "0 5231831\n",
      "16384 593758\n",
      "16400 2\n",
      "16416 94\n",
      "16448 2660\n",
      "16480 44\n",
      "16496 11\n",
      "16512 10\n",
      "16544 16\n",
      "16896 26\n",
      "16928 1\n",
      "16992 1\n",
      "18432 232\n",
      "18464 2\n",
      "18496 2\n",
      "18528 6\n",
      "18544 1\n",
      "18560 1\n",
      "18944 23\n",
      "18976 11\n",
      "19040 45\n",
      "20480 206\n",
      "20512 9\n",
      "22528 5\n",
      "23040 1\n",
      "49152 11637\n",
      "49160 1894\n",
      "49184 48\n",
      "49192 13\n",
      "49216 216804\n",
      "49224 196\n",
      "49232 4896\n",
      "49248 1632\n",
      "49256 2\n",
      "49264 2029\n",
      "49280 80\n",
      "49288 60\n",
      "49312 1\n",
      "49328 1\n",
      "49408 1165\n",
      "49416 240\n",
      "49440 5\n",
      "49448 1\n",
      "49456 1\n",
      "49472 1440\n",
      "49480 2\n",
      "49488 64\n",
      "49504 13\n",
      "49520 2\n",
      "49664 8797\n",
      "49672 122\n",
      "49696 15\n",
      "49704 1\n",
      "49728 3706\n",
      "49736 4\n",
      "49744 17\n",
      "49760 256\n",
      "49776 25\n",
      "49824 1\n",
      "49920 1248\n",
      "49928 8\n",
      "49952 7\n",
      "49984 453\n",
      "50000 7\n",
      "50016 33\n",
      "50032 5\n",
      "50176 2\n",
      "50184 61\n",
      "50208 9\n",
      "50216 21\n",
      "50240 29\n",
      "50248 6\n",
      "50256 334\n",
      "50272 89\n",
      "50280 4\n",
      "50288 156\n",
      "50432 12\n",
      "50440 9\n",
      "50464 9\n",
      "50472 9\n",
      "50480 1\n",
      "50496 213\n",
      "50512 23\n",
      "50528 188\n",
      "50544 87\n",
      "50592 14\n",
      "50608 5\n",
      "50696 9\n",
      "50720 2\n",
      "50728 4\n",
      "50752 334\n",
      "50784 555\n",
      "50800 176\n",
      "50848 2\n",
      "50944 13\n",
      "50952 4\n",
      "50976 6\n",
      "50984 1\n",
      "51008 24\n",
      "51024 1\n",
      "51040 35\n",
      "51056 4\n",
      "51200 489\n",
      "51208 572\n",
      "51232 30\n",
      "51240 4\n",
      "51264 10815\n",
      "51272 78\n",
      "51280 2012\n",
      "51296 948\n",
      "51304 1\n",
      "51312 777\n",
      "51328 1\n",
      "51456 13\n",
      "51464 156\n",
      "51488 1\n",
      "51496 3\n",
      "51520 419\n",
      "51528 6\n",
      "51536 13\n",
      "51552 66\n",
      "51568 2\n",
      "51712 233\n",
      "51720 80\n",
      "51744 11\n",
      "51752 6\n",
      "51776 570\n",
      "51784 17\n",
      "51792 5\n",
      "51808 161\n",
      "51816 3\n",
      "51824 8\n",
      "51968 2\n",
      "51976 22\n",
      "52000 2\n",
      "52008 1\n",
      "52032 102\n",
      "52064 24\n",
      "52072 1\n",
      "52080 5\n",
      "52224 9\n",
      "52232 122\n",
      "52256 1\n",
      "52264 17\n",
      "52288 132\n",
      "52296 178\n",
      "52304 6\n",
      "52320 105\n",
      "52328 92\n",
      "52336 11\n",
      "52360 4\n",
      "52384 2\n",
      "52392 1\n",
      "52480 4\n",
      "52488 67\n",
      "52512 1\n",
      "52520 15\n",
      "52528 2\n",
      "52544 76\n",
      "52552 39\n",
      "52560 11\n",
      "52576 57\n",
      "52584 3\n",
      "52592 21\n",
      "52616 5\n",
      "52648 3\n",
      "52656 1\n",
      "52736 12\n",
      "52744 19\n",
      "52768 18\n",
      "52776 6\n",
      "52800 385\n",
      "52808 16\n",
      "52816 3\n",
      "52832 466\n",
      "52840 4\n",
      "52848 14\n",
      "52992 3\n",
      "53000 12\n",
      "53024 2\n",
      "53032 1\n",
      "53056 120\n",
      "53064 15\n",
      "53088 71\n",
      "53096 4\n",
      "53104 4\n",
      "53248 1200\n",
      "53256 4\n",
      "53312 35\n",
      "53328 13\n",
      "53336 8\n",
      "53360 15\n",
      "53504 4\n",
      "53512 1\n",
      "53760 497\n",
      "53768 4\n",
      "53824 59\n",
      "53840 103\n",
      "53848 4\n",
      "53856 3\n",
      "53872 31\n",
      "53896 4\n",
      "54016 4\n",
      "54048 1\n",
      "54080 6\n",
      "54272 3\n",
      "54384 4\n",
      "54392 1\n",
      "54848 3\n",
      "54880 1\n",
      "54896 4\n",
      "55104 1\n",
      "55296 61\n",
      "55304 58\n",
      "55336 1\n",
      "55360 70\n",
      "55368 7\n",
      "55560 5\n",
      "55808 288\n",
      "55816 12\n",
      "55840 2\n",
      "55872 82\n",
      "55880 7\n",
      "55904 6\n",
      "56064 11\n",
      "56096 1\n",
      "56128 2\n",
      "56160 1\n",
      "56320 2\n",
      "56328 32\n",
      "56352 2\n",
      "56360 2\n",
      "56384 21\n",
      "56392 23\n",
      "56416 12\n",
      "56424 22\n",
      "56488 2\n",
      "56576 3\n",
      "56584 11\n",
      "56616 5\n",
      "56640 3\n",
      "56648 2\n",
      "56672 1\n",
      "56680 2\n",
      "56712 1\n",
      "56744 1\n",
      "56832 5\n",
      "56840 16\n",
      "56864 1\n",
      "56872 2\n",
      "56896 11\n",
      "56928 7\n",
      "56936 4\n",
      "57096 2\n",
      "57152 2\n",
      "57160 9\n",
      "57184 2\n",
      "81920 5538\n",
      "81936 3\n",
      "81952 1\n",
      "81984 22\n",
      "114688 402261\n",
      "114704 2\n",
      "114720 25\n",
      "114752 221532\n",
      "114768 6588\n",
      "114784 2017\n",
      "114800 1079\n",
      "114816 14\n",
      "114848 5\n",
      "115008 321\n",
      "115040 44\n",
      "115200 1463\n",
      "115232 4\n",
      "115264 773\n",
      "115296 58\n",
      "115328 2\n",
      "115360 1\n",
      "115776 63\n",
      "115792 5\n",
      "115808 39\n",
      "115824 9\n",
      "115872 1\n",
      "116336 4\n",
      "116544 1\n",
      "116560 20\n",
      "116576 1\n",
      "116592 14\n",
      "116736 810\n",
      "116768 62\n",
      "116800 15922\n",
      "116816 3621\n",
      "116832 1113\n",
      "116848 618\n",
      "117056 59\n",
      "117312 101\n",
      "117344 29\n",
      "117824 30\n",
      "117840 2\n",
      "117856 29\n",
      "117872 1\n",
      "118592 1\n",
      "118608 9\n",
      "118624 1\n",
      "118640 9\n",
      "147456 233\n",
      "147488 1\n",
      "147552 7\n",
      "180224 2\n",
      "180288 144\n",
      "180304 31\n",
      "180320 12\n",
      "180336 42\n",
      "180544 5\n",
      "180560 2\n",
      "180736 1\n",
      "180816 1\n",
      "180832 1\n",
      "180848 1\n",
      "181104 1\n",
      "181344 1\n",
      "181360 1\n",
      "181600 4\n",
      "181616 1\n",
      "181824 2\n",
      "181840 1\n",
      "181856 1\n",
      "181872 2\n",
      "182272 2\n",
      "182336 62\n",
      "182352 31\n",
      "182368 9\n",
      "182384 46\n",
      "182592 1\n",
      "182624 1\n",
      "182640 1\n",
      "182704 1\n",
      "182848 2\n",
      "182880 3\n",
      "182896 1\n",
      "183376 1\n",
      "183408 1\n",
      "183600 1\n",
      "183632 1\n",
      "183648 1\n",
      "183664 1\n",
      "183728 1\n",
      "183840 1\n",
      "183872 5\n",
      "183888 1\n",
      "183904 5\n",
      "183920 7\n",
      "212992 1\n",
      "245760 45\n",
      "245824 132\n",
      "245840 26\n",
      "245856 20\n",
      "245872 30\n",
      "246080 2\n",
      "246272 2\n",
      "246304 1\n",
      "246336 1\n",
      "246368 1\n",
      "246864 1\n",
      "246896 1\n",
      "247808 1\n",
      "247872 35\n",
      "247888 28\n",
      "247904 20\n",
      "247920 37\n",
      "248384 1\n",
      "248416 1\n",
      "249680 1\n"
     ]
    }
   ],
   "source": [
    "ccd_cuts = ccd.ccd_cuts\n",
    "m = ccd_cuts > 0\n",
    "ccd_cuts_pos = ccd_cuts[m]\n",
    "print(len(ccd_cuts_pos))\n",
    "\n",
    "unique, counts = np.unique(ccd_cuts, return_counts=True)\n",
    "\n",
    "for i in range(len(unique)):\n",
    "    print(unique[i], counts[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49216\n"
     ]
    },
    {
     "data": {
      "text/plain": "'0b111100101001100000'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ccd_cuts[6])\n",
    "bin(ccd_cuts[6])\n",
    "\n",
    "bin(248416)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "65536\n",
      "131072\n",
      "262143\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(18):\n",
    "    t = 2 ** i\n",
    "    print(t)\n",
    "    c += t\n",
    "\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "importlib.reload(sys.modules['utilities'])\n",
    "from utilities import MultiSetTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 1005\n",
      "Test Samples: 495\n"
     ]
    }
   ],
   "source": [
    "trainer = MultiSetTrainer(num_pixels=1500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9  9  9  9  6  6  6  6  6  7  7  7  7  7  9  9  9  9  8  8 12  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9 12  9  9  9  9  9  9  3  6  6  6  6\n",
      "  6 12 12 12  6  9 12 12 12  9 12 11  5  9  9 10]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.traindata.lengths[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../bricks_data/multiset.pickle', 'rb') as f:\n",
    "    mini_multiset = pickle.load(f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import MultiSetSequence\n",
    "\n",
    "data = MultiSetSequence(dict=mini_multiset, num_pixels=20000)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19989\n"
     ]
    }
   ],
   "source": [
    "print(data.num_pixels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}