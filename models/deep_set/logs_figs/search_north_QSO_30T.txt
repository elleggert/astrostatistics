[32m[I 2021-08-19 16:28:38,778][0m A new study created in memory with name: DeepSet[0m
Starting Loading north
Finished Loading north
Finished north setup

++++++++ Session Characteristics +++++++

Area: north
Gal Type: qso
Training Set: 62405
Validation Set: 15602
Test Samples: 19505
Number of features: 6
Device: cuda:0
Number of Workers: 8
Number of Trials: 30

+++++++++++++++++++++++++++++++++++++++

Trial Id: 0 | Model params: 44587 | Timestamp: 2021-08-19 16:28:38.779202

epoch 0 -0.28619318390536663 32.5389535979116
epoch 5 -0.20665236327261138 31.51676000365219
epoch 10 -0.0401008131568108 29.260934951364913
epoch 15 -0.048292958336432434 29.37594287527971
epoch 20 0.047738709504310806 27.998099075043626
epoch 25 0.10111932750698738 27.202041693732458
epoch 30 0.1516165493097711 26.426921510107558
epoch 35 0.13716432318646343 26.651062502356183
epoch 40 0.07155776523975443 27.645721256679092
epoch 45 0.08851139359453308 27.392148844976948
epoch 50 0.08426856748024403 27.455827749578777
epoch 55 0.05364766608177485 27.911097220392275
epoch 60 0.047488030393500136 28.00178402832827
epoch 65 0.047023041171336266 28.008618031214834
epoch 70 0.08497032251642056 27.44530558259251
epoch 75 0.07390935369968887 27.610688071753305
epoch 80 0.07838995592874609 27.543814213213693
[32m[I 2021-08-19 17:17:23,537][0m Trial 0 finished with value: 0.03458375422421811 and parameters: {'n_layers_fe': 2, 'fe_n_units_l0': 252, 'fe_dropout_l0': 0.42033384151450615, 'fe_n_units_l1': 56, 'fe_dropout_l1': 0.03267030617210709, 'n_units_l(Invariant)': 224, 'n_layers_mlp': 2, 'mlp_n_units_l0': 193, 'mlp_dropout_l0': 0.11259034725726186, 'mlp_n_units_l1': 14, 'mlp_dropout_l1': 0.40174922941101937, 'reduction': 'sum', 'lr': 0.0035078889228857602, 'criterion': 'L1Loss', 'batch_size': 32, 'no_epochs': 84}. Best is trial 0 with value: 0.03458375422421811.[0m

Trial Id: 1 | Model params: 111891 | Timestamp: 2021-08-19 17:17:23.537603

[32m[I 2021-08-19 17:18:24,319][0m Trial 1 pruned. [0m
++++++++++++++++++++
        NaN         
++++++++++++++++++++

Trial Id: 2 | Model params: 80398 | Timestamp: 2021-08-19 17:18:24.319450

epoch 0 -2.2341435233493403 51.59767410862132
epoch 5 -1.1655678780910566 42.22176470619641
epoch 10 -1.2033824447825574 42.58880194142733
epoch 15 -1.183362150289272 42.39487600362104
epoch 20 -1.546479351829404 45.78471975474735
epoch 25 -1.3353140416175213 43.845308083301
epoch 30 -1.5763921132601078 46.052844632414576
epoch 35 -2.109817317261532 50.596202204660145
epoch 40 -2.20719660801105 51.38226831766954
epoch 45 -2.51409012206777 53.784474326106114
epoch 50 -2.74903417903017 55.55334073330347
epoch 55 -2.62511615895697 54.62751491756284
[32m[I 2021-08-19 18:06:26,771][0m Trial 2 finished with value: -2.5885285090002004 and parameters: {'n_layers_fe': 4, 'fe_n_units_l0': 163, 'fe_dropout_l0': 0.2651849706268482, 'fe_n_units_l1': 13, 'fe_dropout_l1': 0.3048861729583727, 'fe_n_units_l2': 199, 'fe_dropout_l2': 0.13284661413996307, 'fe_n_units_l3': 157, 'fe_dropout_l3': 0.10344561579523048, 'n_units_l(Invariant)': 115, 'n_layers_mlp': 2, 'mlp_n_units_l0': 160, 'mlp_dropout_l0': 0.21236473634506742, 'mlp_n_units_l1': 86, 'mlp_dropout_l1': 0.03574139002370885, 'reduction': 'sum', 'lr': 1.5025459246575172e-05, 'criterion': 'L1Loss', 'batch_size': 32, 'no_epochs': 57}. Best is trial 0 with value: 0.03458375422421811.[0m

Trial Id: 3 | Model params: 64170 | Timestamp: 2021-08-19 18:06:26.771948

[32m[I 2021-08-19 18:07:04,461][0m Trial 3 pruned. [0m
++++++++++++++++++++
        NaN         
++++++++++++++++++++

Trial Id: 4 | Model params: 127078 | Timestamp: 2021-08-19 18:07:04.461613

[32m[I 2021-08-19 18:08:06,955][0m Trial 4 pruned. [0m
++++++++++++++++++++
        NaN         
++++++++++++++++++++

Trial Id: 5 | Model params: 158021 | Timestamp: 2021-08-19 18:08:06.956054

epoch 0 -3.00984038405306 57.45317362253013
epoch 5 -0.4151096185545229 34.13072567347035
epoch 10 -0.0519789046422352 29.42754254210302
epoch 15 0.05234828626315502 27.930252177077595
epoch 20 0.14877490211743627 26.471142793026633
epoch 25 0.13762532858333776 26.643941838753776
epoch 30 0.17782992392084118 26.0154482790378
epoch 35 0.1737059743590954 26.080612531954042
epoch 40 0.09819825191034426 27.246204825166345
epoch 45 0.15875522864179392 26.315502640398204
