Starting Loading north
Finished Loading north
Finished north setup

++++++++ Session Characteristics +++++++

Area: north
Gal Type: lrg
Training Set: 78007
Validation Set: 19505
Test Samples: 19505
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=120, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=120, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.00012625840029965784, weight decay: 0.11966102805969332, batch_size: 256

 Model params: 21062

epoch 0 -0.6161102995943595 15.216742485214725 0
epoch 1 -0.4095166246399733 14.210890507794028 0
epoch 2 -0.2870960183399922 13.579746581533865 0
epoch 3 -0.24703040376927854 13.366715763143104 0
epoch 4 -0.20445443950437459 13.136551731152503 0
epoch 5 -0.18890765083175354 13.0514947477265 0
epoch 6 -0.13997728892342476 12.780101165359262 0
epoch 7 -0.11446007931542157 12.636257002460182 0
epoch 8 -0.09718427839116339 12.53793401819489 0
epoch 9 -0.0699544915464243 12.381374078232925 0
epoch 10 -0.05455930239647189 12.29197577079484 0
epoch 11 -0.04439461013743551 12.232592344657338 0
epoch 12 -0.03568743113256878 12.181493699403056 0
epoch 13 -0.013704656710381569 12.051522413319017 0
epoch 14 -0.0062801158608207786 12.007307632052967 0
epoch 15 -0.021212491592378813 12.096068881799996 0
epoch 16 0.0014050344519980218 11.96136872071201 1
epoch 17 0.004397949474626017 11.943430404656405 0
epoch 18 -0.01838115039847743 12.079288892416184 0
epoch 19 0.007552448409386403 11.92449441062608 1
epoch 20 0.0014118882925758802 11.961327672310103 0
epoch 21 0.00456516980588062 11.942427359184649 1
epoch 22 -0.014995218752428041 12.059191456840914 2
epoch 23 0.012767219849516454 11.893124786494315 3
epoch 24 0.013148474843344138 11.89082808850965 0
epoch 25 -0.0006803340647831835 11.973851686080636 0
epoch 26 0.015189748494035316 11.878523806585298 1
epoch 27 0.015324816899469407 11.877709198754607 0
epoch 28 0.014797860271454577 11.880886998157944 0
epoch 29 0.015252475577580582 11.87814550171934 1
epoch 30 0.014020968164242698 11.885570477843341 2
epoch 31 0.01633381515015686 11.871622085085002 3
epoch 32 0.017087247921282245 11.867074717970546 0
epoch 33 0.01749019631981097 11.864641994962389 0
epoch 34 0.014936562085982263 11.880050642590671 0
epoch 35 0.01649081009134079 11.870674680868248 1
epoch 36 0.013385972578032646 11.889397166738156 2
epoch 37 0.002437469174788154 11.955183767637262 3
epoch 38 0.019174196243548547 11.854469768269322 4
epoch 39 0.01446788613537886 11.882876466641548 0
epoch 40 0.014594839858473874 11.882111081134 1
epoch 41 0.01657648981455606 11.870157604727313 2
epoch 42 0.018346230037878497 11.859472200827167 3
epoch 43 0.019338519419449862 11.853476704206049 4
epoch 44 0.01871403612145084 11.857250238858112 0
epoch 45 0.019020771318859375 11.855396895188829 1
epoch 46 0.019146885534783498 11.854634808644736 2
epoch 47 0.020440708073603542 11.846813629939746 3
epoch 48 0.016700420156440687 11.869409646689016 0
epoch 49 0.0211651165548149 11.84243231297165 1
epoch 50 0.01837528193205873 11.859296709889758 0
epoch 51 0.01801213841271898 11.861490128840376 1
epoch 52 0.021006803683953135 11.843389948262969 2
epoch 53 0.015533001991447914 11.876453509193565 3
epoch 54 0.02192219491328995 11.837851671407263 4
epoch 55 0.02089473944063769 11.844067778588375 0
epoch 56 0.02030390118292258 11.847640873969883 1
epoch 57 0.019370955562910575 11.853280671090745 2
epoch 58 0.02239829294812634 11.83497017061558 3
epoch 59 0.01968895115536995 11.851358641219068 0
epoch 60 0.022543215783415893 11.834092910996375 1
epoch 61 0.01689048392611836 11.868262461328623 0
epoch 62 0.0201449086171247 11.848602197795154 1
epoch 63 0.020013628302299802 11.849395905019374 2
epoch 64 0.022438839146660783 11.834724739361507 3
epoch 65 0.021798256483594236 11.838601672206792 4
epoch 66 0.02219735039016002 11.836186426157031 5
epoch 67 0.02210308360651725 11.836756956588221 6
epoch 68 0.011223801373971276 11.902417883385153 7
Target 19505 0 131.0 1.0 35.255216611125356
[37. 27. 21. ... 27. 25. 32.]
Prediction 19505 0 42.85247802734375 14.035449981689453 34.03713671565209
[37.13718033 32.81822586 33.29800415 ... 32.6945076  33.1686821
 30.91647339]

 XXXXXX======== TRIAL north - lrg ended

Test Set - R-squared:  0.011223801373971276
Test Set - RMSE:  11.902417883385153
Test Set - MAE:  8.637900926051644



Starting Loading north
Finished Loading north
Finished north setup

++++++++ Session Characteristics +++++++

Area: north
Gal Type: elg
Training Set: 78007
Validation Set: 19505
Test Samples: 19505
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.0004377981116963404, weight decay: 0, batch_size: 32

 Model params: 17342

epoch 0 -0.4542126196965195 27.007700333449936 0
epoch 1 -0.0067870617638232655 22.47203820468475 0
epoch 2 0.11741635430733954 21.04028360751492 0
epoch 3 0.09891467626470274 21.259674444950367 0
epoch 4 0.14746181634688726 20.679049430069963 1
epoch 5 0.15364892947828024 20.60387590838045 0
epoch 6 0.15314287637392043 20.610034757591418 0
epoch 7 0.15139026867899685 20.63135041708192 1
epoch 8 0.13956163396017196 20.774641357277797 2
epoch 9 0.14825436683911075 20.66943519701432 3
epoch 10 0.1438152121223366 20.723228005011883 4
epoch 11 0.1698369884850871 20.405880603744198 5
epoch 12 0.17117840283294306 20.38938757339433 0
epoch 13 0.14315637711402962 20.731199743568133 0
epoch 14 0.17031627500836488 20.39998918514573 1
epoch 15 0.17441606315422986 20.349524648854338 2
epoch 16 0.1775726437493108 20.310584676069052 0
epoch 17 0.14914964765768746 20.658569386027473 0
epoch 18 0.18466646533283337 20.22280081363929 1
epoch 19 0.15688443366513216 20.564455056133973 0
epoch 20 0.18601167564860144 20.206111232478037 1
epoch 21 0.18620695814548838 20.203687280912852 0
epoch 22 0.18837934010177182 20.176702867644632 0
epoch 23 0.19091390344917158 20.145173902568327 0
epoch 24 0.1864319750192056 20.200893889585146 0
epoch 25 0.18680898540854218 20.196212763265486 1
epoch 26 0.1923882133695305 20.126811350006108 2
epoch 27 0.19504198239557713 20.09371632907963 0
epoch 28 0.1823178177567213 20.251906740779322 0
epoch 29 0.19346993860364115 20.11332778322261 1
epoch 30 0.1996995718370671 20.035499595741463 2
epoch 31 0.18378744986555218 20.23369903221504 0
epoch 32 0.21126057730199477 19.89025842550059 1
epoch 33 0.20074907963507693 20.02235808622626 0
epoch 34 0.21257373330174234 19.873694087681088 1
epoch 35 0.16442315766023308 20.472310002154128 0
epoch 36 0.19226550283633503 20.12834035068718 1
epoch 37 0.22579301983612798 19.706168543659253 2
epoch 38 0.2354052457887662 19.583454742298454 0
epoch 39 0.20261539455524602 19.998967518558327 0
epoch 40 0.1995920751768987 20.036845138550955 1
epoch 41 0.22472449496982227 19.71976262853783 2
epoch 42 0.2364150214648315 19.570518850785174 3
epoch 43 0.23864157798080143 19.54196493789311 0
epoch 44 0.23228746833954506 19.62334171323714 0
epoch 45 0.22362718640366475 19.733713161607195 1
epoch 46 0.2324090455532445 19.6217878466714 2
epoch 47 0.16236898109697584 20.497459050593108 3
epoch 48 0.23149719006352953 19.63343918536326 4
epoch 49 0.2233338365939661 19.737440967485572 5
epoch 50 0.2381280159113569 19.54855468578798 6
epoch 51 0.17043188776139517 20.398567811550134 7
Target 19505 0 285.0 1.0 125.01307357087926
[ 63. 156.  95. ... 132. 139. 111.]
Prediction 19505 0 175.53866577148438 83.97389221191406 131.2501339112267
[102.31626129 143.25973511 122.11019135 ... 145.14616394 161.22555542
 130.53865051]

 XXXXXX======== TRIAL north - elg ended

Test Set - R-squared:  0.17043188776139517
Test Set - RMSE:  20.398567811550134
Test Set - MAE:  16.028511618834465



Starting Loading north
Finished Loading north
Finished north setup

++++++++ Session Characteristics +++++++

Area: north
Gal Type: qso
Training Set: 78007
Validation Set: 19505
Test Samples: 19505
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.0033982461411864624, weight decay: 0.006718087764096936, batch_size: 128

 Model params: 17342

epoch 0 -0.43949477632477607 34.854824288458865 0
epoch 1 0.10997309312677317 27.406868699712565 0
epoch 2 0.15025033170541846 26.779554811399944 0
epoch 3 0.12128925631707022 27.23208031581525 0
epoch 4 0.12275797447754144 27.20931231276241 1
epoch 5 0.14426235541043209 26.87374362971998 2
epoch 6 0.1508013787694058 26.77087037834977 3
epoch 7 0.13834769081696097 26.966456315007644 0
epoch 8 0.1031843179365094 27.511194546039256 1
epoch 9 0.14548047886508575 26.85460973073091 2
epoch 10 0.15176514818299114 26.75567471620638 3
epoch 11 0.15211248623406903 26.75019615360939 0
epoch 12 0.1638542075775511 26.564329310121966 0
epoch 13 0.1586014809025572 26.64763816944555 0
epoch 14 0.1620935195847234 26.59228310721173 1
epoch 15 0.15575782160069485 26.69263045611296 2
epoch 16 0.133368573970029 27.044257838361453 3
epoch 17 0.1586598234125498 26.646714280817065 4
epoch 18 0.15314899166267837 26.733840680778666 5
epoch 19 0.1458835644223645 26.848275187228307 6
epoch 20 0.1654193986474305 26.539454624793905 7
epoch 21 0.1653648968132675 26.540321183001865 0
epoch 22 0.1617441263791164 26.597826801462084 1
epoch 23 0.1632138801196067 26.57449895654277 2
epoch 24 0.15833270474068695 26.651893987504405 3
epoch 25 0.1209543292787596 27.237269674843375 4
epoch 26 0.1603254438379571 26.620324657899108 5
epoch 27 0.16766134981779046 26.503783909376303 6
epoch 28 0.1542290258979211 26.71678769581896 0
epoch 29 0.16621923717403952 26.526734243685983 1
epoch 30 0.14685291000875933 26.833035669378503 2
epoch 31 0.1401275622249234 26.93859029768207 3
epoch 32 0.16970555197142645 26.4712175983806 4
epoch 33 0.16729727045345988 26.509579883054872 0
epoch 34 0.16694845407118808 26.51513168878534 1
epoch 35 0.15808871535246516 26.65575674191116 2
epoch 36 0.1787428035090376 26.32676186957399 3
epoch 37 0.17980513586634894 26.30972894654018 0
epoch 38 0.17599502450434612 26.37076739889378 0
epoch 39 0.1714481608266567 26.443424321290625 1
epoch 40 0.18026462001616927 26.302358382829325 2
epoch 41 0.16093175969934503 26.61071186227585 0
epoch 42 0.1797635530796292 26.310395872187453 1
epoch 43 0.15723209495827495 26.669314025212607 2
epoch 44 0.18649279275775088 26.202248041007547 3
epoch 45 0.1525903641061671 26.74265675226254 0
epoch 46 0.18209031533990783 26.273052059717845 1
epoch 47 0.174033001305973 26.40214420863414 2
epoch 48 0.17870379625957744 26.32738708319667 3
epoch 49 0.1645084132525667 26.553935228285916 4
epoch 50 0.17811463443985032 26.336828445804574 5
epoch 51 0.1573378944751782 26.667639964606295 6
epoch 52 0.16979973906036416 26.46971613245878 7
Target 19505 0 314.0 1.0 153.38815688285055
[166. 146. 114. ... 168. 134. 150.]
Prediction 19505 0 195.0817108154297 9.876794815063477 149.23141811569357
[160.35491943 139.24978638 160.88934326 ... 147.58210754 133.95664978
 125.38116455]

 XXXXXX======== TRIAL north - qso ended

Test Set - R-squared:  0.16979973906036416
Test Set - RMSE:  26.46971613245878
Test Set - MAE:  20.47242623196905



Starting Loading south
Finished Loading south
Finished south setup

++++++++ Session Characteristics +++++++

Area: south
Gal Type: lrg
Training Set: 148560
Validation Set: 37139
Test Samples: 37139
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 7.458723170594822e-05, weight decay: 0, batch_size: 128

 Model params: 17342

epoch 0 -0.48446570495007024 14.398056281666669 0
epoch 1 -0.3321975788210194 13.63964611432642 0
epoch 2 -0.20787291905474303 12.987614958497367 0
epoch 3 -0.05673876202596895 12.147938973275458 0
epoch 4 -0.02802455250802338 11.981757513033838 0
epoch 5 0.008439839721052 11.767340408906522 0
epoch 6 0.012581255535861646 11.74274056917674 0
epoch 7 0.014955912907602453 11.728611927679522 0
epoch 8 0.01621415191222786 11.721118804901078 0
epoch 9 0.01623160180310168 11.721014852830898 0
epoch 10 0.017303407359567924 11.714628150201422 0
epoch 11 0.017675485188504703 11.712410188875538 0
epoch 12 0.02153746151217517 11.689364038734455 0
epoch 13 0.02340189052156294 11.678221874166292 0
epoch 14 0.01819982211210036 11.70928389570124 0
epoch 15 0.025182944753157965 11.667568035014442 1
epoch 16 0.025556865953060504 11.665330092282847 0
epoch 17 0.02586846755850114 11.663464808361342 0
epoch 18 0.026856055693038616 11.657551017459395 0
epoch 19 0.025764016574687187 11.66409009749232 0
epoch 20 0.02787163202240661 11.651466499648 1
epoch 21 0.026810058082795907 11.657826523028227 0
epoch 22 0.029390817754046616 11.642358822578952 1
epoch 23 0.02779847736345753 11.651904889808844 0
epoch 24 0.030317542619362037 11.63679950982926 1
epoch 25 0.02465919506165337 11.670701989499758 0
epoch 26 0.025352199264925934 11.66655508891998 1
epoch 27 0.03272003378391386 11.622374866958987 2
epoch 28 0.033731416756353494 11.616297130050313 0
epoch 29 0.032837976833808735 11.621666271632437 0
epoch 30 0.03395523549335211 11.614951698990877 1
epoch 31 0.03505048771808905 11.608365612148917 0
epoch 32 0.033240337437219325 11.619248586186277 0
epoch 33 0.036006738646050196 11.602612325722019 1
epoch 34 0.034850394899096915 11.609569110451275 0
epoch 35 0.03636733646265178 11.600442047062018 1
epoch 36 0.03802171658825271 11.59047985624879 0
epoch 37 0.03761822207161092 11.592910370975371 0
epoch 38 0.030012896310003034 11.638627339959346 1
epoch 39 0.03961890020342007 11.580853955541595 2
epoch 40 0.039736840494738024 11.580142836161164 0
epoch 41 0.04010296197576424 11.577935033433217 0
epoch 42 0.039797706773381236 11.579775826678897 0
epoch 43 0.04031276209535606 11.576669697256781 1
epoch 44 0.03374593932433234 11.616209835947242 0
epoch 45 0.04028445567790073 11.576840425602388 1
epoch 46 0.038762073939849984 11.586018867472387 2
epoch 47 0.041910461665117915 11.567029189396846 3
epoch 48 0.0394468257717564 11.581891397661378 0
epoch 49 0.041107605114111045 11.571874624036168 1
epoch 50 0.04015010620709525 11.57765071150697 2
epoch 51 0.04156353901829224 11.569123200981673 3
epoch 52 0.04229938137995193 11.564681234355513 4
epoch 53 0.041207274692382834 11.571273204188564 0
epoch 54 0.041576818676044125 11.569043052461126 1
epoch 55 0.0381207773924529 11.58988306948381 2
epoch 56 0.042947582700935794 11.560766905410524 3
epoch 57 0.042532860323880706 11.563271464906302 0
epoch 58 0.03898194513435416 11.584693712987294 1
epoch 59 0.043153704886335964 11.559521906278682 2
epoch 60 0.039986200011570494 11.57863918256307 0
epoch 61 0.040103506383637466 11.577931750206147 1
epoch 62 0.044628240641450434 11.550611645439597 2
epoch 63 0.044031351344833936 11.554219330022574 0
epoch 64 0.04450367364401531 11.551364639287048 1
epoch 65 0.04281472735843794 11.561569294245253 2
epoch 66 0.0438548113357643 11.555286147341617 3
epoch 67 0.04130294515729416 11.570695886132913 4
epoch 68 0.04190831805196682 11.567042129326273 5
epoch 69 0.04315546059359543 11.559511301050895 6
epoch 70 0.0449049040085735 11.548939070096141 7
epoch 71 0.04494776179523985 11.548679950600254 0
epoch 72 0.0446627038678622 11.550403310343645 0
epoch 73 0.0436990125667045 11.55622754517947 1
epoch 74 0.04459047043516673 11.550839967382567 2
epoch 75 0.044480237127762945 11.551506304973023 3
epoch 76 0.04360545814654515 11.556792801171555 4
epoch 77 0.045543181042192904 11.545079425873777 5
epoch 78 0.045914036402492364 11.542836280617358 0
epoch 79 0.04345794744769926 11.557684004947511 0
epoch 80 0.04603578241395534 11.542099796083882 1
epoch 81 0.045613492661756405 11.54465417448124 0
epoch 82 0.042316998653812665 11.564574865470798 1
epoch 83 0.04457365746935993 11.550941600774859 2
epoch 84 0.046429356407128974 11.539718606696455 3
epoch 85 0.041092336720844336 11.571966752845515 0
epoch 86 0.04104630931433306 11.57224447574153 1
epoch 87 0.0418662294652673 11.567296194317198 2
epoch 88 0.04412407272396068 11.55365898260363 3
epoch 89 0.045962762167050975 11.542541526933965 4
epoch 90 0.04240072634577208 11.564069324323583 5
epoch 91 0.0455048600188821 11.545311188489103 6
epoch 92 0.044682257804539605 11.55028510234969 7
Target 37139 0 129.0 1.0 33.86528985702361
[51. 35. 31. ... 28. 22. 36.]
Prediction 37139 0 42.77854919433594 -1.3218653202056885 33.89562338490235
[33.69371796 33.75235367 35.29465103 ... 33.07236099 35.03711319
 33.90889359]

 XXXXXX======== TRIAL south - lrg ended

Test Set - R-squared:  0.044682257804539605
Test Set - RMSE:  11.55028510234969
Test Set - MAE:  8.420855470960028



Starting Loading south
Finished Loading south
Finished south setup

++++++++ Session Characteristics +++++++

Area: south
Gal Type: elg
Training Set: 148560
Validation Set: 37139
Test Samples: 37139
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.0012133886263240518, weight decay: 0, batch_size: 256

 Model params: 17342

epoch 0 -0.5751370766667019 29.18726596760677 0
epoch 1 0.058814729792045606 22.561698916503524 0
epoch 2 0.07817955353151362 22.3283898796805 0
epoch 3 0.07922707840159915 22.31569966851042 0
epoch 4 0.09475413112973285 22.12674415328805 0
epoch 5 0.09688580154636317 22.100676801075775 0
epoch 6 0.09114127642486136 22.17085432930773 0
epoch 7 0.09674490145526304 22.102400761307845 1
epoch 8 0.10606228995705436 21.988108304560015 2
epoch 9 0.10074354977185762 22.053423591075262 0
epoch 10 0.10138972911468458 22.045498695083843 1
epoch 11 0.10724893867828156 21.973509510368185 2
epoch 12 0.10833103780110409 21.960188481741625 0
epoch 13 0.11078032863703635 21.93000694701251 0
epoch 14 0.02226182989188963 22.995641184480284 0
epoch 15 0.08949572379997972 22.190916197905143 1
epoch 16 0.08217024568135045 22.280006066043587 2
epoch 17 0.11258633126411877 21.90772573708065 3
epoch 18 0.10545565597304751 21.99556770101111 0
epoch 19 0.08611557231560818 22.23206876234909 1
epoch 20 0.10985150461177784 21.941457324055182 2
epoch 21 0.11680732408022165 21.855561464683813 3
epoch 22 0.10809255105710347 21.963125033270146 0
epoch 23 0.11500165378729454 21.877891692801988 1
epoch 24 0.10615954869484212 21.98691213965594 2
epoch 25 0.11566684911901426 21.869668057605246 3
epoch 26 0.11715929073240539 21.85120613229014 4
epoch 27 0.10622356762323082 21.98612474870931 0
epoch 28 0.12462280811651272 21.758645264245086 1
epoch 29 0.12451026124624243 21.760043969135452 0
epoch 30 0.1285126655703437 21.710247691241854 1
epoch 31 0.10883438538559265 21.953989337957253 0
epoch 32 0.11919784947185774 21.825963350054387 1
epoch 33 0.11517020176850301 21.87580827079315 2
epoch 34 0.10874436745707705 21.955098112076755 3
epoch 35 0.12703957863762672 21.72858850803403 4
epoch 36 0.12153566367500401 21.79697900345287 5
epoch 37 0.12481287257588858 21.75628298562277 6
epoch 38 0.13390795334300865 21.642940409628398 7
epoch 39 0.1350727063798628 21.628382394828318 0
epoch 40 0.13314437313188943 21.652478933945243 0
epoch 41 0.1354569554966707 21.623577592090758 1
epoch 42 0.13207098277679208 21.665880457234564 0
epoch 43 0.13427860574250639 21.638308762054976 1
epoch 44 0.13346592965804283 21.648462612489936 2
epoch 45 0.1351390548849516 21.62755282315743 3
epoch 46 0.13024359415725928 21.688676771612684 4
epoch 47 0.13707369049037166 21.603349591811185 5
epoch 48 0.13507675157976473 21.628331817610274 0
epoch 49 0.12102245068172468 21.803345146630875 1
epoch 50 0.13823493426873878 21.58880883638864 2
epoch 51 0.13694030242116384 21.60501921163233 0
epoch 52 0.1278572447225953 21.718409986904643 1
epoch 53 0.13188805769406853 21.66816349196155 2
epoch 54 0.1354014898782927 21.624271222022962 3
epoch 55 0.13427411234392506 21.63836491719933 4
epoch 56 0.13842721855754625 21.58640016347633 5
epoch 57 0.13741471502691038 21.59908039742982 0
epoch 58 0.13148402793487757 21.673205217611237 1
epoch 59 0.1234283091686923 21.77348562034629 2
epoch 60 0.12242017454808285 21.786002735169532 3
epoch 61 0.14093808228968918 21.55492281359493 4
epoch 62 0.13400272274891156 21.64175627179681 0
epoch 63 0.13602869112655047 21.616426407158336 1
epoch 64 0.1393434450977712 21.574919245018858 2
epoch 65 0.1436354362668938 21.521056239743363 3
epoch 66 0.14092143218135766 21.555131698457338 0
epoch 67 0.13922720333879257 21.57637616873236 1
epoch 68 0.13164380118424157 21.671211611389285 2
epoch 69 0.14422398330494224 21.513659663896703 3
epoch 70 0.1415477484069877 21.547272818748993 0
epoch 71 0.1449546907017033 21.50447294502427 1
epoch 72 0.14452648292342685 21.509857004721948 0
epoch 73 0.14493120819441152 21.50476823667149 1
epoch 74 0.13553409687629092 21.622612857119083 2
epoch 75 0.14615088424080125 21.489425488296636 3
epoch 76 0.14515088879105575 21.502005602933593 0
epoch 77 0.14613194818304398 21.489663775564615 1
epoch 78 0.13713622738629838 21.602566772416182 2
epoch 79 0.1397354066836487 21.570005843409188 3
epoch 80 0.10973552984672452 21.942886620679733 4
epoch 81 0.14429526079 21.512763710132724 5
epoch 82 0.13896962816140634 21.57960415365897 6
epoch 83 0.14167327342313718 21.545697413335624 7
Target 37139 0 274.0 1.0 130.19173914214167
[ 97. 150. 113. ... 133. 123. 139.]
Prediction 37139 0 166.4380340576172 70.97270965576172 131.30862354118435
[125.68399811 135.33244324 126.04087067 ... 136.4863739  115.14585114
 130.85643005]

 XXXXXX======== TRIAL south - elg ended

Test Set - R-squared:  0.14167327342313718
Test Set - RMSE:  21.545697413335624
Test Set - MAE:  16.30936374714123



Starting Loading south
Finished Loading south
Finished south setup

++++++++ Session Characteristics +++++++

Area: south
Gal Type: qso
Training Set: 148560
Validation Set: 37139
Test Samples: 37139
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.0008379365544368044, weight decay: 0, batch_size: 256

 Model params: 17342

epoch 0 -0.8096580645809655 37.84855142389866 0
epoch 1 0.07324835397168628 27.085239749810633 0
epoch 2 0.07041825652675726 27.126564432790786 0
epoch 3 0.08274938087461337 26.946043585757046 1
epoch 4 0.03314608885831971 27.665048144389345 0
epoch 5 0.08062084832196537 26.97729038684697 1
epoch 6 0.08907771807291698 26.852929017860795 2
epoch 7 0.08672685805383118 26.887556999815455 0
epoch 8 0.07404433536256183 27.073605576735268 1
epoch 9 0.07717371643279591 27.027817567258563 2
epoch 10 0.09126613598763611 26.820653614478985 3
epoch 11 0.05797424264048445 27.307528147148894 0
epoch 12 0.09472107802448027 26.769619945305127 1
epoch 13 0.06688899604780763 27.178010158663614 0
epoch 14 0.09898301046284308 26.70653170457166 1
epoch 15 0.09908914734168384 26.704958686841273 0
epoch 16 0.0949036323650081 26.766920690639292 0
epoch 17 0.09773002071019399 26.725094831171788 1
epoch 18 0.10249343000806466 26.654455758511272 2
epoch 19 0.08792773145541022 26.86987380533475 0
epoch 20 0.09026178175241217 26.83547093297684 1
epoch 21 0.04502482782780115 27.494576937580113 2
epoch 22 0.08045471293906059 26.97972772730921 3
epoch 23 0.07605124521446804 27.044250089900906 4
epoch 24 0.0975539068888086 26.727702935749804 5
epoch 25 0.08439528394565943 26.921856908547223 6
epoch 26 0.10476475482982484 26.62070710398438 7
epoch 27 0.1061676296388746 26.59984098996121 0
epoch 28 0.10452997107030748 26.624197639011342 0
epoch 29 0.09734603534835007 26.730781019260842 1
epoch 30 0.09873575130564294 26.71019588717166 2
epoch 31 0.10055261858869002 26.683259634433156 3
epoch 32 0.10236929304769926 26.656299025638138 4
epoch 33 0.10554422776957606 26.60911538011184 5
epoch 34 0.10256051097882735 26.65345964314118 6
epoch 35 0.10644678271502883 26.595686963135954 7
epoch 36 0.10655205254361722 26.59412029322889 0
epoch 37 0.09718344311075278 26.73318837688005 0
epoch 38 0.10318286724981052 26.644216220712668 1
epoch 39 0.10541879815252242 26.61098101408565 2
epoch 40 0.09581688788772358 26.753413174487044 3
epoch 41 0.11137994014326502 26.522170190973828 4
epoch 42 0.09821024073389584 26.71798186382839 0
epoch 43 0.10626173833789576 26.598440647790422 1
epoch 44 0.11128638841943761 26.523566248497744 2
epoch 45 0.09369070158154091 26.784850025770947 3
epoch 46 0.10200449833104619 26.66171499972177 4
epoch 47 0.11172583056545726 26.51700788486445 5
epoch 48 0.11061349587902691 26.533605552832572 0
epoch 49 0.10986285685222308 26.54480032531175 1
epoch 50 0.10892408669953146 26.558794179894033 2
epoch 51 0.1107060508875175 26.532224892134977 3
epoch 52 0.1129076769272529 26.499361609965977 4
epoch 53 0.11264653087850363 26.50326182089892 0
epoch 54 0.1082153238798299 26.56935452830129 1
epoch 55 0.10020461790509128 26.688421078437077 2
epoch 56 0.11197773911518771 26.513247596156663 3
epoch 57 0.11334071650521937 26.492892907192555 4
epoch 58 0.09744298373930727 26.729345488094737 0
epoch 59 0.10432183577744358 26.627291608117215 1
epoch 60 0.11119306633567516 26.524958805932666 2
epoch 61 0.11566836006712877 26.458095698657598 3
epoch 62 0.11345063117092202 26.491250761346706 0
epoch 63 0.0755510134706523 27.051570063935532 1
epoch 64 0.1128797024167959 26.499779436163426 2
epoch 65 0.10237116133469026 26.65627128503043 3
epoch 66 0.11056138592074805 26.534382855399922 4
epoch 67 0.10935586322814139 26.55235878349358 5
epoch 68 0.11375229560825773 26.486743314574827 6
epoch 69 0.11309983387774969 26.496491383177524 7
Target 37139 0 344.0 1.0 158.8338135114031
[166. 176. 138. ... 178. 189. 186.]
Prediction 37139 0 205.6060028076172 50.66825485229492 157.03591012730024
[165.20783997 151.85568237 157.60786438 ... 170.2497406  159.43269348
 159.01313782]

 XXXXXX======== TRIAL south - qso ended

Test Set - R-squared:  0.11309983387774969
Test Set - RMSE:  26.496491383177524
Test Set - MAE:  19.909753742278106



Starting Loading des
Finished Loading des
Finished des setup

++++++++ Session Characteristics +++++++

Area: des
Gal Type: lrg
Training Set: 69272
Validation Set: 17317
Test Samples: 17317
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.00471120213385988, weight decay: 0, batch_size: 128

 Model params: 17342

epoch 0 -0.19331862554343915 11.137608115762468 0
epoch 1 -0.007332868110655699 10.232935238920497 0
epoch 2 -0.0004886040221181442 10.198112448612285 0
epoch 3 -0.07063438452046888 10.549559278711918 0
epoch 4 -0.007449199343338986 10.233526094059615 1
epoch 5 0.004663092057937357 10.171822602950646 2
epoch 6 0.005064015095067931 10.169773784741874 0
epoch 7 -0.0028164216917969664 10.20996943220505 0
epoch 8 0.0006807698690248776 10.192150914898443 1
epoch 9 -0.006722835660097681 10.229836279215126 2
epoch 10 0.0024533318827970607 10.183107639513599 3
epoch 11 -0.008634503666634208 10.2395444009954 4
epoch 12 0.002181125883584878 10.184496904802337 5
epoch 13 -0.009491436485167482 10.243893220456114 6
epoch 14 0.0051223150669026385 10.169475822752398 7
epoch 15 -0.021058591973021512 10.302415362453413 0
epoch 16 0.0052715082284175985 10.16871328020213 1
epoch 17 0.004073058484451053 10.174837073530275 0
epoch 18 -0.0014744628665530612 10.203135706154567 1
epoch 19 0.0021255562949250573 10.184780493557291 2
epoch 20 -0.012273959726888162 10.258001441300271 3
epoch 21 0.004065618963687734 10.174875076202538 4
epoch 22 0.005384196789967377 10.16813727874186 5
epoch 23 0.004918865107317649 10.170515585585571 0
epoch 24 0.003406086313405332 10.17824354697163 1
epoch 25 0.004010740493036513 10.175155402849573 2
epoch 26 -0.0005238748201557009 10.198292206978852 3
epoch 27 0.0037649965820661935 10.176410601256778 4
epoch 28 -0.005748749219433469 10.2248859810549 5
epoch 29 -0.000862473952606857 10.200017723418885 6
epoch 30 0.00435652932377617 10.173388937752573 7
Target 17317 0 105.0 4.0 32.608765952532195
[26. 33. 36. ... 29. 25. 29.]
Prediction 17317 0 39.63713836669922 31.729793548583984 32.992117873459094
[32.92676544 32.42195892 32.83499146 ... 34.02024841 32.09103394
 32.697052  ]

 XXXXXX======== TRIAL des - lrg ended

Test Set - R-squared:  0.00435652932377617
Test Set - RMSE:  10.173388937752573
Test Set - MAE:  7.783041951011591



Starting Loading des
Finished Loading des
Finished des setup

++++++++ Session Characteristics +++++++

Area: des
Gal Type: elg
Training Set: 69272
Validation Set: 17317
Test Samples: 17317
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.00471120213385988, weight decay: 0, batch_size: 128

 Model params: 17342

epoch 0 -1.0479894682249968 26.546064784311813 0
epoch 1 -0.056851898237847864 19.069677846214393 0
epoch 2 -0.0001356640052319058 18.550932599766824 0
epoch 3 0.0030282200324804887 18.521566838010045 0
epoch 4 -0.009913943240830614 18.6413978157914 0
epoch 5 -0.14727476439699427 19.868725553488453 1
epoch 6 -0.0035675694567189886 18.582733547786955 2
epoch 7 -0.0021207991197200737 18.569334029406413 3
epoch 8 -0.0030182534204856726 18.577647098667423 4
epoch 9 0.006695173745979388 18.48747344806227 5
epoch 10 -0.007305366503328914 18.61730717000531 0
epoch 11 -0.03983520242176719 18.915531479559764 1
epoch 12 -0.026920351540796528 18.797698122244626 2
epoch 13 -0.07924611748919586 19.270657732885777 3
epoch 14 0.00828719897877983 18.472652052761163 4
epoch 15 -0.010164085698790792 18.643706287911773 0
epoch 16 0.00459038206901774 18.50705036315028 1
epoch 17 0.004469448863215653 18.508174548066954 2
epoch 18 0.003829380854282971 18.514123429736095 3
epoch 19 -0.04726148774708472 18.9829566924688 4
epoch 20 0.013112079766292695 18.427660692760472 5
epoch 21 -0.003177330610051099 18.579120233733843 0
epoch 22 0.01989337163983962 18.364239734904963 1
epoch 23 0.009295336209050209 18.463260370253305 0
epoch 24 0.022845345177056053 18.336563342891854 1
epoch 25 -0.05106327875795058 19.017381645548518 0
epoch 26 0.03167951075439801 18.253487433562896 1
epoch 27 0.01461963168975644 18.41358043492739 0
epoch 28 0.03294366169433394 18.24156849779733 1
epoch 29 0.023650624112447227 18.3290061503913 0
epoch 30 0.029165170952729635 18.277170561241245 1
epoch 31 0.028351918404814436 18.284824203015635 2
epoch 32 0.02953798580761835 18.27366087309377 3
epoch 33 0.02501553181038696 18.316189964032716 4
epoch 34 0.022976918315305794 18.335328799111625 5
epoch 35 0.002874391951175892 18.52299567845119 6
epoch 36 -0.03414625354924716 18.86371698126803 7
Target 17317 0 226.0 8.0 124.32580701045215
[127. 121. 133. ... 135. 117. 110.]
Prediction 17317 0 124.56657409667969 104.06048583984375 120.35504974789946
[122.06452179 118.25634766 122.52085876 ... 116.17469788 123.58399963
 119.40032196]

 XXXXXX======== TRIAL des - elg ended

Test Set - R-squared:  -0.03414625354924716
Test Set - RMSE:  18.86371698126803
Test Set - MAE:  14.770413576678907



Starting Loading des
Finished Loading des
Finished des setup

++++++++ Session Characteristics +++++++

Area: des
Gal Type: qso
Training Set: 69272
Validation Set: 17317
Test Samples: 17317
Number of features: 6
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
VarMultiSetNet(
  (feature_extractor): Sequential(
    (0): Linear(in_features=6, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=60, bias=True)
    (7): ReLU()
  )
  (adder): InvLinear(in_features=60, out_features=1, bias=True, reduction=sum)
  (mlp): Sequential(
    (0): Linear(in_features=66, out_features=60, bias=True)
    (1): ReLU()
    (2): Dropout(p=0, inplace=False)
    (3): Linear(in_features=60, out_features=60, bias=True)
    (4): ReLU()
    (5): Dropout(p=0, inplace=False)
    (6): Linear(in_features=60, out_features=30, bias=True)
    (7): Linear(in_features=30, out_features=1, bias=True)
  )
)
Learning Rate: 0.00471120213385988, weight decay: 0, batch_size: 128

 Model params: 17342

epoch 0 -0.9787887890609026 34.61791471598414 0
epoch 1 -0.008862693073837136 24.718221197580366 0
epoch 2 -0.05635583922559495 25.293346975441054 0
epoch 3 -0.009606364054799421 24.727329888793296 1
epoch 4 -0.007487460619064024 24.701368115067975 2
epoch 5 0.009301381342255444 24.494690808031955 0
epoch 6 -0.13968315203077308 26.27200675771231 0
epoch 7 -0.0712947061652287 25.471566947423824 1
epoch 8 0.001032700086102789 24.596698587378924 2
epoch 9 -0.025571415420468258 24.92207146016256 3
epoch 10 -0.09522891504964237 25.754530287770738 4
epoch 11 -0.06963045433817738 25.45177427133469 5
epoch 12 0.008276444317999676 24.507358144546405 6
epoch 13 0.005312652537648788 24.543951265416666 7
Target 17317 0 332.0 19.0 165.85898250274298
[138. 178. 199. ... 158. 166. 161.]
Prediction 17317 0 177.6887969970703 157.51678466796875 167.53757826048488
[166.42591858 165.95066833 169.38442993 ... 166.12738037 164.20272827
 165.97395325]

 XXXXXX======== TRIAL des - qso ended

Test Set - R-squared:  0.005312652537648788
Test Set - RMSE:  24.543951265416666
Test Set - MAE:  19.190314370283264



