{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First attempt at building a Neural Network to learn a non-linear F(s)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_geometric = pd.read_csv('../bricks_data/dataset_geometric.csv')\n",
    "df_kitanidis = pd.read_csv('../bricks_data/dataset_kitanidis.csv')\n",
    "df_kitanidis.drop('pixel_id', axis=1, inplace=True)\n",
    "df_geometric.drop('pixel_id', axis=1, inplace=True)\n",
    "\n",
    "train_df_geo, test_df_geo = train_test_split(df_geometric, test_size=0.33, random_state=44, shuffle=True)\n",
    "train_df_kit, test_df_kit = train_test_split(df_kitanidis, test_size=0.33, random_state=44, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        lrg  elg  qso  stellar       EBV   airmass      fwhm  ccdskysb_g  \\\n89136    33  108  135       14  0.018107  1.319964  3.886310   23.432305   \n161006   35  124  147       20  0.027707  1.291452  4.266571   23.534226   \n86817    26   82  116       15  0.147090  1.324597  5.368878   23.549151   \n116131   11   73   71        7  0.022910  1.476976  4.209666   23.492786   \n34538    12   59   68        8  0.010726  1.667206  4.654831   23.515421   \n\n        ccdskysb_r  ccdskysb_z   exptime_g  exptime_r   exptime_z  \\\n89136    22.669881   20.389898  103.560000  45.820000   79.306667   \n161006   22.664447   20.069928   90.000000  90.000000   90.000000   \n86817    22.722929   20.304141  188.973333  81.126667  160.739333   \n116131   22.685325   20.136689  121.533333  53.413333  128.116667   \n34538    22.689333   19.506456  149.774994  96.747853  140.954691   \n\n           meansky_g     meansky_r     meansky_z  galdepth_g  galdepth_r  \\\n89136   1.315610e-01  2.650449e-01  2.247409e+00   23.790844   23.136869   \n161006  2.144951e+08  6.823467e+08  2.257909e+09   23.459292   23.163053   \n86817   1.058678e-01  2.296210e-01  2.123827e+00   24.115970   23.479475   \n116131  1.165547e-01  2.448748e-01  2.796967e+00   23.913834   23.310549   \n34538   1.897221e-01  4.977593e-01  3.323957e+00   23.723508   22.956473   \n\n        galdepth_z  \n89136    22.230731  \n161006   22.008386  \n86817    22.420954  \n116131   22.329167  \n34538    22.234153  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lrg</th>\n      <th>elg</th>\n      <th>qso</th>\n      <th>stellar</th>\n      <th>EBV</th>\n      <th>airmass</th>\n      <th>fwhm</th>\n      <th>ccdskysb_g</th>\n      <th>ccdskysb_r</th>\n      <th>ccdskysb_z</th>\n      <th>exptime_g</th>\n      <th>exptime_r</th>\n      <th>exptime_z</th>\n      <th>meansky_g</th>\n      <th>meansky_r</th>\n      <th>meansky_z</th>\n      <th>galdepth_g</th>\n      <th>galdepth_r</th>\n      <th>galdepth_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89136</th>\n      <td>33</td>\n      <td>108</td>\n      <td>135</td>\n      <td>14</td>\n      <td>0.018107</td>\n      <td>1.319964</td>\n      <td>3.886310</td>\n      <td>23.432305</td>\n      <td>22.669881</td>\n      <td>20.389898</td>\n      <td>103.560000</td>\n      <td>45.820000</td>\n      <td>79.306667</td>\n      <td>1.315610e-01</td>\n      <td>2.650449e-01</td>\n      <td>2.247409e+00</td>\n      <td>23.790844</td>\n      <td>23.136869</td>\n      <td>22.230731</td>\n    </tr>\n    <tr>\n      <th>161006</th>\n      <td>35</td>\n      <td>124</td>\n      <td>147</td>\n      <td>20</td>\n      <td>0.027707</td>\n      <td>1.291452</td>\n      <td>4.266571</td>\n      <td>23.534226</td>\n      <td>22.664447</td>\n      <td>20.069928</td>\n      <td>90.000000</td>\n      <td>90.000000</td>\n      <td>90.000000</td>\n      <td>2.144951e+08</td>\n      <td>6.823467e+08</td>\n      <td>2.257909e+09</td>\n      <td>23.459292</td>\n      <td>23.163053</td>\n      <td>22.008386</td>\n    </tr>\n    <tr>\n      <th>86817</th>\n      <td>26</td>\n      <td>82</td>\n      <td>116</td>\n      <td>15</td>\n      <td>0.147090</td>\n      <td>1.324597</td>\n      <td>5.368878</td>\n      <td>23.549151</td>\n      <td>22.722929</td>\n      <td>20.304141</td>\n      <td>188.973333</td>\n      <td>81.126667</td>\n      <td>160.739333</td>\n      <td>1.058678e-01</td>\n      <td>2.296210e-01</td>\n      <td>2.123827e+00</td>\n      <td>24.115970</td>\n      <td>23.479475</td>\n      <td>22.420954</td>\n    </tr>\n    <tr>\n      <th>116131</th>\n      <td>11</td>\n      <td>73</td>\n      <td>71</td>\n      <td>7</td>\n      <td>0.022910</td>\n      <td>1.476976</td>\n      <td>4.209666</td>\n      <td>23.492786</td>\n      <td>22.685325</td>\n      <td>20.136689</td>\n      <td>121.533333</td>\n      <td>53.413333</td>\n      <td>128.116667</td>\n      <td>1.165547e-01</td>\n      <td>2.448748e-01</td>\n      <td>2.796967e+00</td>\n      <td>23.913834</td>\n      <td>23.310549</td>\n      <td>22.329167</td>\n    </tr>\n    <tr>\n      <th>34538</th>\n      <td>12</td>\n      <td>59</td>\n      <td>68</td>\n      <td>8</td>\n      <td>0.010726</td>\n      <td>1.667206</td>\n      <td>4.654831</td>\n      <td>23.515421</td>\n      <td>22.689333</td>\n      <td>19.506456</td>\n      <td>149.774994</td>\n      <td>96.747853</td>\n      <td>140.954691</td>\n      <td>1.897221e-01</td>\n      <td>4.977593e-01</td>\n      <td>3.323957e+00</td>\n      <td>23.723508</td>\n      <td>22.956473</td>\n      <td>22.234153</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_kit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrMatrix = df_kitanidis.corr()\n",
    "sns.heatmap(corrMatrix, annot=False)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining The Dataset Class Inheriting from Torch.dataset to be able to use a dataloader for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DensitySurvey(Dataset):\n",
    "    def __init__(self, df, galaxy_type, scaler_in=None, scaler_out=None):\n",
    "        self.data = df\n",
    "        # Extracting Targets and Input\n",
    "        self.target = self.data[galaxy_type].to_numpy(copy=True)\n",
    "        self.input = self.data.drop(columns=['lrg','elg','qso']).to_numpy(copy=True)\n",
    "\n",
    "        # Scaling, when scaler is passed (test-set) use the existing scaler\n",
    "        self.scaler_in = scaler_in\n",
    "        self.scaler_out = scaler_out\n",
    "        if self.scaler_in is None:\n",
    "            self.scaler_in = preprocessing.MinMaxScaler()\n",
    "            self.scaler_out = preprocessing.MinMaxScaler()\n",
    "            self.input = self.scaler_in.fit_transform(self.input)\n",
    "            self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        else:\n",
    "            self.input = self.scaler_in.transform(self.input)\n",
    "            self.target = self.scaler_out.transform(self.target.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.input[idx]).float(), torch.tensor(self.target[idx]).float()\n",
    "\n",
    "    def __getscaler__(self):\n",
    "        return self.scaler_in, self.scaler_out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Models and Hyperparameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_input_vars = 17, n_output_vars=1):\n",
    "        super().__init__() # call constructor of superclass\n",
    "        self.linear = nn.Linear(n_input_vars, n_output_vars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "model = LinearRegression().to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature = 16, n_hidden = 10, n_output = 1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature,n_hidden)\n",
    "        #self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.predict(out)\n",
    "        return out\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100 #very low, but computational power not sufficient for more iterations\n",
    "batch = 1024\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['LRG', 'ELG', 'QSO']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Epoch 40 :  0.04640561086125672\n",
      "Loss for Epoch 50 :  0.04622825689148158\n",
      "Loss for Epoch 60 :  0.046297409309772775\n",
      "Loss for Epoch 70 :  0.0462116924172733\n",
      "Loss for Epoch 80 :  0.04617627616971731\n",
      "Loss for Epoch 90 :  0.04685542525839992\n",
      "Loss for Epoch 100 :  0.04615518142236397\n",
      "Loss for Epoch 110 :  0.046161778329405934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-59efc8afe6a3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mtrainloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraindata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_no\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0;31m#Put Model into train mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    519\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 521\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    559\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    562\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-27-d618d4b457ac>\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getscaler__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  LRG\n",
      "\n",
      "Loss for Epoch 0 :  0.055659619509242475\n",
      "Loss for Epoch 10 :  0.047092226159293205\n",
      "Loss for Epoch 20 :  0.046443431347142905\n",
      "Loss for Epoch 30 :  0.046371587639441714\n",
      "Loss for Epoch 40 :  0.04637736457516439\n",
      "Loss for Epoch 50 :  0.04607162805041298\n",
      "Loss for Epoch 60 :  0.0463370299548842\n",
      "Loss for Epoch 70 :  0.04623115135473199\n",
      "Loss for Epoch 80 :  0.046324527414981276\n",
      "Loss for Epoch 90 :  0.046368653886020184\n",
      "\n",
      "2.65 minutes (1.59e+02 seconds) taken to train the model\n",
      "Neural Net R^2 for LRG, Kitanidis :  0.09512772957911253.\n",
      "Neural Net MSE for LRG, Kitanidis :  0.0004425338169648956.\n",
      "GALAXY TYPE:  ELG\n",
      "\n",
      "Loss for Epoch 0 :  0.1746001905121375\n",
      "Loss for Epoch 10 :  0.02544980352104176\n",
      "Loss for Epoch 20 :  0.024404774885624647\n",
      "Loss for Epoch 30 :  0.02381907326343935\n",
      "Loss for Epoch 40 :  0.023172870351118036\n",
      "Loss for Epoch 50 :  0.02286576878395863\n",
      "Loss for Epoch 60 :  0.022516714758239686\n",
      "Loss for Epoch 70 :  0.0221528021938866\n",
      "Loss for Epoch 80 :  0.022071532090194523\n",
      "Loss for Epoch 90 :  0.022091512524639256\n",
      "\n",
      "2.5471 minutes (1.53e+02 seconds) taken to train the model\n",
      "Neural Net R^2 for ELG, Kitanidis :  0.1948858337231706.\n",
      "Neural Net MSE for ELG, Kitanidis :  0.00021244693846851542.\n",
      "GALAXY TYPE:  QSO\n",
      "\n",
      "Loss for Epoch 0 :  2.1535041506867856\n",
      "Loss for Epoch 10 :  0.14095048781018704\n",
      "Loss for Epoch 20 :  0.13538011035416275\n",
      "Loss for Epoch 30 :  0.13296975335106254\n",
      "Loss for Epoch 40 :  0.1298959741834551\n",
      "Loss for Epoch 50 :  0.12625251000281423\n",
      "Loss for Epoch 60 :  0.12157459231093526\n",
      "Loss for Epoch 70 :  0.11920661648036912\n",
      "Loss for Epoch 80 :  0.11821262672310695\n",
      "Loss for Epoch 90 :  0.1182261569192633\n",
      "\n",
      "2.6413 minutes (1.58e+02 seconds) taken to train the model\n",
      "Neural Net R^2 for QSO, Kitanidis :  0.2368647529373613.\n",
      "Neural Net MSE for QSO, Kitanidis :  0.0011502293693739193.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata = DensitySurvey(train_df_kit, gal)\n",
    "    scaler_in, scaler_out = traindata.__getscaler__()\n",
    "    testdata = DensitySurvey(test_df_kit, gal, scaler_in, scaler_out)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "        for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            inputs = batch_no[0].to(device)\n",
    "            labels = batch_no[1].to(device)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "            predictions =  model(inputs)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    testloader = torch.utils.data.DataLoader(testdata, batch_size=batch, shuffle=False)\n",
    "\n",
    "\n",
    "    for batch_no in testloader:\n",
    "\n",
    "        #Split dataloader\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Forward pass through the trained network\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, outputs.detach().numpy())\n",
    "\n",
    "    y_gold = testdata.target\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Neural Net R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Neural Net MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric Neural Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALAXY TYPE:  LRG\n",
      "\n",
      "Loss for Epoch 0 :  0.1162809282541275\n",
      "Loss for Epoch 10 :  0.0645222504681442\n",
      "Loss for Epoch 20 :  0.0625937175063882\n",
      "Loss for Epoch 30 :  0.06243429446476512\n",
      "Loss for Epoch 40 :  0.06230533667257987\n",
      "Loss for Epoch 50 :  0.06227218222920783\n",
      "Loss for Epoch 60 :  0.061999652738450095\n",
      "Loss for Epoch 70 :  0.06181814146111719\n",
      "Loss for Epoch 80 :  0.06085118683404289\n",
      "Loss for Epoch 90 :  0.06059876336075831\n",
      "\n",
      "4.1149 minutes (2.47e+02 seconds) taken to train the model\n",
      "\n",
      "Neural Net R^2 for LRG, Geometric :  0.38443757500315257.\n",
      "Neural Net MSE for LRG, Geometric :  0.0003322833752020372.\n",
      "GALAXY TYPE:  ELG\n",
      "\n",
      "Loss for Epoch 0 :  2.4312975874054246\n",
      "Loss for Epoch 10 :  0.06502228003228083\n",
      "Loss for Epoch 20 :  0.055561175948241726\n",
      "Loss for Epoch 30 :  0.046266059929621406\n",
      "Loss for Epoch 40 :  0.03645620016322937\n",
      "Loss for Epoch 50 :  0.03533643936680164\n",
      "Loss for Epoch 60 :  0.03508950311515946\n",
      "Loss for Epoch 70 :  0.03495112086238805\n",
      "Loss for Epoch 80 :  0.03485323264612816\n",
      "Loss for Epoch 90 :  0.034759289148496464\n",
      "\n",
      "4.6468 minutes (2.79e+02 seconds) taken to train the model\n",
      "\n",
      "Neural Net R^2 for ELG, Geometric :  0.5217010424355256.\n",
      "Neural Net MSE for ELG, Geometric :  0.00019322576913077577.\n",
      "GALAXY TYPE:  QSO\n",
      "\n",
      "Loss for Epoch 0 :  0.9134626978775486\n",
      "Loss for Epoch 10 :  0.18038211314706132\n",
      "Loss for Epoch 20 :  0.138246692775283\n",
      "Loss for Epoch 30 :  0.1289135585539043\n",
      "Loss for Epoch 40 :  0.12650711054448038\n",
      "Loss for Epoch 50 :  0.1253230280126445\n",
      "Loss for Epoch 60 :  0.12447834311751649\n",
      "Loss for Epoch 70 :  0.12392768578138202\n",
      "Loss for Epoch 80 :  0.12359314283821732\n",
      "Loss for Epoch 90 :  0.12318668473744765\n",
      "\n",
      "3.8798 minutes (2.33e+02 seconds) taken to train the model\n",
      "\n",
      "Neural Net R^2 for QSO, Geometric :  0.5611385693268605.\n",
      "Neural Net MSE for QSO, Geometric :  0.0006951821151324711.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = Net().to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata = DensitySurvey(train_df_geo, gal)\n",
    "    scaler_in, scaler_out = traindata.__getscaler__()\n",
    "    testdata = DensitySurvey(test_df_geo, gal, scaler_in, scaler_out)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "        for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            inputs = batch_no[0].to(device)\n",
    "            labels = batch_no[1].to(device)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "            predictions =  model(inputs)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    testloader = torch.utils.data.DataLoader(testdata, batch_size=batch, shuffle=False)\n",
    "\n",
    "\n",
    "    for batch_no in testloader:\n",
    "\n",
    "        #Split dataloader\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Forward pass through the trained network\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, outputs.detach().numpy())\n",
    "\n",
    "    y_gold = testdata.target\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(f\"Neural Net R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Neural Net MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "galaxy_types = ['lrg','elg','qso']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric - Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 for lrg, Geometric :  0.22429511761770937.\n",
      "Linear Regression MSE for lrg, Geometric :  116.73494454968107.\n",
      "Linear Regression R^2 for elg, Geometric :  0.2707214443169599.\n",
      "Linear Regression MSE for elg, Geometric :  996.3742889230185.\n",
      "Linear Regression R^2 for qso, Geometric :  0.2873594296697155.\n",
      "Linear Regression MSE for qso, Geometric :  1806.4367916145238.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_geo[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_geo.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_geo[gal]\n",
    "    X_test = test_df_geo.drop(columns=['lrg','elg','qso'])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Linear Regression R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Linear Regression MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric - Ridge Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression R^2 for lrg, Geometric :  0.22429220844731323.\n",
      "Ridge Regression MSE for lrg, Geometric :  116.73538234742168.\n",
      "Ridge Regression R^2 for elg, Geometric :  0.2707178215774092.\n",
      "Ridge Regression MSE for elg, Geometric :  996.3792384783231.\n",
      "Ridge Regression R^2 for qso, Geometric :  0.2873569106933308.\n",
      "Ridge Regression MSE for qso, Geometric :  1806.4431768412535.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.87398e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.87398e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.87398e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_geo[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_geo.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_geo[gal]\n",
    "    X_test = test_df_geo.drop(columns=['lrg','elg','qso'])\n",
    "    reg = Ridge()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Ridge Regression R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Ridge Regression MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric - Lasso Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression R^2 for lrg, Geometric :  0.21112410308197582.\n",
      "Lasso Regression MSE for lrg, Geometric :  118.71703553094446.\n",
      "Lasso Regression R^2 for elg, Geometric :  0.23620539020780862.\n",
      "Lasso Regression MSE for elg, Geometric :  1043.531727739005.\n",
      "Lasso Regression R^2 for qso, Geometric :  0.2589981942866073.\n",
      "Lasso Regression MSE for qso, Geometric :  1878.3282628339373.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_geo[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_geo.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_geo[gal]\n",
    "    X_test = test_df_geo.drop(columns=['lrg','elg','qso'])\n",
    "    reg = Lasso()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Lasso Regression R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Lasso Regression MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric - Adaboost-Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regression R^2 for lrg, Geometric :  -14.197335788294952.\n",
      "AdaBoost Regression MSE for lrg, Geometric :  2287.0297594377976.\n",
      "AdaBoost Regression R^2 for elg, Geometric :  -0.09047134292485381.\n",
      "AdaBoost Regression MSE for elg, Geometric :  1489.8526775959442.\n",
      "AdaBoost Regression R^2 for qso, Geometric :  -1.0977061757706212.\n",
      "AdaBoost Regression MSE for qso, Geometric :  5317.370034311699.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_geo[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_geo.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_geo[gal]\n",
    "    X_test = test_df_geo.drop(columns=['lrg','elg','qso'])\n",
    "    reg = AdaBoostRegressor(n_estimators=100)\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"AdaBoost Regression R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"AdaBoost Regression MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis - Linear Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 for lrg, Kitanidis :  0.06959531735312607.\n",
      "Linear Regression MSE for lrg, Kitanidis :  126.85246668554198.\n",
      "Linear Regression R^2 for elg, Kitanidis :  0.10670288843788489.\n",
      "Linear Regression MSE for elg, Kitanidis :  792.8437391446898.\n",
      "Linear Regression R^2 for qso, Kitanidis :  0.12991526946317766.\n",
      "Linear Regression MSE for qso, Kitanidis :  1402.1212270198284.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_kit[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_kit.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_kit[gal]\n",
    "    X_test = test_df_kit.drop(columns=['lrg','elg','qso'])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Linear Regression R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Linear Regression MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis - Ridge Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression R^2 for lrg, Kitanidis :  0.06959235854194745.\n",
      "Ridge Regression MSE for lrg, Kitanidis :  126.85287009333159.\n",
      "Ridge Regression R^2 for elg, Kitanidis :  0.10670253475343427.\n",
      "Ridge Regression MSE for elg, Kitanidis :  792.8440530564876.\n",
      "Ridge Regression R^2 for qso, Kitanidis :  0.12991602422112913.\n",
      "Ridge Regression MSE for qso, Kitanidis :  1402.1200107450131.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.88334e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.88334e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/edgareggert/miniconda3/envs/astro/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.88334e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_kit[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_kit.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_kit[gal]\n",
    "    X_test = test_df_kit.drop(columns=['lrg','elg','qso'])\n",
    "    reg = Ridge()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Ridge Regression R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Ridge Regression MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis - Lasso Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression R^2 for lrg, Kitanidis :  0.06677871229150256.\n",
      "Lasso Regression MSE for lrg, Kitanidis :  127.23648592621204.\n",
      "Lasso Regression R^2 for elg, Kitanidis :  0.08376202975207314.\n",
      "Lasso Regression MSE for elg, Kitanidis :  813.204844027076.\n",
      "Lasso Regression R^2 for qso, Kitanidis :  0.10545207379278931.\n",
      "Lasso Regression MSE for qso, Kitanidis :  1441.5430956337375.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_kit[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_kit.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_kit[gal]\n",
    "    X_test = test_df_kit.drop(columns=['lrg','elg','qso'])\n",
    "    reg = Lasso()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"Lasso Regression R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Lasso Regression MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis - AdaBoost-Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regression R^2 for lrg, Kitanidis :  -0.18888314257819183.\n",
      "AdaBoost Regression MSE for lrg, Kitanidis :  162.0937233547244.\n",
      "AdaBoost Regression R^2 for elg, Kitanidis :  -0.022779423543789035.\n",
      "AdaBoost Regression MSE for elg, Kitanidis :  907.7654589800183.\n",
      "AdaBoost Regression R^2 for qso, Kitanidis :  -0.9604874739511455.\n",
      "AdaBoost Regression MSE for qso, Kitanidis :  3159.279787426464.\n"
     ]
    }
   ],
   "source": [
    "for gal in galaxy_types:\n",
    "    y_train = train_df_kit[gal]#.to_numpy(copy=True)\n",
    "    X_train = train_df_kit.drop(columns=['lrg','elg','qso'])#.to_numpy(copy=True)\n",
    "    y_gold = test_df_kit[gal]\n",
    "    X_test = test_df_kit.drop(columns=['lrg','elg','qso'])\n",
    "    reg = AdaBoostRegressor(n_estimators=100)\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(f\"AdaBoost Regression R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"AdaBoost Regression MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}