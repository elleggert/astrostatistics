{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### First attempt at building a Neural Network to learn a non-linear F(s)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_geometric = pd.read_csv('../../bricks_data/dataset_geometric.csv')\n",
    "df_kitanidis = pd.read_csv('../../bricks_data/dataset_kitanidis.csv')\n",
    "df_kitanidis.drop('pixel_id', axis=1, inplace=True)\n",
    "df_geometric.drop('pixel_id', axis=1, inplace=True)\n",
    "\n",
    "train_df_geo, test_df_geo = train_test_split(df_geometric, test_size=0.33, random_state=44, shuffle=True)\n",
    "train_df_kit, test_df_kit = train_test_split(df_kitanidis, test_size=0.33, random_state=44, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df_kit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrMatrix = df_kitanidis.corr()\n",
    "sns.heatmap(corrMatrix, annot=False)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining The Dataset Class Inheriting from Torch.dataset to be able to use a dataloader for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DensitySurvey(Dataset):\n",
    "    def __init__(self, df, galaxy_type, scaler_in=None, scaler_out=None):\n",
    "        self.data = df\n",
    "        # Extracting Targets and Input\n",
    "        self.target = self.data[galaxy_type].to_numpy(copy=True)\n",
    "        self.input = self.data.drop(columns=['lrg','elg','qso']).to_numpy(copy=True)\n",
    "\n",
    "        # Scaling, when scaler is passed (test-set) use the existing scaler\n",
    "        self.scaler_in = scaler_in\n",
    "        self.scaler_out = scaler_out\n",
    "        if self.scaler_in is None:\n",
    "            self.scaler_in = preprocessing.MinMaxScaler()\n",
    "            self.scaler_out = preprocessing.MinMaxScaler()\n",
    "            self.input = self.scaler_in.fit_transform(self.input)\n",
    "            self.target = self.scaler_out.fit_transform(self.target.reshape(-1, 1))\n",
    "        else:\n",
    "            self.input = self.scaler_in.transform(self.input)\n",
    "            self.target = self.scaler_out.transform(self.target.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.input[idx]).float(), torch.tensor(self.target[idx]).float()\n",
    "\n",
    "    def __getscaler__(self):\n",
    "        return self.scaler_in, self.scaler_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dens = DensitySurvey(train_df_geo, 'lrg')\n",
    "\n",
    "x = dens.__getitem__(4)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Models and Hyperparameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_input_vars = 17, n_output_vars=1):\n",
    "        super().__init__() # call constructor of superclass\n",
    "        self.linear = nn.Linear(n_input_vars, n_output_vars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "model = LinearRegression().to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature = 16, n_hidden = 10, n_output = 1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature,n_hidden)\n",
    "        #self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.predict(out)\n",
    "        return out\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 100 #very low, but computational power not sufficient for more iterations\n",
    "batch = 1024\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "#optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "galaxy_types = ['LRG', 'ELG', 'QSO']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kitanidis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gal in galaxy_types:\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata = DensitySurvey(train_df_kit, gal)\n",
    "    scaler_in, scaler_out = traindata.__getscaler__()\n",
    "    testdata = DensitySurvey(test_df_kit, gal, scaler_in, scaler_out)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "        for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            inputs = batch_no[0].to(device)\n",
    "            labels = batch_no[1].to(device)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "            predictions =  model(inputs)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    testloader = torch.utils.data.DataLoader(testdata, batch_size=batch, shuffle=False)\n",
    "\n",
    "\n",
    "    for batch_no in testloader:\n",
    "\n",
    "        #Split dataloader\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Forward pass through the trained network\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, outputs.detach().numpy())\n",
    "\n",
    "    y_gold = testdata.target\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Neural Net R^2 for {gal}, Kitanidis :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Neural Net MSE for {gal}, Kitanidis :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric Neural Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gal in galaxy_types:\n",
    "    model = Net().to(device)\n",
    "    optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(\"GALAXY TYPE: \", gal)\n",
    "    print()\n",
    "    traindata = DensitySurvey(train_df_geo, gal)\n",
    "    scaler_in, scaler_out = traindata.__getscaler__()\n",
    "    testdata = DensitySurvey(test_df_geo, gal, scaler_in, scaler_out)\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        loss_per_epoch = 0\n",
    "\n",
    "        #loading the training data from trainset and shuffling for each epoch\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "        for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "            #Put Model into train mode\n",
    "            model.train()\n",
    "\n",
    "            #Extract inputs and associated labels from dataloader batch\n",
    "            inputs = batch_no[0].to(device)\n",
    "            labels = batch_no[1].to(device)\n",
    "\n",
    "            #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            #Predict outputs (forward pass)\n",
    "            predictions =  model(inputs)\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #Perform one step of gradient descent\n",
    "            optimiser.step()\n",
    "\n",
    "            #Append loss to the general loss for this one epoch\n",
    "            loss_per_epoch += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_passed = time_end - time_start\n",
    "    print()\n",
    "    print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = np.array([])\n",
    "    testloader = torch.utils.data.DataLoader(testdata, batch_size=batch, shuffle=False)\n",
    "\n",
    "\n",
    "    for batch_no in testloader:\n",
    "\n",
    "        #Split dataloader\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Forward pass through the trained network\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #Get predictions and append to label array + count number of correct and total\n",
    "        y_pred = np.append(y_pred, outputs.detach().numpy())\n",
    "\n",
    "    y_gold = testdata.target\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(f\"Neural Net R^2 for {gal}, Geometric :  {metrics.r2_score(y_gold, y_pred)}.\")\n",
    "    print(f\"Neural Net MSE for {gal}, Geometric :  {metrics.mean_squared_error(y_gold, y_pred)}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}