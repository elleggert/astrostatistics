++++++++ Session Characteristics +++++++

Area: north
Gal Type: lrg
Training Samples: 290460
Validation Samples: 72616
Test Samples: 72616
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.006257032577053012 4.854470143613582 0
epoch 1 -0.004638768346919564 4.881010781099368 0
epoch 2 0.008441191717548313 4.84913236102084 1
epoch 3 0.0052935284868471655 4.8568229495191355 0
epoch 4 0.001623375614460354 4.8657747715170006 1
epoch 5 0.005974790555509646 4.85515947588531 2
epoch 6 0.004726244208279384 4.858207682940088 3
epoch 7 0.009133969849708046 4.847438079342944 4
epoch 8 0.003933761214716447 4.8601414628946635 0
epoch 9 0.007123872895361649 4.852352408619837 1
epoch 10 0.0005291241900283739 4.86844056052007 2
epoch 11 0.006206245412532674 4.8545941905915075 3
epoch 12 0.009519526943748136 4.846494891300036 4
epoch 13 0.00016384865404317495 4.869330111095031 0
epoch 14 0.008186739392229803 4.84975450962475 1
epoch 15 0.004056115421978368 4.859842950107348 2
epoch 16 0.007038481915583317 4.852561064164387 3
epoch 17 0.008337427199488268 4.849386080071628 4
epoch 18 0.004959008844870438 4.857639555295256 5
epoch 19 0.007739695349436193 4.8508473613236225 6
epoch 20 0.0047349126636032635 4.858186526324781 7
Target: 72616, NaN: 0, Max: 178.0, Min: 0.0, Mean: 8.47994932246337
Prediction: 72616, NaN: 0, Max: 9.611029624938965, Min: 8.536615371704102, Mean: 8.738615532074782

 XXXXXX======== TRIAL north - lrg ended

Test Set - R-squared:  0.004733081766640224
Test Set - RMSE:  4.858097907449962
Test Set - MAE:  3.3250346423850208



++++++++ Session Characteristics +++++++

Area: north
Gal Type: elg
Training Samples: 290460
Validation Samples: 72616
Test Samples: 72616
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.0761228720807311 7.475082331885553 0
epoch 1 0.0876324529640562 7.428374442587231 0
epoch 2 0.08764900364760764 7.42830706555663 0
epoch 3 0.0854212583338293 7.43737062049874 0
epoch 4 0.09561503554734785 7.395806489899825 1
epoch 5 0.0975210706808205 7.388008869000678 0
epoch 6 0.09207196760466385 7.410279436520695 0
epoch 7 0.10435030935183898 7.360002515130373 1
epoch 8 0.0948021170427028 7.399129653022648 0
epoch 9 0.10024623109468278 7.376845876367166 1
epoch 10 0.10853928000130209 7.342770907456916 2
epoch 11 0.11121170851686424 7.331756536031124 0
epoch 12 0.11079180324108995 7.333488264352521 0
epoch 13 0.11579916241772625 7.312810737491228 1
epoch 14 0.10988750534219494 7.337216284888635 0
epoch 15 0.10172008682751921 7.370801521211142 1
epoch 16 0.11501002105016334 7.316073318903168 2
epoch 17 0.11554045907848443 7.313880466287865 3
epoch 18 0.112682883699328 7.3256860434338 4
epoch 19 0.1114165909102367 7.330911433536287 5
epoch 20 0.11722979291487634 7.306892305346237 6
epoch 21 0.10987243997956708 7.337278376678694 0
epoch 22 0.12030158659116552 7.294168254819781 1
epoch 23 0.11890135384871392 7.299971079984747 0
epoch 24 0.12125607611544187 7.290210025136484 1
epoch 25 0.12130173104501774 7.290020642120889 0
epoch 26 0.11471285159066735 7.317301542456865 0
epoch 27 0.11670843071926995 7.309049704335622 1
epoch 28 0.11530762066584688 7.31484311080481 2
epoch 29 0.09980631431853149 7.3786490372964835 3
epoch 30 0.11420198576106155 7.319412507355389 4
epoch 31 0.1136686188196131 7.321615800378232 5
epoch 32 0.11984663545528818 7.296054163183153 6
epoch 33 0.12168031138032043 7.288450048501592 7
epoch 34 0.12291101218783251 7.283341973483838 0
epoch 35 0.11568886960772495 7.313266813340065 0
epoch 36 0.1233328324002737 7.2815903665333055 1
epoch 37 0.1225516374065524 7.284833943742437 0
epoch 38 0.1264038767957073 7.2688251424017345 1
epoch 39 0.10993154480832157 7.337034773514025 0
epoch 40 0.11993302843545894 7.295696075969875 1
epoch 41 0.12419073744381481 7.2780266182920395 2
epoch 42 0.12369366601107479 7.280091671784036 3
epoch 43 0.1239135338307309 7.279178316353568 4
epoch 44 0.12341056269168194 7.281267545793133 5
epoch 45 0.1252557337460335 7.2736001811932445 6
epoch 46 0.12616674450730336 7.269811614376599 7
Target: 72616, NaN: 0, Max: 175.0, Min: 6.0, Mean: 31.337873195989864
Prediction: 72616, NaN: 0, Max: 210.05003356933594, Min: 20.07701301574707, Mean: 31.660492200663374

 XXXXXX======== TRIAL north - elg ended

Test Set - R-squared:  0.1261564379060902
Test Set - RMSE:  7.270840398738127
Test Set - MAE:  5.751427060932371



++++++++ Session Characteristics +++++++

Area: north
Gal Type: qso
Training Samples: 290460
Validation Samples: 72616
Test Samples: 72616
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.08051625699957454 2.3726328545815294 0
epoch 1 0.09093611282138181 2.359150869307725 0
epoch 2 0.09917367226804563 2.3484377217966803 0
epoch 3 0.1000508199868867 2.347294089324723 0
epoch 4 0.0983579631937509 2.3495007505060705 0
epoch 5 0.09099868080260054 2.3590696814785264 1
epoch 6 0.10230401847763648 2.3443537932345113 2
epoch 7 0.09826019104306727 2.349628134492674 0
epoch 8 0.10261918941658821 2.3439422190126873 1
epoch 9 0.10520180502649856 2.3405669164727487 0
epoch 10 0.10656200267269089 2.338787272513638 0
epoch 11 0.10425168094839032 2.3418092295311914 0
epoch 12 0.10304806280241552 2.343382047366768 1
epoch 13 0.10433495261234627 2.3417003759171915 2
epoch 14 0.10554409768916684 2.3401191979149716 3
epoch 15 0.10693271741546306 2.338302004995373 4
epoch 16 0.10784264051306303 2.33711048377435 0
epoch 17 0.10618414177047508 2.3392817907968544 0
epoch 18 0.10540049685774933 2.3403070381288402 1
epoch 19 0.10823442348688872 2.3365972667775754 2
epoch 20 0.1073391758327249 2.3377698330550514 0
epoch 21 0.10926490101971176 2.3352468519167022 1
epoch 22 0.10889833182728503 2.335727321082038 0
epoch 23 0.10697770217479707 2.3382431128605714 1
epoch 24 0.11001125072805251 2.3342682915908197 2
epoch 25 0.10619604840937091 2.3392662098043817 0
epoch 26 0.10797181381691912 2.336941285365678 1
epoch 27 0.10907212120274934 2.3354995443869457 2
epoch 28 0.11081519609586243 2.333213756816234 3
epoch 29 0.1092849684307462 2.3352205463279576 0
epoch 30 0.11105447556524006 2.3328998019942313 1
epoch 31 0.11092600565344202 2.333068370593742 0
epoch 32 0.11115473834210232 2.3327682362224147 1
epoch 33 0.11055695427148282 2.333552544452499 0
epoch 34 0.1117560159202734 2.3319790783185366 1
epoch 35 0.10972248805754015 2.334646945186186 0
epoch 36 0.11197793803708955 2.331687745041095 1
epoch 37 0.11177150230027233 2.3319587494042886 0
epoch 38 0.11091628406328624 2.333081126040784 1
epoch 39 0.10733376460262545 2.3377769187201625 2
epoch 40 0.1116815623884796 2.3320768107227954 3
epoch 41 0.11197252370985333 2.3316948532548216 4
epoch 42 0.11226016304787823 2.331317195186219 5
epoch 43 0.11200817305630784 2.331648050518352 0
epoch 44 0.11262138531622001 2.330842839224541 1
epoch 45 0.11261481857025302 2.330851463516497 0
epoch 46 0.11212382604806703 2.331496207423951 1
epoch 47 0.11273355221763948 2.3306955223538477 2
epoch 48 0.11256635833340456 2.3309151067203073 0
epoch 49 0.11281081298291407 2.3305940448099087 1
epoch 50 0.1118625825132934 2.331839185156288 0
epoch 51 0.11251818629547294 2.3309783697080575 1
epoch 52 0.11286421232364874 2.3305239052838274 2
epoch 53 0.11300681042550564 2.3303365936876106 0
epoch 54 0.11308140648070042 2.330238601068154 0
epoch 55 0.11324372438298047 2.330025358978295 0
epoch 56 0.1127432182552991 2.3306828268145843 0
epoch 57 0.11162975528542396 2.332144813579126 1
epoch 58 0.11266904889151019 2.3307802403557036 2
epoch 59 0.11282017872945305 2.33058174314357 3
epoch 60 0.11325607987692843 2.330009126381304 4
epoch 61 0.11359160064555107 2.329568277338395 0
epoch 62 0.11271212839407885 2.3307236605238173 0
epoch 63 0.11329326404362428 2.329960273294138 1
epoch 64 0.11344856899503386 2.3297562203653253 2
epoch 65 0.11284781367213514 2.3305454449811815 3
epoch 66 0.1107165299296291 2.333343202837794 4
epoch 67 0.11339606876597574 2.3298252016563143 5
epoch 68 0.1134499408917854 2.3297544177703964 6
epoch 69 0.11360045295333132 2.329556644942488 7
epoch 70 0.11383181026796829 2.3292526087184955 0
epoch 71 0.11339050252925098 2.32983251514647 0
epoch 72 0.11375045131017747 2.3293595304165735 1
epoch 73 0.11379675732365335 2.3292986757944463 2
epoch 74 0.11385487859886534 2.329222291494164 3
epoch 75 0.11363037524204189 2.329517325058467 0
epoch 76 0.11415418748762507 2.328828893281125 1
epoch 77 0.1138015671629683 2.329292354689417 0
epoch 78 0.11346214699128265 2.32973837958292 1
epoch 79 0.11392239975264162 2.3291335505144257 2
epoch 80 0.11165204672548878 2.3321155537109752 3
epoch 81 0.11420282418129313 2.328764961109954 4
epoch 82 0.11396452921588995 2.329078179341132 0
epoch 83 0.11228213735064863 2.3312883413572076 1
epoch 84 0.11421851142778272 2.328744340096079 2
epoch 85 0.11410845051372875 2.3288890122149084 0
epoch 86 0.11401843979723425 2.3290073222068592 1
epoch 87 0.1138788594337038 2.329190774606225 2
epoch 88 0.1142833908059373 2.328659053683272 3
epoch 89 0.11378983282961486 2.3293077759548333 0
epoch 90 0.11379823331722327 2.329296736041163 1
epoch 91 0.11438845466585679 2.3285209366140833 2
epoch 92 0.1146537633027469 2.3281721251099103 0
epoch 93 0.11400209368901504 2.32902880686966 0
epoch 94 0.11426083347502669 2.328688706507813 1
epoch 95 0.11422868723290847 2.328730963819336 2
epoch 96 0.11386029645766904 2.329215171093407 3
epoch 97 0.11366580506329327 2.329470767051004 4
epoch 98 0.11419993720890342 2.328768756038889 5
epoch 99 0.11228553420711707 2.3312838810101812 6
epoch 100 0.11377570080895405 2.3293263481263136 7
Target: 72616, NaN: 0, Max: 64.0, Min: 0.0, Mean: 4.437699680511182
Prediction: 72616, NaN: 0, Max: 8.025439262390137, Min: 3.4214096069335938, Mean: 4.405092476974359

 XXXXXX======== TRIAL north - qso ended

Test Set - R-squared:  0.1138989034109339
Test Set - RMSE:  2.329779258403449
Test Set - MAE:  1.809351572702671



++++++++ Session Characteristics +++++++

Area: north
Gal Type: glbg
Training Samples: 290460
Validation Samples: 72616
Test Samples: 72616
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.12206950695406438 10.584793967798298 0
epoch 1 0.13528736476803271 10.50481103691182 0
epoch 2 0.10809704581695634 10.668691162441567 0
epoch 3 0.14395591583924716 10.45202421724514 1
epoch 4 0.13919264519146402 10.48106288330802 0
epoch 5 0.150207011393368 10.413792356419831 1
epoch 6 0.15162921340815372 10.405074516587 0
epoch 7 0.15450174753358026 10.387444091559924 0
epoch 8 0.15636626453175406 10.375984425447536 0
epoch 9 0.15487446302879282 10.385154324478703 0
epoch 10 0.16037545939897657 10.351300203725685 1
epoch 11 0.16217768315335346 10.340184889835239 0
epoch 12 0.1685562534635212 10.300748359166823 0
epoch 13 0.16998552256743815 10.291890950610236 0
epoch 14 0.16698271681039212 10.310491016787442 0
epoch 15 0.1760389362810756 10.25429215909048 1
epoch 16 0.17371781746002046 10.268725299706748 0
epoch 17 0.17529524312660982 10.258918789649627 1
epoch 18 0.1760722406635329 10.254084918521736 2
epoch 19 0.17861351981380658 10.238259127778107 0
epoch 20 0.17908023771535764 10.235349987013418 0
epoch 21 0.17930934229701634 10.233921632308506 0
epoch 22 0.17663996056663978 10.250551567945807 0
epoch 23 0.18100617204586966 10.223336518584615 1
epoch 24 0.17879574171024204 10.237123402682677 0
epoch 25 0.1828622426994706 10.21174546792468 1
epoch 26 0.1819391516910882 10.217511759888431 0
epoch 27 0.1815373947228942 10.220020407432294 1
epoch 28 0.18720784850331273 10.184555819375415 2
epoch 29 0.18178989232976317 10.21844383586139 0
epoch 30 0.18831134431258112 10.17763988656731 1
epoch 31 0.19026882253563948 10.165360218651252 0
epoch 32 0.1849877419943906 10.19845567038318 0
epoch 33 0.19209145317958165 10.153913126489943 1
epoch 34 0.19376393757201604 10.143397666961958 0
epoch 35 0.19230589244187024 10.15256548500752 0
epoch 36 0.1920611189530247 10.154103747205179 1
epoch 37 0.19629699879195972 10.127450687104417 2
epoch 38 0.19451326371824984 10.138682869206662 0
epoch 39 0.18115148985417617 10.222429491747384 1
epoch 40 0.19076121261547463 10.162269017631068 2
epoch 41 0.19099838133567681 10.160779748337612 3
epoch 42 0.19648407063532103 10.12627197362182 4
epoch 43 0.19441047956715762 10.139329721987048 0
epoch 44 0.19395483195239482 10.142196757989398 1
epoch 45 0.19878187709623207 10.11178260812695 2
epoch 46 0.19899226103604684 10.110454944491073 0
epoch 47 0.1971757398611078 10.121912670736535 0
epoch 48 0.19695366352872212 10.123312529913193 1
epoch 49 0.1985425089948042 10.11329296927776 2
epoch 50 0.2018055136683523 10.092684652927401 3
epoch 51 0.19172028477180592 10.15624530815599 0
epoch 52 0.1991614492339605 10.109387127100083 1
epoch 53 0.20569633895591222 10.068056041302299 2
epoch 54 0.2018249847414646 10.092561552227885 0
epoch 55 0.20165760809056776 10.093619697728249 1
epoch 56 0.19965055456873404 10.106299544489135 2
epoch 57 0.19622338824706276 10.127914459227643 3
epoch 58 0.19256628018338295 10.150928840224083 4
epoch 59 0.20279537321796248 10.086424625019797 5
epoch 60 0.201860794487283 10.092335150680185 6
epoch 61 0.20346794835530346 10.08216893605565 7
Target: 72616, NaN: 0, Max: 135.0, Min: 0.0, Mean: 30.728833865814696
Prediction: 72616, NaN: 0, Max: 70.05596160888672, Min: 7.9033002853393555, Mean: 29.86337941796346

 XXXXXX======== TRIAL north - glbg ended

Test Set - R-squared:  0.20337426699933359
Test Set - RMSE:  10.085041786489603
Test Set - MAE:  7.749663851052848



++++++++ Session Characteristics +++++++

Area: north
Gal Type: rlbg
Training Samples: 290460
Validation Samples: 72616
Test Samples: 72616
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.09502342356755589 9.30941218164137 0
epoch 1 0.1022086857942952 9.272381460464397 0
epoch 2 0.11070327717478046 9.228411169672613 0
epoch 3 0.11287248881482026 9.217149124760306 0
epoch 4 0.1153428025958696 9.204307045545066 0
epoch 5 0.10712095885176065 9.246979708045176 0
epoch 6 0.10977885602715132 9.233206376045219 1
epoch 7 0.1089304854814811 9.237604898277873 2
epoch 8 0.10686286150676283 9.248316086410286 3
epoch 9 0.12103737782563195 9.174634964421744 4
epoch 10 0.11880127580359978 9.186297797356115 0
epoch 11 0.11062521247483847 9.228816207339563 1
epoch 12 0.1243030439024243 9.157575549999336 2
epoch 13 0.12405882878309238 9.158852397251305 0
epoch 14 0.1187767931768986 9.186425409398344 1
epoch 15 0.12588661236844434 9.149291742615313 2
epoch 16 0.12677625007494875 9.144634665444134 0
epoch 17 0.12789143254490953 9.13879355412131 0
epoch 18 0.127248579076232 9.142161152559293 0
epoch 19 0.12614575197331312 9.147935442832537 1
epoch 20 0.13121618427754245 9.121356944325 2
epoch 21 0.13192806154186765 9.117619180569456 0
epoch 22 0.13185777882676064 9.117988273286763 0
epoch 23 0.13190313372603302 9.11775009178203 1
epoch 24 0.1338446212739275 9.107548518885762 2
epoch 25 0.13511017675620474 9.100892483737871 0
epoch 26 0.13521509777359297 9.100340445874817 0
epoch 27 0.13536449800630068 9.099554324549894 0
epoch 28 0.13634292584049146 9.094404306199301 0
epoch 29 0.1366772995279758 9.092643639852044 0
epoch 30 0.13860693277159664 9.082476362612685 0
epoch 31 0.13855796419583732 9.082734519793222 0
epoch 32 0.13882918125128896 9.081304599767192 1
epoch 33 0.1396705338476324 9.076867357970668 0
epoch 34 0.13944502768202083 9.078056876359325 0
epoch 35 0.14049592740709127 9.072512174315028 1
epoch 36 0.14097681814344487 9.069973793389007 0
epoch 37 0.1406367391840304 9.071768973131235 0
epoch 38 0.14162292802194587 9.066562184637446 1
epoch 39 0.14099038372047545 9.069902177211167 0
epoch 40 0.14362173969154557 9.055999861219355 1
epoch 41 0.14275484827393703 9.06058228886268 0
epoch 42 0.14379551549331027 9.055080995367673 1
epoch 43 0.14473405560731212 9.05011670988868 0
epoch 44 0.1425494143287479 9.061667882440757 0
epoch 45 0.14362414226459008 9.055987157886362 1
epoch 46 0.1451064800873495 9.048146064365886 2
epoch 47 0.14615594665239262 9.04259061063065 0
epoch 48 0.1455831180600068 9.045623357625987 0
epoch 49 0.1435831981526393 9.056203642807573 1
epoch 50 0.14520876017610196 9.04760478475454 2
epoch 51 0.1478737095546072 9.03349009231501 3
epoch 52 0.1478730692099416 9.033493486498578 0
epoch 53 0.14495593503028248 9.048942709603581 1
epoch 54 0.14809875625551816 9.03229714039603 2
epoch 55 0.1497771693349319 9.023395052188672 0
epoch 56 0.14921526609309144 9.02637629269609 0
epoch 57 0.14478387762111444 9.049853106731495 1
epoch 58 0.15075197749991232 9.018220760491502 2
epoch 59 0.15038050891458565 9.020192869563928 0
epoch 60 0.15150014389371713 9.01424747106696 1
epoch 61 0.15279549649934931 9.007364094029002 0
epoch 62 0.1508817270059577 9.017531824895354 0
epoch 63 0.15305642644375694 9.005976901210378 1
epoch 64 0.1535289739145702 9.003464133226963 0
epoch 65 0.14852788552197715 9.03002192873493 0
epoch 66 0.15344225245507803 9.003925326539488 1
epoch 67 0.14926007067849845 9.02613861308335 2
epoch 68 0.15359873850375982 9.003093101082978 3
epoch 69 0.15276485544414264 9.007526978340806 0
epoch 70 0.15388357360399896 9.001578091107957 1
epoch 71 0.149582182887543 9.024429686179397 0
epoch 72 0.15656822327544262 8.987286155286561 1
epoch 73 0.1566128240101342 8.98704852796701 0
epoch 74 0.1546304369870828 8.997604386608652 0
epoch 75 0.15622853436141215 8.98909577062014 1
epoch 76 0.15639746459446546 8.988195878813778 2
epoch 77 0.1577683844019182 8.980889650223169 3
epoch 78 0.15632451747212073 8.988584479383105 0
epoch 79 0.1573394607589913 8.98317620983269 1
epoch 80 0.15760291755447964 8.981771810480241 2
epoch 81 0.1592804425731904 8.972824334411065 3
epoch 82 0.1574684904518131 8.982488423478003 0
epoch 83 0.15889242123754832 8.974894730906126 1
epoch 84 0.15847226203309484 8.977136069543805 2
epoch 85 0.15939323381176218 8.972222415550043 3
epoch 86 0.15979459645806138 8.970080186250033 0
epoch 87 0.16012663972617114 8.96830755478876 0
epoch 88 0.15957688056850317 8.971242284519988 0
epoch 89 0.16025394418963435 8.967627839904083 1
epoch 90 0.1602586211415482 8.96760286734107 0
epoch 91 0.15740019325027022 8.982852484871154 0
epoch 92 0.15465829955013932 8.997456109218348 1
epoch 93 0.1599465936581288 8.96926878421956 2
epoch 94 0.16157948266997324 8.960547347961032 3
epoch 95 0.1614689634606008 8.961137910784089 0
epoch 96 0.1624079258547807 8.956119296120047 1
epoch 97 0.16093728288243092 8.963978418634197 0
epoch 98 0.16114026933953873 8.962894068057915 1
epoch 99 0.16316217613137174 8.952085902597398 2
epoch 100 0.16265982104899446 8.954772475202828 0
epoch 101 0.16259441414881648 8.955122209090467 1
epoch 102 0.16272710811854285 8.954412673703562 2
epoch 103 0.15867341076902985 8.976063111749466 3
epoch 104 0.16265525675053627 8.954796881172786 4
epoch 105 0.16413574626870198 8.94687699615895 5
epoch 106 0.1635761229197551 8.949871527555775 0
epoch 107 0.16492750688789126 8.942638590737591 1
epoch 108 0.1648457065105079 8.943076572652009 0
epoch 109 0.16390675071088778 8.948102467146128 1
epoch 110 0.16304879437758868 8.952692333612323 2
epoch 111 0.1651589015819529 8.941399523168824 3
epoch 112 0.16517184313871514 8.941330218915514 0
epoch 113 0.16634051742149636 8.935069551845105 0
epoch 114 0.16518673015931729 8.941250495705708 0
epoch 115 0.16693190881325637 8.931899756029518 1
epoch 116 0.16653501111357683 8.934027210173952 0
epoch 117 0.16601679549959192 8.93680419123023 1
epoch 118 0.1671763554930804 8.93058921883996 2
epoch 119 0.16712598139020518 8.930859302200654 0
epoch 120 0.16717885408376143 8.930575822304043 1
epoch 121 0.16558676460811161 8.939107958602806 0
epoch 122 0.16720783480595047 8.930420436727093 1
epoch 123 0.16812437453578755 8.925504841476618 0
epoch 124 0.16751571269198107 8.928769524744798 0
epoch 125 0.16589630683873258 8.937449734614454 1
epoch 126 0.1671129627504272 8.930929100983677 2
epoch 127 0.16762637027572913 8.928176078770948 3
epoch 128 0.16840730969779882 8.923986853783893 4
epoch 129 0.16744172249011713 8.92916630507507 0
epoch 130 0.16832354169882613 8.92443630800941 1
epoch 131 0.1687233515131783 8.922290938792047 2
epoch 132 0.16826563325167887 8.924747000495293 0
epoch 133 0.16912192707058427 8.920151678973914 1
epoch 134 0.16678004143289793 8.932713856591691 0
epoch 135 0.1672334353444448 8.930283172389872 1
epoch 136 0.1675946572519602 8.928346156698257 2
epoch 137 0.16834174387262957 8.924338646816778 3
epoch 138 0.1670479031762766 8.931277906446931 4
epoch 139 0.1640046244246599 8.947578715966518 5
epoch 140 0.17044964390034167 8.91302176964251 6
epoch 141 0.16416889107571708 8.946699607635702 0
epoch 142 0.1698702316291537 8.916133945226397 1
epoch 143 0.17007717856174143 8.915022503586364 2
epoch 144 0.1696468658212188 8.917333411615465 3
epoch 145 0.17015094216982674 8.914626310818997 4
epoch 146 0.16982988081187034 8.916350639611757 5
epoch 147 0.17044435148158277 8.913050201532164 6
epoch 148 0.17023151823618876 8.914193507436469 7
Target: 72616, NaN: 0, Max: 105.0, Min: 1.0, Mean: 25.19630659909662
Prediction: 72616, NaN: 0, Max: 43.11145782470703, Min: 17.39487075805664, Mean: 25.09006716617472

 XXXXXX======== TRIAL north - rlbg ended

Test Set - R-squared:  0.1701973575135226
Test Set - RMSE:  8.914606151446856
Test Set - MAE:  6.9226230266691235



++++++++ Session Characteristics +++++++

Area: south
Gal Type: lrg
Training Samples: 530277
Validation Samples: 132570
Test Samples: 132570
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.003722923996605343 4.894095346536362 0
epoch 1 0.002649827248424219 4.8967303687062795 0
epoch 2 0.0038190181486625896 4.893859315167865 1
epoch 3 0.006286255480770442 4.887795257535324 0
epoch 4 0.0063438156772887 4.8876536943681765 0
epoch 5 0.0040222084259646795 4.89336019133365 0
epoch 6 0.00424234387119371 4.892819385322675 1
epoch 7 0.004782461855866393 4.891492225953407 2
epoch 8 0.006830558130736963 4.886456439220225 3
epoch 9 0.00572338039182585 4.8891793727891635 0
epoch 10 0.006967576525359065 4.886119358012112 1
epoch 11 0.006269681335202448 4.887836019119211 0
epoch 12 0.00604059304491944 4.888399392022515 1
epoch 13 0.0063367943789102155 4.887670962722602 2
epoch 14 0.006876773494998045 4.886342746640708 3
epoch 15 0.006513889927363015 4.887235390923458 4
epoch 16 0.006873284667331392 4.8863513294592025 5
epoch 17 0.00676478999507335 4.8866182282344 6
epoch 18 0.006757534718653702 4.886636075820198 7
Target: 132570, NaN: 0, Max: 227.0, Min: 0.0, Mean: 8.573847778532096
Prediction: 132570, NaN: 0, Max: 10.465764045715332, Min: 7.889364242553711, Mean: 8.505232582896545

 XXXXXX======== TRIAL south - lrg ended

Test Set - R-squared:  0.00675711440726201
Test Set - RMSE:  4.8858986090190415
Test Set - MAE:  3.2988512849559557



++++++++ Session Characteristics +++++++

Area: south
Gal Type: elg
Training Samples: 530277
Validation Samples: 132570
Test Samples: 132570
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.0575852468244451 7.691193200678808 0
epoch 1 0.07518007545724803 7.6190578588012885 0
epoch 2 0.07468744259545945 7.621086847618881 0
epoch 3 0.08063475315637725 7.596555658225182 1
epoch 4 0.08082496531263228 7.595769772537641 0
epoch 5 0.08092421283221785 7.595359686519539 0
epoch 6 0.08397359236215751 7.582748986697911 0
epoch 7 0.08393590515463223 7.58290497002603 0
epoch 8 0.08292975418594728 7.587068135797995 1
epoch 9 0.08673167686737604 7.571324846213656 2
epoch 10 0.0880702571937837 7.5657741539290315 0
epoch 11 0.08894448858276616 7.562146778430833 0
epoch 12 0.08742802712293163 7.568437797989134 0
epoch 13 0.09074308794806751 7.554678522246698 1
epoch 14 0.09057225445437922 7.555388184991246 0
epoch 15 0.09203191072045969 7.549322448332143 1
epoch 16 0.09297671326616308 7.545393634306864 0
epoch 17 0.0944621087183738 7.539212709300051 0
epoch 18 0.09531473334849527 7.535662536331882 0
epoch 19 0.09589669282378854 7.533238402843412 0
epoch 20 0.0961870619651678 7.532028587764724 0
epoch 21 0.09579152720960604 7.533676524571388 0
epoch 22 0.09742144973585676 7.5268833744882775 1
epoch 23 0.09819512965612587 7.523656704078262 0
epoch 24 0.09903849441085799 7.520137832483719 0
epoch 25 0.09867937153234907 7.521636445056072 0
epoch 26 0.09962320899434185 7.517697191075457 1
epoch 27 0.10055349164572225 7.513812489277614 0
epoch 28 0.09983256479669955 7.516823131990954 0
epoch 29 0.1007866581791812 7.512838510752004 1
epoch 30 0.10089380550878946 7.512390894748154 0
epoch 31 0.10133194110696342 7.5105602728607 0
epoch 32 0.09323349097533118 7.544325510662517 0
epoch 33 0.09745195598195311 7.5267561728742285 1
epoch 34 0.10221079867444827 7.506886876851291 2
epoch 35 0.10297193214989153 7.503704083823768 0
epoch 36 0.1019044742142744 7.508167437449455 0
epoch 37 0.09982474693941101 7.51685577332001 1
epoch 38 0.10081167679032688 7.512733996014525 2
epoch 39 0.10314973154542073 7.502960394626532 3
epoch 40 0.10417238147739105 7.498681480549815 0
epoch 41 0.10008701315749624 7.5157606749250165 0
epoch 42 0.10348528305621985 7.501556667985767 1
epoch 43 0.10354715837129469 7.501297793712589 2
epoch 44 0.1048976216560693 7.495645491193171 3
epoch 45 0.10429776630763399 7.498156684379808 0
epoch 46 0.10470938706855326 7.496433594096886 1
epoch 47 0.10155056254360928 7.50964666002314 2
epoch 48 0.10534078102135169 7.493789738808546 3
epoch 49 0.10399145276058697 7.499438690024572 0
epoch 50 0.09991893863318368 7.516462492179965 1
epoch 51 0.10128284215483208 7.510765440719384 2
epoch 52 0.104856492586347 7.495817697966479 3
epoch 53 0.10114395220899275 7.511345784321249 4
epoch 54 0.10559305469754132 7.492733124662479 5
epoch 55 0.10543812411635622 7.493382048084251 0
epoch 56 0.1066833586861512 7.488164819354413 1
epoch 57 0.10526877131004941 7.494091314406403 0
epoch 58 0.10659621310961942 7.488530056324242 1
epoch 59 0.10427636347166114 7.498246268201814 2
epoch 60 0.10665098591466582 7.4883004993816185 3
epoch 61 0.10656648019625936 7.4886546662521 4
epoch 62 0.1068554679503545 7.4874434376186905 5
epoch 63 0.10694151198520496 7.487082765108138 0
epoch 64 0.10769137808767693 7.483938800479216 0
epoch 65 0.10643442051123198 7.489208100174592 0
epoch 66 0.10670651699484224 7.488067757266738 1
epoch 67 0.10722802548487909 7.485881655441167 2
epoch 68 0.10716522508583692 7.486144941084919 3
epoch 69 0.10777609645806896 7.4835835186106285 4
epoch 70 0.10783448181714395 7.483338659188354 0
epoch 71 0.10771677964380455 7.483832276211839 0
epoch 72 0.10225291007628445 7.506710817016504 1
epoch 73 0.10597357122668183 7.491139100753209 2
epoch 74 0.10653063062404422 7.488804908193595 3
epoch 75 0.10745358266838367 7.484935948646671 4
epoch 76 0.09382240533624686 7.541875219868067 5
epoch 77 0.10816217249378546 7.481964225031185 6
epoch 78 0.10729077330477865 7.4856185809825515 0
epoch 79 0.10814983785625565 7.482015964817717 1
epoch 80 0.10805033329364211 7.482433340960488 2
epoch 81 0.10573075651297381 7.492156316379326 3
epoch 82 0.1069852703470272 7.48689933563831 4
epoch 83 0.10341516476142387 7.501850018483822 5
epoch 84 0.10307550590092684 7.50327087039272 6
epoch 85 0.10818737042616688 7.4818585268007975 7
epoch 86 0.10775840155459959 7.483657726794746 0
epoch 87 0.10619608116840584 7.490206825935727 1
epoch 88 0.10612005506130762 7.49052537407901 2
epoch 89 0.107712812594003 7.483848912578897 3
epoch 90 0.10570843061685453 7.492249838582437 4
epoch 91 0.10470438719560249 7.496454526497317 5
epoch 92 0.1089024615957247 7.478858297985557 6
epoch 93 0.1077450848641488 7.483713573317548 0
epoch 94 0.10824470032354927 7.481618038462192 1
epoch 95 0.10386369325716449 7.499973333591453 2
epoch 96 0.10072724227826768 7.51308671363907 3
epoch 97 0.10907701486044263 7.478125761415503 4
epoch 98 0.10887593309722132 7.478969622165006 0
epoch 99 0.107623862273312 7.484221928229382 1
epoch 100 0.10922794596400232 7.477492300611904 2
epoch 101 0.105199660894995 7.4943807363823804 0
epoch 102 0.10733746744580741 7.485422806653088 1
epoch 103 0.10735010799284528 7.4853698078038 2
epoch 104 0.10804365543675609 7.482461350683095 3
epoch 105 0.10752028066037989 7.484656277183519 4
epoch 106 0.10779823199652139 7.48349068643166 5
epoch 107 0.10943604424179254 7.4766188200435 6
epoch 108 0.10823025293235844 7.481678643330361 0
epoch 109 0.10823430264789702 7.4816616553663975 1
epoch 110 0.10830777496354493 7.481353443057315 2
epoch 111 0.10890659552950455 7.478840950198431 3
epoch 112 0.10926708626524917 7.4773280192365865 4
epoch 113 0.10921264688714238 7.477556513581828 5
epoch 114 0.10911949327027604 7.477947484121791 6
epoch 115 0.1084539983436712 7.480740006263269 7
Target: 132570, NaN: 0, Max: 365.0, Min: 0.0, Mean: 32.88295994568907
Prediction: 132570, NaN: 0, Max: 42.7127685546875, Min: 27.334186553955078, Mean: 33.149222385673816

 XXXXXX======== TRIAL south - elg ended

Test Set - R-squared:  0.10847379717115846
Test Set - RMSE:  7.48087750024685
Test Set - MAE:  5.868865646919963



++++++++ Session Characteristics +++++++

Area: south
Gal Type: qso
Training Samples: 530277
Validation Samples: 132570
Test Samples: 132570
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.08184931615737623 2.284548579225421 0
epoch 1 0.08679025874744695 2.278393244014399 0
epoch 2 0.08514474184884835 2.280445043858135 0
epoch 3 0.0785531692448398 2.288645652641416 1
epoch 4 0.07396584202675349 2.294335472072953 2
epoch 5 0.06132889905236272 2.3099370253941975 3
epoch 6 0.06556425253303955 2.3047198302368557 4
epoch 7 0.07633187787269735 2.2914025608901487 5
epoch 8 0.07477960019498697 2.293327169861724 6
epoch 9 0.07205136618162766 2.2967058932494306 7
Target: 132570, NaN: 0, Max: 87.0, Min: 0.0, Mean: 4.115938749339971
Prediction: 132570, NaN: 0, Max: 8.536276817321777, Min: 2.7196121215820312, Mean: 3.744999493496571

 XXXXXX======== TRIAL south - qso ended

Test Set - R-squared:  0.07201499983493753
Test Set - RMSE:  2.296768105039513
Test Set - MAE:  1.7275080043589572



++++++++ Session Characteristics +++++++

Area: south
Gal Type: glbg
Training Samples: 530277
Validation Samples: 132570
Test Samples: 132570
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.033802427307622174 8.240988956616164 0
epoch 1 0.05142512460711113 8.165488468660785 0
epoch 2 0.04390036614706727 8.197811671659483 0
epoch 3 0.04269164578886908 8.202991953997213 1
epoch 4 0.0675323887470417 8.095864652771123 2
epoch 5 0.06793730826920996 8.094106666988452 0
epoch 6 0.0709991611358024 8.080801043553466 0
epoch 7 0.07662657185861921 8.05628919252747 0
epoch 8 0.07644207780286794 8.057093993264294 0
epoch 9 0.08600841540908544 8.015257139809028 1
epoch 10 0.0844656777858609 8.02201881322751 0
epoch 11 0.09265779275635155 7.986048031860315 1
epoch 12 0.08528459506390784 8.018430286105321 0
epoch 13 0.09571624627105091 7.972577053630821 1
epoch 14 0.09697471744825514 7.96702749488652 0
epoch 15 0.10291925642336197 7.940761062373602 0
epoch 16 0.09849705830366817 7.960309162831564 0
epoch 17 0.10123662817910706 7.948204700772803 1
epoch 18 0.10381512638711776 7.936795050208348 2
epoch 19 0.10917573839684469 7.9130221131524126 0
epoch 20 0.10940116959962154 7.912020818599649 0
epoch 21 0.11220159347499059 7.899571634709884 0
epoch 22 0.11215069732991056 7.8997980667348 0
epoch 23 0.11094575379124816 7.905156849575483 1
epoch 24 0.11145256111024737 7.90290335239456 2
epoch 25 0.12103123043525643 7.860190710369448 3
epoch 26 0.12100911064231012 7.860289613028567 0
epoch 27 0.11255718386927971 7.8979894663359795 1
epoch 28 0.11723377206492791 7.877151823316003 2
epoch 29 0.12133995160232736 7.858810217429342 3
epoch 30 0.1260836765474057 7.837567367340007 0
epoch 31 0.12691564238746944 7.833835808163063 0
epoch 32 0.12878845714222364 7.825429289759844 0
epoch 33 0.12393765548885827 7.847184576177994 0
epoch 34 0.1328668923016224 7.80709106541451 1
epoch 35 0.12311906413824347 7.850849918948582 0
epoch 36 0.12816054040998148 7.828248830530009 1
epoch 37 0.1267646679148955 7.834513095583637 2
epoch 38 0.13358187495683538 7.803871786995015 3
epoch 39 0.1309856836098393 7.815555054672694 0
epoch 40 0.13730991967421202 7.787064344161133 1
epoch 41 0.13518794079174934 7.796635473956478 0
epoch 42 0.136795398434571 7.789386158720304 1
epoch 43 0.14156955053714593 7.76781579421318 2
epoch 44 0.1377854168643583 7.784918012786058 0
epoch 45 0.13454267961383226 7.799543578710312 1
epoch 46 0.14057827481305152 7.772299457158102 2
epoch 47 0.14035816010448354 7.773294712369623 3
epoch 48 0.14097276137902692 7.770515455453548 4
epoch 49 0.14200468242555608 7.7658468211919836 5
epoch 50 0.14346962943642516 7.7592142591570274 0
epoch 51 0.1315603172091938 7.812970618995466 0
epoch 52 0.1443963157058331 7.755015748841503 1
epoch 53 0.14856393200792206 7.736105484593359 0
epoch 54 0.13762695647505396 7.785633347744206 0
epoch 55 0.14710625945225375 7.742724822630469 1
epoch 56 0.13881161987231205 7.780283850396948 2
epoch 57 0.14624573905882943 7.746629818383872 3
epoch 58 0.14610569857537758 7.747265128420835 4
epoch 59 0.14539082835050277 7.750507409399095 5
epoch 60 0.15116069253147857 7.724299457986305 6
epoch 61 0.1472890507402398 7.741895071856584 0
epoch 62 0.1493321780740866 7.73261457431183 1
epoch 63 0.1450487371848661 7.752058477960621 2
epoch 64 0.1513069309829287 7.723634056280065 3
epoch 65 0.15441101976926408 7.7094965495193835 0
epoch 66 0.15091224093934807 7.725429809793158 0
epoch 67 0.15389762656283257 7.711836576802226 1
epoch 68 0.1397370662169949 7.776102320067921 2
epoch 69 0.14488113534576907 7.7528182847734834 3
epoch 70 0.1462600456299703 7.746564912016804 4
epoch 71 0.1513037550133366 7.723648507914495 5
epoch 72 0.15537106262317824 7.705118802616428 6
epoch 73 0.1431973463230901 7.76044745252214 0
epoch 74 0.1418602454202833 7.766500454395371 1
epoch 75 0.15200401345389147 7.720461462962112 2
epoch 76 0.1562859979495077 7.700944427791605 3
epoch 77 0.15348070006033177 7.7137363900874005 0
epoch 78 0.14665210679476604 7.744785988580888 1
epoch 79 0.1542285685124336 7.7103282369590005 2
epoch 80 0.15078856464407586 7.72599242404493 3
epoch 81 0.15443500664881094 7.709387200840002 4
epoch 82 0.1601789773769815 7.683157428644131 5
epoch 83 0.14912280497946717 7.733566121903671 0
epoch 84 0.15634330327760204 7.700682898031728 1
epoch 85 0.1479703427725756 7.738801675790881 2
epoch 86 0.1581699651302102 7.692341729094605 3
epoch 87 0.1519008087902889 7.720931254918183 4
epoch 88 0.1556168721033817 7.703997523801277 5
epoch 89 0.15447945799906826 7.709184556940724 6
epoch 90 0.14869907545905758 7.735491506913754 7
Target: 132570, NaN: 0, Max: 159.0, Min: 0.0, Mean: 21.532646903522668
Prediction: 132570, NaN: 0, Max: 47.79228591918945, Min: 15.837199211120605, Mean: 20.650935618089875

 XXXXXX======== TRIAL south - glbg ended

Test Set - R-squared:  0.1487432562433989
Test Set - RMSE:  7.73404945506542
Test Set - MAE:  5.87162650968637



++++++++ Session Characteristics +++++++

Area: south
Gal Type: rlbg
Training Samples: 530277
Validation Samples: 132570
Test Samples: 132570
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.0318156470146006 4.462020258525324 0
epoch 1 0.04883648886657266 4.422624817283697 0
epoch 2 0.042735586605879505 4.43678582798638 0
epoch 3 0.06344957997240974 4.388520075571549 1
epoch 4 0.06520138746867854 4.384413814672928 0
epoch 5 0.07287550413346722 4.3663800682560066 0
epoch 6 0.07824149347379283 4.353725915929191 0
epoch 7 0.08130940068826964 4.346474580826145 0
epoch 8 0.07698284368816066 4.356697381216934 0
epoch 9 0.08843841344413916 4.329577477554149 1
epoch 10 0.08857520058522073 4.329252621421066 0
epoch 11 0.0957248535330345 4.312238823403824 0
epoch 12 0.09531174730979852 4.3132237057671725 0
epoch 13 0.0928460704791445 4.319097430389462 1
epoch 14 0.1039303016373152 4.292629478234887 2
epoch 15 0.10332455576409683 4.294080148479578 0
epoch 16 0.10303642382066225 4.29477000916938 1
epoch 17 0.11176158807566039 4.273830391996368 2
epoch 18 0.1103139145757076 4.277311772667044 0
epoch 19 0.11384410094548392 4.268817363069123 1
epoch 20 0.11574549475161588 4.2642351775241165 0
epoch 21 0.11614456829265185 4.263272821398641 0
epoch 22 0.1031822451710297 4.294420889854813 0
epoch 23 0.11434137837770297 4.267619444943313 1
epoch 24 0.11576423668885616 4.264189986659334 2
epoch 25 0.12127498336505638 4.2508815463054965 3
epoch 26 0.11611799088504227 4.26333691892166 0
epoch 27 0.12061722468020408 4.252472220953576 1
epoch 28 0.12437417731418265 4.243378662677274 2
epoch 29 0.1235278049609756 4.2454289739160735 0
epoch 30 0.12538787269319418 4.24092171195089 1
epoch 31 0.1312613216335068 4.22665779076448 0
epoch 32 0.12245848416241945 4.248017956043523 0
epoch 33 0.10631356820027493 4.286917148124747 1
epoch 34 0.13276877423518463 4.222989108325873 2
epoch 35 0.10400201824779631 4.2924576952827564 0
epoch 36 0.1338444850266871 4.220369204667089 1
epoch 37 0.12691240739224774 4.237223928652013 0
epoch 38 0.12955403292083145 4.230808971910829 1
epoch 39 0.12877892702886062 4.2326922566727685 2
epoch 40 0.14113088938816465 4.202580099691574 3
epoch 41 0.1373422750507145 4.211839039759706 0
epoch 42 0.13262886699229526 4.223329734284837 1
epoch 43 0.1321921982010652 4.224392695783099 2
epoch 44 0.13390732896492585 4.2202160973855 3
epoch 45 0.13754074825012885 4.211354499233155 4
epoch 46 0.1443941022796812 4.194588797840453 5
epoch 47 0.13853285394822445 4.208931595762111 0
epoch 48 0.1398559165119736 4.205698263170256 1
epoch 49 0.13776957488337382 4.210795786460391 2
epoch 50 0.14494946946554865 4.1932272392498735 3
epoch 51 0.1374222430904749 4.2116438173047195 0
epoch 52 0.14031171637490591 4.2045837924960185 1
epoch 53 0.11318966492042315 4.2703933567917955 2
epoch 54 0.13817288201176636 4.209810874224809 3
epoch 55 0.13854875551794354 4.208892749865099 4
epoch 56 0.14632528901057218 4.18985232375752 5
epoch 57 0.13324883417074296 4.221820118758651 0
epoch 58 0.12957548326241097 4.230756841818816 1
epoch 59 0.13709293353899732 4.212447688130748 2
epoch 60 0.142772533568312 4.198561768499076 3
epoch 61 0.13943481041516914 4.206727642143836 4
epoch 62 0.14617869041025333 4.190212062725311 5
epoch 63 0.1485427527503682 4.184407107509583 6
epoch 64 0.1440546558031327 4.195420779713845 0
epoch 65 0.1464835771880587 4.189463865000707 1
epoch 66 0.14551435201768848 4.191841898757125 2
epoch 67 0.14471486834190206 4.193802449906438 3
epoch 68 0.14861817620165685 4.184221772652127 4
epoch 69 0.13745923989849296 4.2115534955642575 0
epoch 70 0.15049891987848296 4.1795976432507 1
epoch 71 0.14925291076543545 4.182661740888047 0
epoch 72 0.14343160724941095 4.1969474398923134 1
epoch 73 0.14901782462389457 4.18323959646008 2
epoch 74 0.1405079444702646 4.204103906605209 3
epoch 75 0.1466376657421432 4.189085678037605 4
epoch 76 0.14756951954084563 4.186797856385402 5
epoch 77 0.15246487467316772 4.174758532559332 6
epoch 78 0.15012077027393245 4.180527799423204 0
epoch 79 0.14582825301511348 4.191071877503698 1
epoch 80 0.13995087907116177 4.205466095733532 2
epoch 81 0.1532624703017399 4.172793686019448 3
epoch 82 0.15001180519154889 4.180795788650304 0
epoch 83 0.1578243386172603 4.161537869970459 1
epoch 84 0.13746869209500212 4.211530419240128 0
epoch 85 0.1554187029077304 4.167477251542164 1
epoch 86 0.14743584030190526 4.1871261330149006 2
epoch 87 0.1512686189572896 4.1777037307133105 3
epoch 88 0.15639112327858185 4.165077419254041 4
epoch 89 0.15308204023259286 4.17323824960776 5
epoch 90 0.15737687971459358 4.162643262810685 6
epoch 91 0.15841919092736734 4.16006790484775 7
epoch 92 0.15004509530821053 4.1807139166059795 0
epoch 93 0.1393572156869186 4.2069172922333395 1
epoch 94 0.15535651997481092 4.167630665541202 2
epoch 95 0.15187157426891473 4.176219505992043 3
epoch 96 0.15096502139080648 4.178450861849853 4
epoch 97 0.1588574869068602 4.158984480369274 5
epoch 98 0.15272475642911687 4.174118425307045 0
epoch 99 0.15557139842308831 4.16710050637044 1
epoch 100 0.15709432295853898 4.16334113375846 2
epoch 101 0.16217114610848304 4.150784290328467 3
epoch 102 0.1579836530208637 4.1611442322106695 0
epoch 103 0.14817876824175313 4.18530139588027 1
epoch 104 0.1451172455701336 4.1928158262274575 2
epoch 105 0.15553290802134867 4.167195476830096 3
epoch 106 0.15707485488331552 4.16338921254864 4
epoch 107 0.15262637618707553 4.1743607543873855 5
epoch 108 0.13937554048812462 4.20687250516556 6
epoch 109 0.15437609008238573 4.170048777283587 7
Target: 132570, NaN: 0, Max: 83.0, Min: 0.0, Mean: 8.78101380402806
Prediction: 132570, NaN: 0, Max: 22.61464500427246, Min: 0.1508898138999939, Mean: 8.507727881790359

 XXXXXX======== TRIAL south - rlbg ended

Test Set - R-squared:  0.15437179965494197
Test Set - RMSE:  4.169521131599413
Test Set - MAE:  3.203187733056175



++++++++ Session Characteristics +++++++

Area: des
Gal Type: lrg
Training Samples: 270820
Validation Samples: 67706
Test Samples: 67706
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.007058758078619776 4.1960223814702164 0
epoch 1 -0.0021468295445232766 4.2154282309911775 0
epoch 2 0.011396575759253125 4.1868468623395065 1
epoch 3 0.011538375367849962 4.1865465829138575 0
epoch 4 0.0126388280753712 4.184215496208004 0
epoch 5 0.014908281745019014 4.17940401164481 0
epoch 6 0.015567254128530883 4.178005881646475 0
epoch 7 0.015250350821360281 4.178678308152149 0
epoch 8 0.01059102689221847 4.188552310091782 1
epoch 9 0.012961655990610721 4.183531404087 2
epoch 10 0.015226707669876105 4.1787284714252815 3
epoch 11 0.015791899436784163 4.177529148739091 4
epoch 12 0.01656271549969357 4.175892941264118 0
epoch 13 0.016081355456035618 4.176914797019445 0
epoch 14 0.018185757413560877 4.172445620267238 1
epoch 15 0.017006488798851027 4.1749506549988835 0
epoch 16 0.01787455647480396 4.173106827887558 1
epoch 17 0.015174960896273348 4.178838259575147 2
epoch 18 0.01894898394922262 4.170823551549386 3
epoch 19 0.017476287714070282 4.173952875424375 0
epoch 20 0.016029377613280937 4.1770251232921 1
epoch 21 0.01698999006627211 4.174985691397688 2
epoch 22 0.019093279211646164 4.1705168130616235 3
epoch 23 0.019337180238249818 4.1699982843629275 0
epoch 24 0.018640187742092418 4.171479905368121 0
epoch 25 0.018218673241402916 4.172375677987491 1
epoch 26 0.01882367267066032 4.1710899161597075 2
epoch 27 0.018560037831300558 4.171650249064557 3
epoch 28 0.01907351292660009 4.170558832963763 4
epoch 29 0.018694105160594665 4.171365310030913 5
epoch 30 0.017912073064762835 4.173027122064892 6
epoch 31 0.015345660720974874 4.178476084649156 7
Target: 67706, NaN: 0, Max: 143.0, Min: 0.0, Mean: 8.148790358313887
Prediction: 67706, NaN: 0, Max: 11.222411155700684, Min: 6.724979400634766, Mean: 8.166557530048548

 XXXXXX======== TRIAL des - lrg ended

Test Set - R-squared:  0.015369586650884504
Test Set - RMSE:  4.177586442199188
Test Set - MAE:  3.091957655966597



++++++++ Session Characteristics +++++++

Area: des
Gal Type: elg
Training Samples: 270820
Validation Samples: 67706
Test Samples: 67706
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.01100316975618576 7.173866207403533 0
epoch 1 0.029271894912275775 7.107299630316891 0
epoch 2 0.029214597842661116 7.107509380828183 0
epoch 3 0.03427085293207777 7.088975780675736 1
epoch 4 0.013380036849235166 7.165240505461594 0
epoch 5 0.04192145859974061 7.060840148769931 1
epoch 6 0.04512430371115783 7.049028116527625 0
epoch 7 0.04481450808987408 7.05017150145188 0
epoch 8 0.039915422936937395 7.068228316830642 1
epoch 9 0.03908861077387327 7.071271194307231 2
epoch 10 0.04645838779945988 7.044102196206662 3
epoch 11 0.04524443540281475 7.048584687968694 0
epoch 12 0.04544063382062091 7.0478604228958766 1
epoch 13 0.04096401401769656 7.0643673517726135 2
epoch 14 0.031515452309895164 7.09908164493416 3
epoch 15 0.03982099579306797 7.0685758988134895 4
epoch 16 0.036151865361814806 7.082068589865393 5
epoch 17 0.0480240204938438 7.038316917813563 6
epoch 18 0.047176355096279265 7.0414497753250584 0
epoch 19 0.04520776175364749 7.04872006023008 1
epoch 20 0.04029527880702766 7.066829912094311 2
epoch 21 0.0430328227414567 7.05674369884603 3
epoch 22 0.0414938257048999 7.062415755846618 4
epoch 23 0.033891493243417226 7.090367996911424 5
epoch 24 0.044069373623571884 7.052920863592009 6
epoch 25 0.04680075138377493 7.0428375106618 7
Target: 67706, NaN: 0, Max: 114.0, Min: 8.0, Mean: 31.139042330074144
Prediction: 67706, NaN: 0, Max: 39.71914291381836, Min: 26.92913055419922, Mean: 31.415023875772466

 XXXXXX======== TRIAL des - elg ended

Test Set - R-squared:  0.04690435919367042
Test Set - RMSE:  7.0427414144931655
Test Set - MAE:  5.609599039459026



++++++++ Session Characteristics +++++++

Area: des
Gal Type: qso
Training Samples: 270820
Validation Samples: 67706
Test Samples: 67706
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.027028349654111716 1.9632863467975663 0
epoch 1 0.027058279313672995 1.9632561501603616 0
epoch 2 0.032171828614734777 1.958090150698181 0
epoch 3 0.03216709713676513 1.9580949370070329 0
epoch 4 0.0309774556899699 1.9592979936006387 1
epoch 5 0.028255783341537777 1.9620475829088904 2
epoch 6 0.032963451642650354 1.957289189125387 3
epoch 7 0.03106690677593915 1.9592075594930412 0
epoch 8 0.02991728667180782 1.9603694956059374 1
epoch 9 0.03326827006834354 1.9569806874289024 2
epoch 10 0.03367425850486805 1.956569717695399 0
epoch 11 0.03293815588091231 1.957314788363229 0
epoch 12 0.03201637898823462 1.9582473956359892 1
epoch 13 0.033630707748610766 1.9566138069332033 2
epoch 14 0.03386558750125479 1.956376011248329 3
epoch 15 0.03365351609616862 1.956590716696671 0
epoch 16 0.033698180046231596 1.9565454999543788 1
epoch 17 0.03369007343450925 1.9565537069768082 2
epoch 18 0.03412271732712435 1.9561156561200148 3
epoch 19 0.033767246922133065 1.9564755762011574 0
epoch 20 0.034090940001011205 1.9561478339209513 1
epoch 21 0.03376924374260992 1.9564735545699827 2
epoch 22 0.03307902413450192 1.9571722258377444 3
epoch 23 0.033340789876716515 1.9569072841662942 4
epoch 24 0.03357065226888345 1.9566746033369222 5
epoch 25 0.03407318881673416 1.9561658085847038 6
epoch 26 0.03427669180386228 1.9559597336780494 7
epoch 27 0.0336897515971174 1.9565540327998554 0
epoch 28 0.03382952819377405 1.956412520094815 1
epoch 29 0.03431842405462049 1.9559174713223377 2
epoch 30 0.03146113930826833 1.9588089447979846 0
epoch 31 0.03231258443702867 1.9579477583711775 1
epoch 32 0.034123804173675776 1.9561145555670816 2
epoch 33 0.03188152039508785 1.9583838015036326 3
epoch 34 0.034135711646464784 1.956102497886847 4
epoch 35 0.03255444067787572 1.9577030659896104 5
epoch 36 0.03438966290399481 1.955845325449702 6
epoch 37 0.03208021167148156 1.9581828272673558 0
epoch 38 0.03384596422538899 1.9563958792453346 1
epoch 39 0.034416253490004656 1.9558183956264632 2
epoch 40 0.03266457235103015 1.957591632716461 0
epoch 41 0.03416686415800341 1.9560709520487096 1
epoch 42 0.03373954651333355 1.9565036205748743 2
epoch 43 0.03435612063326243 1.955879295116964 3
epoch 44 0.03312850042427473 1.9571221520150914 4
epoch 45 0.03429826944365644 1.9559378820617628 5
epoch 46 0.03237634705762482 1.9578832510030597 6
epoch 47 0.032610485781456644 1.9576463593051123 7
Target: 67706, NaN: 0, Max: 45.0, Min: 0.0, Mean: 3.39903405901988
Prediction: 67706, NaN: 0, Max: 5.14221715927124, Min: 2.9645442962646484, Mean: 3.321570695973082

 XXXXXX======== TRIAL des - qso ended

Test Set - R-squared:  0.032698715801897316
Test Set - RMSE:  1.957076722683766
Test Set - MAE:  1.5344703893656146



++++++++ Session Characteristics +++++++

Area: des
Gal Type: glbg
Training Samples: 270820
Validation Samples: 67706
Test Samples: 67706
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.07884008936464815 9.140546185963784 0
epoch 1 0.08367976163016921 9.116502854888347 0
epoch 2 0.07570316408995692 9.156096602621275 0
epoch 3 0.08048009572048787 9.1324057796128 1
epoch 4 0.08726988105043554 9.098626214330308 2
epoch 5 0.08818557316408038 9.094060992481172 0
epoch 6 0.09053098734996523 9.082357364639995 0
epoch 7 0.09104610585787454 9.079784900397286 0
epoch 8 0.08362497645680567 9.116775380640473 0
epoch 9 0.091055644192229 9.079737259778764 1
epoch 10 0.09527252578876799 9.058650882064022 0
epoch 11 0.09632195568987145 9.053395610344031 0
epoch 12 0.09743433306662663 9.047821781490743 0
epoch 13 0.0958630626318866 9.05569400252682 0
epoch 14 0.09363452540613193 9.066847473888183 1
epoch 15 0.09846809738744178 9.042638781821477 2
epoch 16 0.09736881247217632 9.048150183027044 0
epoch 17 0.09959608554799859 9.036979979295149 1
epoch 18 0.08955895713915807 9.087209628970633 0
epoch 19 0.09476245622065782 9.06120407692823 1
epoch 20 0.09909975327013021 9.039470376570783 2
epoch 21 0.09534651290475327 9.058280473750145 3
epoch 22 0.10060304201665182 9.031925363859838 4
epoch 23 0.10009542675054484 9.034473791690923 0
epoch 24 0.10087109168119424 9.030579359209748 1
epoch 25 0.09796442092291202 9.045164443059424 0
epoch 26 0.10076754277610434 9.031099351212449 1
epoch 27 0.10164567609383557 9.026688675070718 2
epoch 28 0.09523249401492218 9.058851290398293 0
epoch 29 0.09946812918054349 9.03762207893146 1
epoch 30 0.10204500295261731 9.024682228507032 2
epoch 31 0.10268562592230701 9.021462440061079 0
epoch 32 0.10263915658719558 9.021696034855726 0
epoch 33 0.10328166935247518 9.018465677264214 1
epoch 34 0.10250663806198834 9.022362153578912 0
epoch 35 0.10250397251641685 9.022375551727938 1
epoch 36 0.10249328910115829 9.022429250850186 2
epoch 37 0.10051588470413952 9.03236297889974 3
epoch 38 0.10295830009274354 9.020091623563893 4
epoch 39 0.09994827965077546 9.03521239349192 5
epoch 40 0.08717464354423021 9.099100893454793 6
epoch 41 0.1036231570428835 9.016748310635478 7
epoch 42 0.10446583940632304 9.01250899909302 0
epoch 43 0.10400276261508401 9.014838862401893 0
epoch 44 0.10132548635812755 9.028297169344942 1
epoch 45 0.10223473262632354 9.023728761754581 2
epoch 46 0.10434342968815513 9.013124933715174 3
epoch 47 0.1021769215976962 9.024019295740931 4
epoch 48 0.1031625201829458 9.019064810217808 5
epoch 49 0.10531283334902763 9.008245986766594 6
epoch 50 0.10241463309120247 9.022824597608324 0
epoch 51 0.09927805675544332 9.038575799820249 1
epoch 52 0.1023560150137125 9.023119216937065 2
epoch 53 0.09895730846083817 9.040184981070407 3
epoch 54 0.1044392297821718 9.012642895546234 4
epoch 55 0.10423906298257968 9.01365004723863 5
epoch 56 0.09616505442871714 9.054181524943328 6
epoch 57 0.10371241222434302 9.016299385862435 7
Target: 67706, NaN: 0, Max: 122.0, Min: 3.0, Mean: 29.60900067940803
Prediction: 67706, NaN: 0, Max: 48.275123596191406, Min: 25.786378860473633, Mean: 29.41151802134092

 XXXXXX======== TRIAL des - glbg ended

Test Set - R-squared:  0.10370956551268562
Test Set - RMSE:  9.015962714189634
Test Set - MAE:  6.9951491485341935



++++++++ Session Characteristics +++++++

Area: des
Gal Type: rlbg
Training Samples: 270820
Validation Samples: 67706
Test Samples: 67706
Number of features: 16
Device: cuda:0
Number of Workers: 8

+++++++++++++++++++++++++++++++++++++++
BaseNet(
  (mlp): Sequential(
    (0): Linear(in_features=16, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.25, inplace=False)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.25, inplace=False)
    (9): Linear(in_features=256, out_features=256, bias=True)
    (10): ReLU()
    (11): Dropout(p=0.25, inplace=False)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=1, bias=True)
  )
)

 Model params: 234753

epoch 0 0.016753421757628284 2.565016002550051 0
epoch 1 0.020642004396606795 2.5599388641533363 0
epoch 2 0.024914380615277287 2.5543489899460163 0
epoch 3 0.025692341188711443 2.553329807996119 0
epoch 4 0.02969165861517431 2.5480839921943925 0
epoch 5 0.02914754499960104 2.5487983284635165 0
epoch 6 0.029881243223363496 2.5478350501397733 1
epoch 7 0.030671742961631887 2.5467967889050205 0
epoch 8 0.03214048726809948 2.5448665803894803 0
epoch 9 0.03640303501342579 2.5392564763281977 0
epoch 10 0.03798804633092456 2.5371672176287103 0
epoch 11 0.036099359568281586 2.5396565653306458 0
epoch 12 0.03175424653459802 2.5453743157981203 1
epoch 13 0.03821417499417967 2.5368690093019346 2
epoch 14 0.039530953254872214 2.5351318043944757 0
epoch 15 0.03961314610420663 2.535023329183751 0
epoch 16 0.0352301295902151 2.5408014178548894 0
epoch 17 0.040762414062648356 2.533506079547057 1
epoch 18 0.039816803358549535 2.5347545295527634 0
epoch 19 0.04023255494985656 2.5342057059884646 1
epoch 20 0.0416079262819572 2.5323892641595154 2
epoch 21 0.04056383643745409 2.5337683042520904 0
epoch 22 0.04089681673681567 2.5333285834160164 1
epoch 23 0.041375519752524625 2.5326962930574983 2
epoch 24 0.04259538586866629 2.5310843303148367 3
epoch 25 0.04270244388050448 2.53094281207493 0
epoch 26 0.04167453677793598 2.5323012591349525 0
epoch 27 0.041427239911628555 2.5326279695247624 1
epoch 28 0.041476824065458495 2.532562465974039 2
epoch 29 0.04350612538723542 2.5298801858225985 3
epoch 30 0.04228484417931333 2.531494785552709 0
epoch 31 0.04339582246693008 2.530026054570576 1
epoch 32 0.0428399246460035 2.5307610668867717 2
epoch 33 0.04302860995208657 2.530511609677659 3
epoch 34 0.04444750975914924 2.5286349212089982 4
epoch 35 0.04419382884926493 2.5289705510386065 0
epoch 36 0.04420879866488214 2.5289507466199765 1
epoch 37 0.04430199960355152 2.5288274423202073 2
epoch 38 0.04497686072454654 2.527934425537611 3
epoch 39 0.043399993105657564 2.5300205393133814 0
epoch 40 0.044122758751935276 2.529064571587787 1
epoch 41 0.044677365679233305 2.5283307743047763 2
epoch 42 0.04514045195954253 2.527717904278124 3
epoch 43 0.04567536808402539 2.5270097862693968 0
epoch 44 0.04500098603187397 2.5279024956410603 0
epoch 45 0.04499634182987877 2.5279086422838155 1
epoch 46 0.0463578096602959 2.526106086993367 2
epoch 47 0.04560130441344801 2.5271078430432374 0
epoch 48 0.04655812358999567 2.5258407669302985 1
epoch 49 0.04670139666033668 2.5256509816025825 0
epoch 50 0.04664626812115624 2.5257240087924346 0
epoch 51 0.04720012403683438 2.524990235813618 1
epoch 52 0.047175811345215424 2.5250224508248067 0
epoch 53 0.04638475030002909 2.526070405164608 1
epoch 54 0.046261187724864095 2.526234054841062 2
epoch 55 0.047504880449317444 2.5245863899864616 3
epoch 56 0.04712817386485468 2.5250855706560555 0
epoch 57 0.047794934365687936 2.524201967058442 1
epoch 58 0.047680028694967236 2.524354264279326 0
epoch 59 0.04797077465473887 2.5239688886424765 1
epoch 60 0.04779178000503026 2.5242061480048945 0
epoch 61 0.04799533325382355 2.5239363342113013 1
epoch 62 0.047875010242251825 2.524095828190827 0
epoch 63 0.04798665659385071 2.5239478358815304 1
epoch 64 0.04890169084742657 2.5227345892633917 2
epoch 65 0.04897431688805165 2.5226382691875684 0
epoch 66 0.04808678770085095 2.523815100170298 0
epoch 67 0.049268358586762706 2.5222482596436384 1
epoch 68 0.04930234291482105 2.5222031797943005 0
epoch 69 0.049570500792756045 2.521847442958538 0
epoch 70 0.04976189088062544 2.521593515179067 0
epoch 71 0.049354390722958885 2.52213413736899 0
epoch 72 0.049955054206344274 2.5213372088172297 1
epoch 73 0.049997233005234065 2.521281238751854 0
epoch 74 0.05050975996639673 2.5206010307606674 0
epoch 75 0.05042470994999271 2.5207139188923797 0
epoch 76 0.04999045598180163 2.5212902317527983 1
epoch 77 0.05006946958185676 2.5211853799848907 2
epoch 78 0.05042261851284613 2.5207166948238293 3
epoch 79 0.05089137260192533 2.5200944484753953 4
epoch 80 0.0509162062804972 2.52006147879043 0
epoch 81 0.0508691527590065 2.5201239476146076 0
epoch 82 0.050089547217517905 2.521158736084444 1
epoch 83 0.051209880411896 2.519671558464143 2
epoch 84 0.05182851574468117 2.518849979491501 0
epoch 85 0.05074940490431479 2.520282919330257 0
epoch 86 0.05181078462757138 2.5188735310409376 1
epoch 87 0.05165563676586171 2.51907959848566 2
epoch 88 0.05204782601254332 2.518558660031149 3
epoch 89 0.051850477854510246 2.518820807774597 0
epoch 90 0.052036949281100364 2.518573108865353 1
epoch 91 0.050992828960103154 2.519959750280267 2
epoch 92 0.05219805807267197 2.5183590807387373 3
epoch 93 0.05232966991719867 2.518184224908588 0
epoch 94 0.052573562045566846 2.5178601645200906 0
epoch 95 0.05239392027594536 2.5180988592613067 0
epoch 96 0.05289819541553742 2.5174287582240376 1
epoch 97 0.05174170355065777 2.5189652866336414 0
epoch 98 0.05223645706824065 2.5183080661573314 1
epoch 99 0.05242727697263139 2.5180545390522737 2
epoch 100 0.05293023032303823 2.5173861829280275 3
epoch 101 0.051765591617212836 2.5189335581533263 0
epoch 102 0.052989446762382486 2.5173074807134443 1
epoch 103 0.052680860673989915 2.517717583217207 0
epoch 104 0.052962215239824806 2.5173436733527055 1
epoch 105 0.053331097667884575 2.516853358021789 2
epoch 106 0.05354667864401663 2.5165667654253268 0
epoch 107 0.05394211749921718 2.5160409855342016 0
epoch 108 0.053758044039155184 2.516285745317211 0
epoch 109 0.05387681702831493 2.5161278173386683 1
epoch 110 0.05440522574449358 2.515425091952231 2
epoch 111 0.05414863102071521 2.5157663591860984 0
epoch 112 0.05388737568195823 2.5161137774140867 1
epoch 113 0.05273653999031758 2.517643591862106 2
epoch 114 0.05439431937204087 2.5154395982103934 3
epoch 115 0.054854186738435895 2.5148278689868313 4
epoch 116 0.054474863478353064 2.515332466795542 0
epoch 117 0.054852366617755055 2.5148302904587063 1
epoch 118 0.055172120700953564 2.514404856775992 2
epoch 119 0.05492074853647899 2.5147393141788768 0
epoch 120 0.055062904220553044 2.5145501776959627 1
epoch 121 0.05367857001380594 2.5163914134061196 2
epoch 122 0.054628823035096086 2.515127673066477 3
epoch 123 0.05528334396801826 2.514256857039865 4
epoch 124 0.05535582673324391 2.514160402836362 0
epoch 125 0.056143383671356184 2.513112147106091 0
epoch 126 0.05568902043001467 2.5137169679939277 0
epoch 127 0.056046831491405213 2.513240683711641 1
epoch 128 0.05578442784251214 2.513589979483346 2
epoch 129 0.05608012508045923 2.5131963618410587 3
epoch 130 0.05623122501749489 2.5129952012232937 4
epoch 131 0.05602918055626682 2.5132641810854524 0
epoch 132 0.056569354559997675 2.512544988172061 1
epoch 133 0.055620591502407946 2.513808043838693 0
epoch 134 0.05561780344810607 2.5138117545444194 1
epoch 135 0.05661928849201869 2.5124784952552823 2
epoch 136 0.055058192163197184 2.5145564472613886 0
epoch 137 0.05651873469979274 2.5126123926870054 1
epoch 138 0.057210102155742515 2.511691623587052 2
epoch 139 0.05712292680168862 2.5118077430670125 0
epoch 140 0.05710758519445769 2.511828177868207 1
epoch 141 0.057242448420797176 2.5116485362883654 2
epoch 142 0.0573853973092916 2.5114581103527396 0
epoch 143 0.05763398982520007 2.5111269193988863 0
epoch 144 0.05690974064480303 2.512091689081732 0
epoch 145 0.05738094075664801 2.511464047260581 1
epoch 146 0.05781266380179195 2.5108888514418224 2
epoch 147 0.05721571365135947 2.511684148768144 0
epoch 148 0.057938104770868915 2.5107216984760945 1
epoch 149 0.05820752270579399 2.5103626552813756 0
epoch 150 0.05801277302053798 2.5106221960386796 0
epoch 151 0.05749158969099777 2.511316639369098 1
epoch 152 0.05747352275697226 2.5113407089551694 2
epoch 153 0.05547204064480038 2.5140057470358936 3
epoch 154 0.05650012419744521 2.512637173649787 4
epoch 155 0.05875026295306418 2.5096392097076823 5
epoch 156 0.05854167277629463 2.509917274639112 0
epoch 157 0.05607428129934655 2.513204141392635 1
epoch 158 0.05907099512194547 2.5092115917353115 2
epoch 159 0.05930186209781818 2.5089037419255154 0
epoch 160 0.05859006275237588 2.5098527702451965 0
epoch 161 0.058366661373757345 2.5101505530103085 1
epoch 162 0.0591381759148335 2.509122013333322 2
epoch 163 0.05793026915196964 2.5107321399436793 3
epoch 164 0.059234244458645446 2.5089939106484365 4
epoch 165 0.05914174434996311 2.5091172551172924 5
epoch 166 0.0589621801409661 2.509356678089678 6
epoch 167 0.059177418353249744 2.509069686259198 7
Target: 67706, NaN: 0, Max: 52.0, Min: 0.0, Mean: 3.995007827962071
Prediction: 67706, NaN: 0, Max: 9.513432502746582, Min: 2.885307788848877, Mean: 3.9273193276932443

 XXXXXX======== TRIAL des - rlbg ended

Test Set - R-squared:  0.05915362354466547
Test Set - RMSE:  2.5089896254607895
Test Set - MAE:  1.9318841640464637



