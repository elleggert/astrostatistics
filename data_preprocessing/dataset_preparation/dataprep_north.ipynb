{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to prepare the full north dataset used for training of different models, combining different code throughout this repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate resolution at NSIDE 512 is 0.11 deg\n",
      "Approximate pix area at NSIDE 512 is 0.013 deg\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from astropy.coordinates import SkyCoord, Latitude, Longitude\n",
    "from dustmaps.sfd import SFDQuery\n",
    "from dustmaps.config import config\n",
    "config['data_dir'] = '/Users/edgareggert/astrostatistics/data_preprocessing/.dustmapsrc'\n",
    "from desiutil.plots import plot_sky_binned, plot_healpix_map\n",
    "\n",
    "# Defining important metrics and functions\n",
    "\n",
    "# Setting NSIDE values\n",
    "NSIDE = 512\n",
    "NPIX = hp.nside2npix(NSIDE)\n",
    "print(\n",
    "    \"Approximate resolution at NSIDE {} is {:.2} deg\".format(\n",
    "        NSIDE, hp.nside2resol(NSIDE, arcmin=True) / 60\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Approximate pix area at NSIDE {} is {:.2} deg\".format(\n",
    "        NSIDE, hp.nside2pixarea(NSIDE, degrees=True)))\n",
    "\n",
    "def raDec2thetaPhi(ra, dec):\n",
    "    return (0.5 * np.pi - np.deg2rad(dec)), (np.deg2rad(ra))\n",
    "\n",
    "### 1. Get a catalogue of all objects in the Galaxy Survey and prepare the north area\n",
    "\n",
    "### NORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_north = pd.read_csv('../../bricks_data/galaxy_catalogue_north.csv',\n",
    "                       dtype={'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8', 'GLBG':'int8','RLBG':'int8'})\n",
    "df_north = df_north.drop_duplicates()\n",
    "# Removing all Lines with Nan that were added to ensure that all bricks are stored\n",
    "df_north = df_north.dropna(axis=0, inplace=False, how='any')\n",
    "\n",
    "print(len(df_north))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Galaxy Count per Healpy Pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LRG\n",
    "\n",
    "df_LRG = df_north[df_north[\"LRG\"] == 1]\n",
    "ra_LRG = df_LRG[\"RA\"].to_numpy(copy=True)\n",
    "dec_LRG = df_LRG[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_LRG, dec_LRG)\n",
    "\n",
    "print(\"Number of LRGs in Sample:\", len(ra_LRG))\n",
    "\n",
    "LRG_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(LRG_pixel_indices, return_counts=True)\n",
    "mean_LRG = counts.mean()\n",
    "print(\"Mean LRGs per Pixel:\", mean_LRG)\n",
    "# Calculating Densities for every block\n",
    "\n",
    "#density_LRG = (counts / mean_LRG) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "#print(id_density)\n",
    "df_lrg = pd.DataFrame(id_density, columns=['pixel_id', 'lrg'])\n",
    "df_lrg.pixel_id = df_lrg.pixel_id.astype(int)\n",
    "\n",
    "# elg\n",
    "\n",
    "df_ELG = df_north[df_north[\"ELG\"] == 1]\n",
    "ra_ELG = df_ELG[\"RA\"].to_numpy(copy=True)\n",
    "dec_ELG = df_ELG[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_ELG, dec_ELG)\n",
    "\n",
    "print(\"Number of ELGs in Sample:\", len(ra_ELG))\n",
    "\n",
    "ELG_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(ELG_pixel_indices, return_counts=True)\n",
    "mean_ELG = counts.mean()\n",
    "print(\"Mean ELGs per Pixel:\", mean_ELG)\n",
    "# Calculating Densities for every block\n",
    "#density_ELG = (counts / mean_ELG) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "df_elg = pd.DataFrame(id_density, columns=['pixel_id', 'elg'])\n",
    "df_elg.pixel_id = df_elg.pixel_id.astype(int)\n",
    "\n",
    "# QSO\n",
    "df_QSO = df_north[df_north[\"QSO\"] == 1]\n",
    "ra_QSO = df_QSO[\"RA\"].to_numpy(copy=True)\n",
    "dec_QSO = df_QSO[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_QSO, dec_QSO)\n",
    "\n",
    "print(\"Number of QSOs in Sample:\", len(ra_QSO))\n",
    "\n",
    "QSO_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(QSO_pixel_indices, return_counts=True)\n",
    "mean_QSO = counts.mean()\n",
    "print(\"Mean QSOs per Pixel:\", mean_QSO)\n",
    "# Calculating Densities for every block\n",
    "#density_QSO = (counts / mean_QSO) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "df_qso = pd.DataFrame(id_density, columns=['pixel_id', 'qso'])\n",
    "df_qso.pixel_id = df_qso.pixel_id.astype(int)\n",
    "\n",
    "# GLBG\n",
    "df_GLBG = df_north[df_north[\"GLBG\"] == 1]\n",
    "ra_GLBG = df_GLBG[\"RA\"].to_numpy(copy=True)\n",
    "dec_GLBG = df_GLBG[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_GLBG, dec_GLBG)\n",
    "\n",
    "print(\"Number of GLBGs in Sample:\", len(ra_GLBG))\n",
    "\n",
    "GLBG_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(GLBG_pixel_indices, return_counts=True)\n",
    "mean_GLBG = counts.mean()\n",
    "print(\"Mean GLBGs per Pixel:\", mean_GLBG)\n",
    "# Calculating Densities for every block\n",
    "#density_QSO = (counts / mean_QSO) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "df_glbg = pd.DataFrame(id_density, columns=['pixel_id', 'glbg'])\n",
    "df_glbg.pixel_id = df_glbg.pixel_id.astype(int)\n",
    "\n",
    "# RLBG\n",
    "df_RLBG = df_north[df_north[\"RLBG\"] == 1]\n",
    "ra_RLBG = df_RLBG[\"RA\"].to_numpy(copy=True)\n",
    "dec_RLBG = df_RLBG[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_RLBG, dec_RLBG)\n",
    "\n",
    "print(\"Number of RLBGs in Sample:\", len(ra_RLBG))\n",
    "\n",
    "RLBG_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(RLBG_pixel_indices, return_counts=True)\n",
    "mean_RLBG = counts.mean()\n",
    "print(\"Mean RLBGs per Pixel:\", mean_RLBG)\n",
    "# Calculating Densities for every block\n",
    "#density_QSO = (counts / mean_QSO) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "df_rlbg = pd.DataFrame(id_density, columns=['pixel_id', 'rlbg'])\n",
    "df_rlbg.pixel_id = df_rlbg.pixel_id.astype(int)\n",
    "\n",
    "# Merging\n",
    "df_north = pd.merge(df_lrg, df_elg, how='outer', on='pixel_id')\n",
    "df_north = pd.merge(df_north, df_qso, how='outer', on='pixel_id')\n",
    "df_north = pd.merge(df_north, df_glbg, how='outer', on='pixel_id')\n",
    "df_north = pd.merge(df_north, df_rlbg, how='outer', on='pixel_id')\n",
    "\n",
    "df_north.fillna(value=0, inplace=True)\n",
    "df_north = df_north.astype(int)\n",
    "\n",
    "\n",
    "print(f'Pixels in the Northern Catalogue: {len(df_north)}')\n",
    "print(df_north.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting Galaxy Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_LRG = np.zeros(NPIX)\n",
    "\n",
    "m_LRG[df_north.pixel_id.to_numpy()] = df_north.lrg.to_numpy()\n",
    "mask = (m_LRG == 0)\n",
    "m_LRG[mask] = np.nan\n",
    "hp.mollview(m_LRG, title=\"LRG\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "\n",
    "\n",
    "hp.graticule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_ELG = np.zeros(NPIX)\n",
    "\n",
    "m_ELG[df_north.pixel_id.to_numpy()] = df_north.elg.to_numpy()\n",
    "mask = (m_ELG == 0)\n",
    "m_ELG[mask] = np.nan\n",
    "hp.mollview(m_ELG, title=\"ELG\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_QSO = np.zeros(NPIX)\n",
    "\n",
    "m_QSO[df_north.pixel_id.to_numpy()] = df_north.qso.to_numpy()\n",
    "mask = (m_QSO == 0)\n",
    "m_QSO[mask] = np.nan\n",
    "hp.mollview(m_QSO, title=\"QSO\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_GLBG = np.zeros(NPIX)\n",
    "\n",
    "m_GLBG[df_north.pixel_id.to_numpy()] = df_north.glbg.to_numpy()\n",
    "mask = (m_GLBG == 0)\n",
    "m_GLBG[mask] = np.nan\n",
    "hp.mollview(m_GLBG, title=\"GLBG\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_RLBG = np.zeros(NPIX)\n",
    "\n",
    "m_RLBG[df_north.pixel_id.to_numpy()] = df_north.rlbg.to_numpy()\n",
    "mask = (m_RLBG == 0)\n",
    "m_RLBG[mask] = np.nan\n",
    "hp.mollview(m_RLBG, title=\"RLBG\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting Exposure Densities across pixels\n",
    "with open(f'../../bricks_data/pixel2ccd_{NSIDE}.pickle', 'rb') as f:\n",
    "    pixel2ccd_dict = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pix_ids = df_north.pixel_id.to_numpy()\n",
    "exp_len = np.zeros(len(pix_ids))\n",
    "for i, pix in enumerate(pix_ids):\n",
    "    exp_len[i] = len(pixel2ccd_dict[pix])\n",
    "df_north['exposures'] = exp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_north.exposures = df_north.exposures.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_EXP = np.zeros(NPIX)\n",
    "\n",
    "m_EXP[df_north.pixel_id.to_numpy()] = df_north.exposures.to_numpy()\n",
    "mask = (m_EXP == 0)\n",
    "m_EXP[mask] = np.nan\n",
    "hp.mollview(m_EXP, title=\"EXP_incl\", format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Importing the Systematics Values and Appending them to the df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Stellar Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import New Systematics here --> maps by Boris\n",
    "m_hinh = hp.read_map(\"../../bricks_data/systematics_maps/HINH_512_NEST.fits\")\n",
    "m_gaia = hp.read_map(\"../../bricks_data/systematics_maps/GaiaEDR3_Gmag_gt17_512_NEST.fits\")\n",
    "m_gaia12 = hp.read_map(\"../../bricks_data/systematics_maps/GaiaEDR3_12lt_Gmag_gt17_512_NEST.fits\")\n",
    "m_sagitarius = hp.read_map(\"../../bricks_data/systematics_maps/SagitariusDR2_512_NEST.fits\")\n",
    "\n",
    "m_hinh = hp.reorder(map_in=m_hinh, n2r=True)\n",
    "m_gaia = hp.reorder(map_in=m_gaia, n2r=True)\n",
    "m_gaia12 = hp.reorder(map_in=m_gaia12, n2r=True)\n",
    "m_sagitarius = hp.reorder(map_in=m_sagitarius, n2r=True)\n",
    "\n",
    "unique = np.arange(NPIX)\n",
    "\n",
    "id_density = np.stack((unique, m_hinh, m_gaia, m_gaia12, m_sagitarius), axis=1)\n",
    "\n",
    "df_hinh = pd.DataFrame(id_density, columns=['pixel_id', 'hinh','gaia', 'gaia12', 'sagitarius'])\n",
    "df_hinh.pixel_id = df_hinh.pixel_id.astype(int)\n",
    "\n",
    "df_north = pd.merge(df_north, df_hinh, how='inner', on='pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Plot all stellar maps across the full sky\n",
    "\"\"\"m_gaia = hp.read_map(\"../../bricks_data/systematics_maps/GaiaEDR3_Gmag_gt17_512_NEST.fits\")\n",
    "mask = (m_gaia == 0)\n",
    "m_gaia[mask] = np.nan\n",
    "hp.mollview(m_gaia, title=\"gaia\", format='%i', nest=True, norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n",
    "\n",
    "m_sagitarius = hp.read_map(\"../../bricks_data/systematics_maps/SagitariusDR2_512_NEST.fits\")\n",
    "\n",
    "mask = (m_sagitarius == 0)\n",
    "m_sagitarius[mask] = np.nan\n",
    "hp.mollview(m_sagitarius, title=\"sagitarius\", nest=True, format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n",
    "\n",
    "m_gaia12 = hp.read_map(\"../../bricks_data/systematics_maps/GaiaEDR3_12lt_Gmag_gt17_512_NEST.fits\")\n",
    "mask = (m_gaia12 == 0)\n",
    "m_gaia12[mask] = np.nan\n",
    "hp.mollview(m_gaia12, title=\"gaia12lt\", format='%i', nest=True, norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n",
    "\n",
    "m_hinh = hp.read_map(\"../../bricks_data/systematics_maps/HINH_512_NEST.fits\")\n",
    "\n",
    "mask = (m_hinh == 0)\n",
    "m_hinh[mask] = np.nan\n",
    "hp.mollview(m_hinh, title=\"hinh\", nest=True, format='%i', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_hinh = np.zeros(NPIX)\n",
    "\n",
    "m_hinh[df_north.pixel_id.to_numpy()] = df_north.hinh.to_numpy()\n",
    "mask = (m_hinh == 0)\n",
    "m_hinh[mask] = np.nan\n",
    "hp.mollview(m_hinh, title=\"HINH\", format='%e', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0),\n",
    "            badcolor='white', remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_gaia = np.zeros(NPIX)\n",
    "\n",
    "m_gaia[df_north.pixel_id.to_numpy()] = df_north.gaia.to_numpy()\n",
    "mask = (m_gaia == 0)\n",
    "m_gaia[mask] = np.nan\n",
    "hp.mollview(m_gaia, title=\"gaia\", format='%e', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0),\n",
    "            badcolor='white', remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_gaia12 = np.zeros(NPIX)\n",
    "\n",
    "m_gaia12[df_north.pixel_id.to_numpy()] = df_north.gaia12.to_numpy()\n",
    "mask = (m_gaia12 == 0)\n",
    "m_gaia12[mask] = np.nan\n",
    "hp.mollview(m_gaia12, title=\"gaia12\", format='%e', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0),\n",
    "            badcolor='white', remove_dip=True, remove_mono=True)\n",
    "hp.graticule()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_sagitarius = np.zeros(NPIX)\n",
    "\n",
    "m_sagitarius[df_north.pixel_id.to_numpy()] = df_north.sagitarius.to_numpy()\n",
    "mask = (m_sagitarius == 0)\n",
    "m_sagitarius[mask] = np.nan\n",
    "hp.mollview(m_sagitarius, title=\"sagitarius\", format='%e', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0),\n",
    "            badcolor='white', remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ToDo: Adapt here to read different metrics and sys maps\n",
    "\n",
    "df_stellar = pd.read_csv('../../bricks_data/stellar_catalogue_north.csv')\n",
    "\n",
    "label_1 = 'RMAG'\n",
    "label_2 = 'GMAG'\n",
    "\n",
    "plt.hist2d(df_stellar[label_1], df_stellar[label_2], bins=1000, cmap='jet')\n",
    "plt.xlabel(label_1)\n",
    "plt.ylabel(label_2)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_stellar['GMR'] = df_stellar['GMAG'] - df_stellar['RMAG']\n",
    "df_stellar['RMZ'] = df_stellar['RMAG'] - df_stellar['ZMAG']\n",
    "df_stellar = df_stellar[(df_stellar['GMAG'] > 15) & (df_stellar['GMAG'] < 30)]\n",
    "df_stellar = df_stellar[(df_stellar['ZMAG'] > 15) & (df_stellar['ZMAG'] < 30)]\n",
    "df_stellar = df_stellar[(df_stellar['GMR'] > -2) & (df_stellar['GMR'] < 4)]\n",
    "df_stellar = df_stellar[(df_stellar['RMZ'] > -2) & (df_stellar['RMZ'] < 4)]\n",
    "\n",
    "plt.hist2d(df_stellar[label_1], df_stellar[label_2], bins=1000, cmap='jet')\n",
    "plt.xlabel(label_1)\n",
    "plt.ylabel(label_2)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Dividing RMAG Column into 1000 equally filled bins (assuming within the RMAG of 17-18 this is somewhat uniform)\n",
    "df_stellar['percent_RMAG'] = pd.qcut(df_stellar['RMAG'], q=1000, labels=False)\n",
    "#grouped = df.groupby('percent_RMAG', as_index=False).sem()\n",
    "grouped = df_stellar.groupby('percent_RMAG')\n",
    "zscore = lambda x: abs((x - x.median()) / x.std())\n",
    "df_stellar['Z_SCORE_RMZ'] = grouped['RMZ'].transform(zscore)\n",
    "df_stellar['Z_SCORE_GMR'] = grouped['GMR'].transform(zscore)\n",
    "#Dividing RMAG Column into 100 equally filled bins (assuming within the RMAG of 17-18 this is somewhat uniform)\n",
    "df_stellar['percent_GMR'] = pd.qcut(df_stellar['GMR'], q=1000, labels=False)\n",
    "df_stellar['percent_RMZ'] = pd.qcut(df_stellar['RMZ'], q=1000, labels=False)\n",
    "#grouped = df.groupby('percent_RMAG', as_index=False).sem()\n",
    "grouped = df_stellar.groupby('percent_GMR')\n",
    "df_stellar['Z_SCORE_RMZ'] = grouped['RMZ'].transform(zscore)\n",
    "\n",
    "#grouped = df.groupby('percent_RMAG', as_index=False).sem()\n",
    "grouped = df_stellar.groupby('percent_RMZ')\n",
    "df_stellar['Z_SCORE_GMR'] = grouped['GMR'].transform(zscore)\n",
    "print(df_stellar.shape)\n",
    "df_stellar = df_stellar[(df_stellar['Z_SCORE_GMR'] < 3)]\n",
    "print(df_stellar.shape)\n",
    "df_stellar = df_stellar[(df_stellar['Z_SCORE_RMZ'] < 3)]\n",
    "df_stellar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "label_1 = 'GMR'\n",
    "label_2 = 'RMZ'\n",
    "\n",
    "plt.hist2d(df_stellar[label_1], df_stellar[label_2], bins=1000, cmap='jet')\n",
    "plt.xlabel(label_1)\n",
    "plt.ylabel(label_2)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ra_stellar = df_stellar[\"RA\"].to_numpy(copy=True)\n",
    "dec_stellar = df_stellar[\"DEC\"].to_numpy(copy=True)\n",
    "theta, phi = raDec2thetaPhi(ra_stellar, dec_stellar)\n",
    "\n",
    "print(\"Number of stellars in Sample:\", len(ra_stellar))\n",
    "\n",
    "stellar_pixel_indices = hp.ang2pix(NSIDE, theta, phi)\n",
    "\n",
    "# Finding out unique indices and how often they appear --> shows the density of LRGs in this pixel\n",
    "(unique, counts) = np.unique(stellar_pixel_indices, return_counts=True)\n",
    "mean_stellar = counts.mean()\n",
    "print(\"Mean stellars per Pixel:\", mean_stellar)\n",
    "# Calculating Densities for every block\n",
    "density_stellar = (counts / mean_stellar) - 1\n",
    "id_density = np.stack((unique, counts), axis=1)\n",
    "df_stellar = pd.DataFrame(id_density, columns=['pixel_id', 'stellar'])\n",
    "df_stellar.pixel_id = df_stellar.pixel_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_north = df_north.merge(df_stellar, how='left', on='pixel_id')\n",
    "df_north.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Plotting it\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_Stellar = np.zeros(NPIX)\n",
    "\n",
    "m_Stellar[df_north.pixel_id.to_numpy()] = df_north.stellar.to_numpy()\n",
    "mask = (m_Stellar == 0)\n",
    "m_Stellar[mask] = np.nan\n",
    "hp.mollview(m_Stellar, title=\"Stellar\", format='%e', norm='hist', cmap=\"bwr\", notext=False, rot=(100, 0, 0),\n",
    "            badcolor='white', remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Getting the centers of each pixel in my corpus as RaDec\n",
    "pixels_ids = df_north[\"pixel_id\"].to_numpy()\n",
    "subpixel_coords = hp.pix2ang(NSIDE, pixels_ids, lonlat=True)\n",
    "ra_ebv = subpixel_coords[0]\n",
    "dec_ebv = subpixel_coords[1]\n",
    "#Querying their position on the SFD dustmap\n",
    "sfd = SFDQuery()\n",
    "coords = SkyCoord(ra_ebv, dec_ebv, frame='icrs', unit='deg')\n",
    "ebv = sfd(coords)\n",
    "df_north[\"EBV\"] = ebv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Plotting it\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "m_EBV = np.zeros(NPIX)\n",
    "\n",
    "m_EBV[df_north.pixel_id.to_numpy()] = df_north.EBV.to_numpy()\n",
    "mask = (m_EBV == 0)\n",
    "m_EBV[mask] = np.nan\n",
    "hp.mollview(m_EBV, title=\"EBV\", format='%e', norm='hist', cmap=\"jet\", notext=False, rot=(100, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Work in Coverage Stats and Other Systematics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m_coverage = hp.read_map(\"../../bricks_data/masks/mask_512.fits\")\n",
    "m_coverage = hp.reorder(map_in=m_coverage, n2r=True)\n",
    "\n",
    "unique = np.arange(NPIX)\n",
    "\n",
    "id_density = np.stack((unique, m_coverage), axis=1)\n",
    "\n",
    "df_bad_pix = pd.DataFrame(id_density, columns=['pixel_id', 'coverage'])\n",
    "df_bad_pix.pixel_id = df_bad_pix.pixel_id.astype(int)\n",
    "df_bad_pix = df_bad_pix[df_bad_pix.coverage == 1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m_cover = np.zeros(NPIX)\n",
    "\n",
    "m_cover[df_bad_pix.pixel_id.to_numpy()] = df_bad_pix.coverage.to_numpy()\n",
    "mask = (m_cover < 1)\n",
    "m_cover[mask] = np.nan\n",
    "hp.mollview(m_cover, title=\"Coverage\", format='%e', norm='hist', cmap=\"viridis\", notext=False, rot=(0, 0, 0), badcolor='gray',\n",
    "            remove_dip=True, remove_mono=True)\n",
    "hp.graticule()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(df_north))\n",
    "df_north = pd.merge(df_north, df_bad_pix, how='inner', on='pixel_id')\n",
    "print(len(df_north))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting Systematics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open('../../bricks_data/pixel2systematics_geometric_512_2048_inclusive.pickle', 'rb') as f:\n",
    "    geo_dict_inc = pickle.load(f)\n",
    "    f.close()\n",
    "sys_list = []\n",
    "for key in geo_dict_inc.keys():\n",
    "    ind_sys_list = geo_dict_inc[key]\n",
    "    ind_sys_list.append(key)\n",
    "    sys_list.append(ind_sys_list)\n",
    "\n",
    "df_sys_geo_inc = pd.DataFrame(sys_list, columns=['airmass',\n",
    "                                                'ccdskysb_g',\n",
    "                                                'ccdskysb_r',\n",
    "                                                'ccdskysb_z',\n",
    "                                                'exptime_g',\n",
    "                                                'exptime_r',\n",
    "                                                'exptime_z',\n",
    "                                                'meansky_g',\n",
    "                                                'meansky_r',\n",
    "                                                'meansky_z',\n",
    "                                                'galdepth_g',\n",
    "                                                'galdepth_r',\n",
    "                                                'galdepth_z',\n",
    "                                                'seeing_g',\n",
    "                                                'seeing_r',\n",
    "                                                'seeing_z',\n",
    "                                                'psfdepth_g',\n",
    "                                                'psfdepth_r',\n",
    "                                                'psfdepth_z',\n",
    "                                                'psfnorm_mean_g',\n",
    "                                                'psfnorm_mean_r',\n",
    "                                                'psfnorm_mean_z',\n",
    "                                                'gausspsfdepth_g',\n",
    "                                                'gausspsfdepth_r',\n",
    "                                                'gausspsfdepth_z',\n",
    "                                                'pixel_covered',\n",
    "                                                'pixel_id'])\n",
    "\n",
    "\n",
    "df_north = df_north.merge(df_sys_geo_inc, how='inner', on='pixel_id')\n",
    "print(len(df_north))\n",
    "df_north.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols = list(df_north.columns)\n",
    "cols.remove('pixel_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "nrows = 39\n",
    "ncols = 1\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(200, 200))\n",
    "\n",
    "#fig = plt.figure()\n",
    "i = 0\n",
    "for ax in ax.flatten():\n",
    "    elem = cols[i]\n",
    "\n",
    "    m = np.zeros(NPIX)\n",
    "\n",
    "    m[df_north.pixel_id.to_numpy()] = df_north[elem].to_numpy()\n",
    "    mask = (m == 0)\n",
    "    m[mask] = np.nan\n",
    "    plt.axes(ax)\n",
    "    hp.mollview(m, title=elem, fig=fig, sub=(nrows, ncols, i + 1), format='%e', norm='hist', cmap=\"bwr\", notext=False,\n",
    "                rot=(120, 0, 0), badcolor='white',\n",
    "                remove_dip=True, remove_mono=True, hold=True)\n",
    "    #hp.graticule()\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### Removing all pixels from the other corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "df_north['RA'], df_north['DEC'] = hp.pix2ang(nside=NSIDE, ipix=df_north.pixel_id.to_numpy(), lonlat=True)\n",
    "\n",
    "df_north.head()\n",
    "df_no_island = df_north[df_north.DEC < 15]\n",
    "\n",
    "df_comp = df_north[df_north.DEC > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "m = np.zeros(NPIX)\n",
    "\n",
    "m[df_no_island.pixel_id.to_numpy()] = 100\n",
    "mask = (m == 0)\n",
    "m[mask] = np.nan\n",
    "hp.mollview(m, title='Cut area', format='%e', norm='hist', cmap=\"jet\", notext=False, rot=(120, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True, hold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "m = np.zeros(NPIX)\n",
    "\n",
    "m[df_comp.pixel_id.to_numpy()] = df_comp['pixel_covered'].to_numpy()\n",
    "mask = (m == 0)\n",
    "m[mask] = np.nan\n",
    "hp.mollview(m, title='exposures', format='%e', norm='hist', cmap=\"jet\", notext=False, rot=(120, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True, hold=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### Removing All Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "m = np.zeros(NPIX)\n",
    "\n",
    "m[df_no_island.pixel_id.to_numpy()] = 100\n",
    "mask = (m == 0)\n",
    "m[mask] = np.nan\n",
    "hp.mollview(m, title='Cut area', format='%e', norm='hist', cmap=\"jet\", notext=False, rot=(120, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True, hold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "m = np.zeros(NPIX)\n",
    "\n",
    "m[df_comp.pixel_id.to_numpy()] = df_comp['pixel_covered'].to_numpy()\n",
    "mask = (m == 0)\n",
    "m[mask] = np.nan\n",
    "hp.mollview(m, title='exposures', format='%e', norm='hist', cmap=\"jet\", notext=False, rot=(120, 0, 0), badcolor='white',\n",
    "            remove_dip=True, remove_mono=True, hold=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing All Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_no_outlier = df_north.drop(columns=['galdepth_g',\n",
    "                                      'galdepth_r',\n",
    "                                      'galdepth_z',\n",
    "                                      'psfdepth_g',\n",
    "                                      'psfdepth_r',\n",
    "                                      'psfdepth_z',\n",
    "                                      'psfnorm_mean_g',\n",
    "                                      'psfnorm_mean_r',\n",
    "                                      'psfnorm_mean_z',\n",
    "                                      'gausspsfdepth_g',\n",
    "                                      'gausspsfdepth_r',\n",
    "                                      'gausspsfdepth_z',\n",
    "                                      'RA',\n",
    "                                      'DEC'])\n",
    "\n",
    "col = list(df_no_outlier.columns)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "factor = 7\n",
    "print(len(df_no_outlier))\n",
    "for elem in col:\n",
    "    if elem == 'stellar':\n",
    "        factor = 7\n",
    "    df_no_outlier['Z'] = df_no_outlier[elem].transform(zscore)\n",
    "    print(\"Element: \", elem, \"| No of Elems with Z higher than factor  : \",\n",
    "          len(df_no_outlier[(df_no_outlier['Z'] > factor)]))\n",
    "    df_no_outlier = df_no_outlier[(df_no_outlier['Z'] < factor)]\n",
    "\n",
    "print()\n",
    "print(f\"Galaxies Remaining before outlier removal: {len(df_north)}\")\n",
    "print(f\"Galaxies Remaining after outlier removal: {len(df_no_outlier)}\")\n",
    "print(f\"Elements cut by outlier removal: {len(df_north) - len(df_no_outlier)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "col = list(df_no_outlier.columns)\n",
    "col.remove('pixel_id')\n",
    "col.remove('Z')\n",
    "print(len(col))\n",
    "df_noout = df_no_outlier\n",
    "nrows = 20\n",
    "ncols = 1\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(150,150))\n",
    "\n",
    "#fig = plt.figure()\n",
    "i = 0\n",
    "for ax in ax.flatten():\n",
    "    elem = col[i]\n",
    "    df_noout['Z'] = df_no_outlier[elem].transform(zscore)\n",
    "\n",
    "    df_outlier = df_noout[(df_noout['Z'] > 7)]\n",
    "\n",
    "    m = np.zeros(NPIX)\n",
    "\n",
    "    m[df_outlier.pixel_id.to_numpy()] = 1\n",
    "    mask = (m == 0)\n",
    "    m[mask] = np.nan\n",
    "\n",
    "    plt.axes(ax)\n",
    "    hp.mollview(m, title=elem, fig=fig, sub=(nrows, ncols, i + 1), min=-5, max=2, cbar=False, cmap=\"Reds\", notext=False,\n",
    "                rot=(120, 0, 0), badcolor='white',\n",
    "                remove_dip=True, remove_mono=True, hold=True)\n",
    "    #hp.graticule()\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(df_no_outlier.shape)\n",
    "print(df_no_outlier.exposures.max())\n",
    "print(df_no_outlier.exposures.mean())\n",
    "print(df_no_outlier.exposures.median())\n",
    "print(len(df_no_outlier[df_no_outlier.exposures > 150]))\n",
    "print(len(df_no_outlier[df_no_outlier.pixel_covered < 0.9]))\n",
    "plt.hist(df_no_outlier.exposures)\n",
    "\n",
    "print(len(df_no_outlier[df_no_outlier.exposures < 7]))\n",
    "\n",
    "df_no_outlier = df_no_outlier[df_no_outlier.exposures < 150]\n",
    "df_no_outlier = df_no_outlier[df_no_outlier.pixel_covered > 0.9]\n",
    "print(df_no_outlier.shape)\n",
    "df_no_outlier.exposures.max()\n",
    "df_no_outlier = df_no_outlier.drop(columns=['pixel_covered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "#scaler = RobustScaler()\n",
    "\n",
    "df_scaled = df_no_outlier\n",
    "\n",
    "cololo = list(df_scaled.columns)\n",
    "cololo.remove('pixel_id')\n",
    "cololo.remove('lrg')\n",
    "cololo.remove('elg')\n",
    "cololo.remove('qso')\n",
    "cololo.remove('glbg')\n",
    "cololo.remove('rlbg')\n",
    "df_scaled[cololo] = scaler.fit_transform(df_no_outlier[cololo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ra, dec = hp.pix2ang(NSIDE, df_scaled.pixel_id,lonlat=True)\n",
    "ax = plot_sky_binned(ra,dec,data=df_scaled.lrg ,cmap='bwr',label='lrg', plot_type='grid', verbose=True,max_bin_area=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ax = plot_sky_binned(ra,dec,data=df_scaled.elg ,cmap='bwr',label='elg', plot_type='grid', verbose=True,max_bin_area=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ax = plot_sky_binned(ra,dec,data=df_scaled.qso ,cmap='bwr',label='qso', plot_type='grid', verbose=True,max_bin_area=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "ax = plot_sky_binned(ra,dec,data=df_scaled.glbg ,cmap='bwr',label='qso', plot_type='grid', verbose=True,max_bin_area=0.5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = plot_sky_binned(ra,dec,data=df_scaled.rlbg ,cmap='bwr',label='rlbg', plot_type='grid', verbose=True,max_bin_area=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_scaled, test_size=0.2, random_state=666, shuffle=True)\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "df_train.to_csv('../../bricks_data/north.csv', index=False)\n",
    "df_test.to_csv('../../bricks_data/north_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}