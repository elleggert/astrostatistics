{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### File to evaluate difference in utilising isLRG directly and the full DESI pipeline\n",
    "\n",
    "##### Existing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from astropy.io import fits\n",
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from brick import Brick\n",
    "import telegram_send\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" File to download, process, classify and delete galaxies from DR9 all in one\"\"\"\n",
    "\n",
    "\"\"\" Defining area to download, how many bricks to download in one session and which storage to use (Astrodisk is the name of a hardrive)\"\"\"\n",
    "area = 'south'\n",
    "device = 'Astrostick'\n",
    "bricks_to_classify = 30000\n",
    "south_survey_is_south =  True\n",
    "\n",
    "## ToDo: Create special folder in astrodisk with dedicated bricks\n",
    "hdulistBricksSouthSummary = fits.open('../../bricks_data/survey-bricks-dr9-south.fits')\n",
    "data_south = hdulistBricksSouthSummary[1].data\n",
    "brickname_south = data_south.field('brickname')\n",
    "brickid_south = data_south.field('brickid')\n",
    "south_survey_is_south = data_south.field('survey_primary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================== Process south ..... ==================================\n",
      "\n",
      "No of bricks to classify in south: 1051 \n",
      "Time taken for bricks left extraction:  0.0\n",
      " Brick south processed:  2443p257 , Brick  0  of  30000\n",
      " Brick south processed:  0531m550 , Brick  100  of  30000\n",
      " Brick south processed:  2133m022 , Brick  200  of  30000\n",
      " Brick south processed:  0813m195 , Brick  300  of  30000\n",
      " Brick south processed:  0254p060 , Brick  400  of  30000\n",
      " Brick south processed:  3142p100 , Brick  500  of  30000\n",
      " Brick south processed:  0171p265 , Brick  600  of  30000\n",
      " Brick south processed:  1295p062 , Brick  700  of  30000\n",
      " Brick south processed:  0405p090 , Brick  800  of  30000\n",
      " Brick south processed:  0346m290 , Brick  900  of  30000\n",
      " Brick south processed:  3500p065 , Brick  1000  of  30000\n",
      "\n",
      "=============================== Download south completed ==================================\n",
      "\n",
      "Minutes taken for:  1050  bricks:  15.77\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "# Everything is times in order to measure when the pipeline slows down\n",
    "start = time.time()\n",
    "\n",
    "print()\n",
    "print(f\"=============================== Process {area} ..... ==================================\")\n",
    "print()\n",
    "\n",
    "bricks_name = []\n",
    "bricks_path = []\n",
    "\n",
    "# Getting already downloaded files from the Harddrive:\n",
    "\n",
    "\n",
    "for filename in os.listdir(f'/Volumes/{device}/bricks_data/{area}/'):\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\n",
    "\n",
    "bricks_name.pop()\n",
    "bricks_path.pop()\n",
    "\"\"\"for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\"\"\"\n",
    "\n",
    "\n",
    "# Define empty Dataframes that will hold the information on stars and galaxies\n",
    "df_galaxy = pd.DataFrame(columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "df_stars = pd.DataFrame(columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "\n",
    "\n",
    "\n",
    "# Prints information on the  current session e.g. how many bricks are left --> all the code until here takes a few minutes to complete\n",
    "print(f\"No of bricks to classify in {area}: {len(bricks_name)} \")\n",
    "print(\"Time taken for bricks left extraction: \", round(((time.time() - start) / 60), 2))\n",
    "\n",
    "\n",
    "# There have been problems with very few bricks that were not found on the servers, this code is only to avoid the script from crashing here\n",
    "c = 0\n",
    "problem_bricks = []\n",
    "inter = time.time()\n",
    "\n",
    "\n",
    "# This is the actual loop doing the classification for the bricks that are missing from the catalogue:\n",
    "\n",
    "for i, brickname in enumerate(bricks_name):\n",
    "\n",
    "    # Download Brick\n",
    "\n",
    "\n",
    "\n",
    "    brickid = brickid_south[np.where(brickname_south == brickname)]\n",
    "\n",
    "    # North Bricks\n",
    "    # brickid = brickid_north[np.where(brickname_north == brickname)]\n",
    "\n",
    "    if len(brickid > 0):\n",
    "        brickid = brickid[0]\n",
    "    else:\n",
    "        brickid = 0\n",
    "\n",
    "    # Open Brick\n",
    "\n",
    "\n",
    "\n",
    "    #hdu = fits.open(f'../../bricks_data/tractor/tractor-{brickname}.fits')\n",
    "    hdu = fits.open(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "    data = hdu[1].data\n",
    "\n",
    "    # Define the Brick Object  --> in brick.py\n",
    "    brick = Brick(data)\n",
    "\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)]\n",
    "\n",
    "    south = south_survey_is_south[np.where(brickid_south == brickid)]\n",
    "    if len(south) > 0:\n",
    "        south = south[0]\n",
    "    else:\n",
    "        south = True\n",
    "\n",
    "    ## Enable this is classifying North Objects\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)][0]\n",
    "\n",
    "    # Initialise Brick Object\n",
    "    brick.initialise_brick_for_galaxy_classification(south)\n",
    "\n",
    "    # Classify Brick objects into categories --> takes under 1 second after optimisation\n",
    "    target_objects = brick.classify_galaxies()\n",
    "\n",
    "    # Appending one empty line per brick to be sure that all bricks are extracted\n",
    "    df_galaxy = df_galaxy.append({'BrickID': brickid, 'RA': np.nan, 'DEC': np.nan, 'LRG': 0, 'ELG': 0, 'QSO': 0},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    support_df = pd.DataFrame(target_objects,\n",
    "                              columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "\n",
    "    df_galaxy = df_galaxy.append(support_df)\n",
    "\n",
    "    # Repeat steps for stellar objects\n",
    "\n",
    "    brick.initialise_brick_for_stellar_density()\n",
    "\n",
    "    #stars = brick.get_stellar_objects()\n",
    "\n",
    "    #support_df = pd.DataFrame(stars, columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "    #df_stars = df_stars.append(support_df)\n",
    "\n",
    "    # Every 100 objects, the newly classified objects are added to the existing catalogue to avoid massive reruns when the script crashes\n",
    "\n",
    "    \"\"\"if i % 100 == 0:\n",
    "        print()\n",
    "        print(i / (bricks_to_classify / 100), '%')\n",
    "        df_galaxy = df_galaxy.astype(\n",
    "            {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "        df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        # df_galaxy.to_csv('../../bricks_data/galaxy_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        # df_stars.to_csv('../../bricks_data/stellar_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        df_galaxy = df_galaxy[0:0]\n",
    "        df_stars = df_stars[0:0]\"\"\"\n",
    "\n",
    "    # This script used to send me updates to my phone using a Telegram Bot, so i knew when it crashed or it was completed\n",
    "\n",
    "    # Remove Downloaded Brick\n",
    "    # os.remove(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "\n",
    "    # Stop the loop when the defined number of bricks was classified, if this number is greater than remaining bricks, script will run till all bricks are finished\n",
    "    if i > bricks_to_classify:\n",
    "        break\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\" Brick {area} processed: \", brickname, \", Brick \", i, \" of \", bricks_to_classify)\n",
    "\n",
    "df_galaxy = df_galaxy.astype(\n",
    "    {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "#df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_galaxy = df_galaxy[0:0]\n",
    "#df_stars = df_stars[0:0]\n",
    "print()\n",
    "print(f\"=============================== Download {area} completed ==================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Prints session statistics upon completion\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "# message = f'++++++ Finished {bricks_to_classify} bricks. Avg. Bandwidths: {round(((time.time() - start) / bricks_to_classify), 2)} seconds per brick ++++++'\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0046m020\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 41081\n",
      "ELG: 154533\n",
      "QSO: 195119\n",
      "372459\n",
      "390733\n",
      "-18274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_galaxy.dropna(inplace=True)\n",
    "\n",
    "\n",
    "LRG = df_galaxy[df_galaxy.LRG == 1]\n",
    "print(\"LRG:\", len(LRG))\n",
    "\n",
    "ELG = df_galaxy[df_galaxy.ELG == 1]\n",
    "print(\"ELG:\", len(ELG))\n",
    "\n",
    "QSO = df_galaxy[df_galaxy.QSO == 1]\n",
    "print(\"QSO:\", len(QSO))\n",
    "\n",
    "\n",
    "print(len(df_galaxy))\n",
    "print(len(LRG) + len(ELG) + len(QSO))\n",
    "\n",
    "print(len(df_galaxy) - (len(LRG) + len(ELG) + len(QSO)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilising DesiHub Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n"
     ]
    }
   ],
   "source": [
    "from desitarget.cuts import select_targets\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(f'/Volumes/{device}/bricks_data/{area}/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    filenames.append(f'/Volumes/{device}/bricks_data/{area}/{filename}')\n",
    "\n",
    "filenames.pop()\n",
    "print(len(filenames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 3.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 5.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 7.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 9.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 11.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 12.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 13.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 14.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.0 total mins elapsed\n",
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 2.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 5.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 7.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 9.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 12.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 12.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 14.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 14.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.2 total mins elapsed\n",
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-59-ddf587b16b40>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mtcnames\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'ELG'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackup\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m )\n\u001B[0;32m---> 11\u001B[0;31m qso = select_targets(\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0minfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilenames\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnumproc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mqso_selection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'colorcuts'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnside\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgaiasub\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     tcnames= ['QSO'], backup=False)\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/cuts.py\u001B[0m in \u001B[0;36mselect_targets\u001B[0;34m(infiles, numproc, qso_selection, gaiasub, nside, pixlist, bundlefiles, extra, radecbox, radecrad, mask, tcnames, survey, resolvetargs, backup, return_infiles, test)\u001B[0m\n\u001B[1;32m   3072\u001B[0m         \u001B[0mtargets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3073\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0minfiles\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3074\u001B[0;31m             \u001B[0mtargets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_update_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_select_targets_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3075\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3076\u001B[0m     \u001B[0mtargets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/cuts.py\u001B[0m in \u001B[0;36m_select_targets_file\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m   3036\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_select_targets_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3037\u001B[0m         \u001B[0;34m'''Returns targets in filename that pass the cuts'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3038\u001B[0;31m         \u001B[0mobjects\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_tractor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgaiasub\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgaiasub\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3039\u001B[0m         desi_target, bgs_target, mws_target = apply_cuts(\n\u001B[1;32m   3040\u001B[0m             \u001B[0mobjects\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqso_selection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mqso_selection\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtcnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtcnames\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/io.py\u001B[0m in \u001B[0;36mread_tractor\u001B[0;34m(filename, header, columns, gaiasub)\u001B[0m\n\u001B[1;32m    187\u001B[0m                                   columns=columns)\n\u001B[1;32m    188\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 189\u001B[0;31m         \u001B[0mindata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfitsio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mupper\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    190\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m     \u001B[0;31m# ADM if requested, sub-in Gaia EDR3 proper motions and parallaxes.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/fitsio/fitslib.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(filename, ext, extver, columns, rows, header, case_sensitive, upper, lower, vstorage, verbose, trim_strings, **keys)\u001B[0m\n\u001B[1;32m    149\u001B[0m         \u001B[0mitem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_item\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextver\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mextver\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 151\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfits\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mread_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    152\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m             \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfits\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_header\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/fitsio/hdu/table.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, columns, rows, vstorage, upper, lower, trim_strings, **keys)\u001B[0m\n\u001B[1;32m    711\u001B[0m                 upper=upper, lower=lower, trim_strings=trim_strings)\n\u001B[1;32m    712\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 713\u001B[0;31m             data = self._read_all(\n\u001B[0m\u001B[1;32m    714\u001B[0m                 \u001B[0mvstorage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvstorage\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    715\u001B[0m                 upper=upper, lower=lower, trim_strings=trim_strings)\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/fitsio/hdu/table.py\u001B[0m in \u001B[0;36m_read_all\u001B[0;34m(self, vstorage, upper, lower, trim_strings, colnums, **keys)\u001B[0m\n\u001B[1;32m    776\u001B[0m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 778\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FITS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_as_rec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ext\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    779\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    780\u001B[0m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_decode_fits_ascii_strings_to_unicode_py3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrg = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['LRG'], backup=False\n",
    ")\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "elg = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['ELG'], backup=False\n",
    ")\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "qso = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "qso_rf = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='randomforest', nside=None, gaiasub=False,\n",
    "    tcnames= ['QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "res = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['LRG', 'ELG', 'QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(lrg) + len(elg) + len(qso))\n",
    "\n",
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))\n",
    "print(\"QSO:\", len(qso))\n",
    "print(\"QSO_RF:\", len(qso_rf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    filenames.append(f'/Volumes/{device}/bricks_data/{area}/{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}