{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### File to evaluate difference in utilising isLRG directly and the full DESI pipeline\n",
    "\n",
    "##### Existing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from astropy.io import fits\n",
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from brick import Brick\n",
    "import telegram_send\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" File to download, process, classify and delete galaxies from DR9 all in one\"\"\"\n",
    "\n",
    "\"\"\" Defining area to download, how many bricks to download in one session and which storage to use (Astrodisk is the name of a hardrive)\"\"\"\n",
    "area = 'south'\n",
    "device = 'Astrostick'\n",
    "bricks_to_classify = 30000\n",
    "south_survey_is_south =  True\n",
    "\n",
    "## ToDo: Create special folder in astrodisk with dedicated bricks\n",
    "hdulistBricksSouthSummary = fits.open('../../bricks_data/survey-bricks-dr9-south.fits')\n",
    "data_south = hdulistBricksSouthSummary[1].data\n",
    "brickname_south = data_south.field('brickname')\n",
    "brickid_south = data_south.field('brickid')\n",
    "south_survey_is_south = data_south.field('survey_primary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================== Process south ..... ==================================\n",
      "\n",
      "No of bricks to classify in south: 1051 \n",
      "Time taken for bricks left extraction:  0.0\n",
      " Brick south processed:  2443p257 , Brick  0  of  30000\n",
      " Brick south processed:  0531m550 , Brick  100  of  30000\n",
      " Brick south processed:  2133m022 , Brick  200  of  30000\n",
      " Brick south processed:  0813m195 , Brick  300  of  30000\n",
      " Brick south processed:  0254p060 , Brick  400  of  30000\n",
      " Brick south processed:  3142p100 , Brick  500  of  30000\n",
      " Brick south processed:  0171p265 , Brick  600  of  30000\n",
      " Brick south processed:  1295p062 , Brick  700  of  30000\n",
      " Brick south processed:  0405p090 , Brick  800  of  30000\n",
      " Brick south processed:  0346m290 , Brick  900  of  30000\n",
      " Brick south processed:  3500p065 , Brick  1000  of  30000\n",
      "\n",
      "=============================== Download south completed ==================================\n",
      "\n",
      "Minutes taken for:  1050  bricks:  15.77\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "# Everything is times in order to measure when the pipeline slows down\n",
    "start = time.time()\n",
    "\n",
    "print()\n",
    "print(f\"=============================== Process {area} ..... ==================================\")\n",
    "print()\n",
    "\n",
    "bricks_name = []\n",
    "bricks_path = []\n",
    "\n",
    "# Getting already downloaded files from the Harddrive:\n",
    "\n",
    "\n",
    "for filename in os.listdir(f'/Volumes/{device}/bricks_data/{area}/'):\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\n",
    "\n",
    "bricks_name.pop()\n",
    "bricks_path.pop()\n",
    "\"\"\"for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\"\"\"\n",
    "\n",
    "\n",
    "# Define empty Dataframes that will hold the information on stars and galaxies\n",
    "df_galaxy = pd.DataFrame(columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "df_stars = pd.DataFrame(columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "\n",
    "\n",
    "\n",
    "# Prints information on the  current session e.g. how many bricks are left --> all the code until here takes a few minutes to complete\n",
    "print(f\"No of bricks to classify in {area}: {len(bricks_name)} \")\n",
    "print(\"Time taken for bricks left extraction: \", round(((time.time() - start) / 60), 2))\n",
    "\n",
    "\n",
    "# There have been problems with very few bricks that were not found on the servers, this code is only to avoid the script from crashing here\n",
    "c = 0\n",
    "problem_bricks = []\n",
    "inter = time.time()\n",
    "\n",
    "\n",
    "# This is the actual loop doing the classification for the bricks that are missing from the catalogue:\n",
    "\n",
    "for i, brickname in enumerate(bricks_name):\n",
    "\n",
    "    # Download Brick\n",
    "\n",
    "\n",
    "\n",
    "    brickid = brickid_south[np.where(brickname_south == brickname)]\n",
    "\n",
    "    # North Bricks\n",
    "    # brickid = brickid_north[np.where(brickname_north == brickname)]\n",
    "\n",
    "    if len(brickid > 0):\n",
    "        brickid = brickid[0]\n",
    "    else:\n",
    "        brickid = 0\n",
    "\n",
    "    # Open Brick\n",
    "\n",
    "\n",
    "\n",
    "    #hdu = fits.open(f'../../bricks_data/tractor/tractor-{brickname}.fits')\n",
    "    hdu = fits.open(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "    data = hdu[1].data\n",
    "\n",
    "    # Define the Brick Object  --> in brick.py\n",
    "    brick = Brick(data)\n",
    "\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)]\n",
    "\n",
    "    south = south_survey_is_south[np.where(brickid_south == brickid)]\n",
    "    if len(south) > 0:\n",
    "        south = south[0]\n",
    "    else:\n",
    "        south = True\n",
    "\n",
    "    ## Enable this is classifying North Objects\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)][0]\n",
    "\n",
    "    # Initialise Brick Object\n",
    "    brick.initialise_brick_for_galaxy_classification(south)\n",
    "\n",
    "    # Classify Brick objects into categories --> takes under 1 second after optimisation\n",
    "    target_objects = brick.classify_galaxies()\n",
    "\n",
    "    # Appending one empty line per brick to be sure that all bricks are extracted\n",
    "    df_galaxy = df_galaxy.append({'BrickID': brickid, 'RA': np.nan, 'DEC': np.nan, 'LRG': 0, 'ELG': 0, 'QSO': 0},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    support_df = pd.DataFrame(target_objects,\n",
    "                              columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "\n",
    "    df_galaxy = df_galaxy.append(support_df)\n",
    "\n",
    "    # Repeat steps for stellar objects\n",
    "\n",
    "    brick.initialise_brick_for_stellar_density()\n",
    "\n",
    "    #stars = brick.get_stellar_objects()\n",
    "\n",
    "    #support_df = pd.DataFrame(stars, columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "    #df_stars = df_stars.append(support_df)\n",
    "\n",
    "    # Every 100 objects, the newly classified objects are added to the existing catalogue to avoid massive reruns when the script crashes\n",
    "\n",
    "    \"\"\"if i % 100 == 0:\n",
    "        print()\n",
    "        print(i / (bricks_to_classify / 100), '%')\n",
    "        df_galaxy = df_galaxy.astype(\n",
    "            {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "        df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        # df_galaxy.to_csv('../../bricks_data/galaxy_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        # df_stars.to_csv('../../bricks_data/stellar_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        df_galaxy = df_galaxy[0:0]\n",
    "        df_stars = df_stars[0:0]\"\"\"\n",
    "\n",
    "    # This script used to send me updates to my phone using a Telegram Bot, so i knew when it crashed or it was completed\n",
    "\n",
    "    # Remove Downloaded Brick\n",
    "    # os.remove(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "\n",
    "    # Stop the loop when the defined number of bricks was classified, if this number is greater than remaining bricks, script will run till all bricks are finished\n",
    "    if i > bricks_to_classify:\n",
    "        break\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\" Brick {area} processed: \", brickname, \", Brick \", i, \" of \", bricks_to_classify)\n",
    "\n",
    "df_galaxy = df_galaxy.astype(\n",
    "    {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "#df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_galaxy = df_galaxy[0:0]\n",
    "#df_stars = df_stars[0:0]\n",
    "print()\n",
    "print(f\"=============================== Download {area} completed ==================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Prints session statistics upon completion\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "# message = f'++++++ Finished {bricks_to_classify} bricks. Avg. Bandwidths: {round(((time.time() - start) / bricks_to_classify), 2)} seconds per brick ++++++'\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0046m020\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 41081\n",
      "ELG: 154533\n",
      "QSO: 195119\n",
      "372459\n",
      "390733\n",
      "-18274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_galaxy.dropna(inplace=True)\n",
    "\n",
    "\n",
    "LRG = df_galaxy[df_galaxy.LRG == 1]\n",
    "print(\"LRG:\", len(LRG))\n",
    "\n",
    "ELG = df_galaxy[df_galaxy.ELG == 1]\n",
    "print(\"ELG:\", len(ELG))\n",
    "\n",
    "QSO = df_galaxy[df_galaxy.QSO == 1]\n",
    "print(\"QSO:\", len(QSO))\n",
    "\n",
    "\n",
    "print(len(df_galaxy))\n",
    "print(len(LRG) + len(ELG) + len(QSO))\n",
    "\n",
    "print(len(df_galaxy) - (len(LRG) + len(ELG) + len(QSO)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilising DesiHub Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from desitarget.cuts import select_targets\n",
    "filenames = []\n",
    "\n",
    "#path = f'/Volumes/{device}/bricks_data/{area}/'\n",
    "path = '../../bricks_data/tractor/'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    filenames.append(f'{path}/{filename}')\n",
    "print(len(filenames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2944:select_targets: Running on the main survey\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'ProcessBackend.StorageFactory.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-b9e0a5c1b7b6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m lrg = select_targets(\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0minfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilenames\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnumproc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mqso_selection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'colorcuts'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnside\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgaiasub\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mtcnames\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'LRG'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackup\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/cuts.py\u001B[0m in \u001B[0;36mselect_targets\u001B[0;34m(infiles, numproc, qso_selection, gaiasub, nside, pixlist, bundlefiles, extra, radecbox, radecrad, mask, tcnames, survey, resolvetargs, backup, return_infiles, test)\u001B[0m\n\u001B[1;32m   3069\u001B[0m         \u001B[0mpool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msharedmem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMapReduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumproc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3070\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mpool\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3071\u001B[0;31m             targets = pool.map(_select_targets_file, infiles,\n\u001B[0m\u001B[1;32m   3072\u001B[0m                                reduce=_update_status)\n\u001B[1;32m   3073\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/internal/sharedmem.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, sequence, reduce, star)\u001B[0m\n\u001B[1;32m    641\u001B[0m                 args=(Q, R, sequence, realfunc))\n\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 643\u001B[0;31m         \u001B[0mpg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    644\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    645\u001B[0m         \u001B[0mL\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/desitarget/internal/sharedmem.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    350\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    351\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mP\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 352\u001B[0;31m             \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    354\u001B[0m         \u001B[0;31m# p is alive from the moment start returns.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/process.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    119\u001B[0m                \u001B[0;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/context.py\u001B[0m in \u001B[0;36m_Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 224\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/context.py\u001B[0m in \u001B[0;36m_Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    282\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m             \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mpopen_spawn_posix\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 284\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    285\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[0;32mclass\u001B[0m \u001B[0mForkServerProcess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBaseProcess\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mduplicate_for_child\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/popen_fork.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinalizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_launch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mduplicate_for_child\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001B[0m in \u001B[0;36m_launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     45\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mreduction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m             \u001B[0mreduction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m             \u001B[0mset_spawning_popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/astro/lib/python3.8/multiprocessing/reduction.py\u001B[0m in \u001B[0;36mdump\u001B[0;34m(obj, file, protocol)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m     \u001B[0mForkingPickler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: Can't pickle local object 'ProcessBackend.StorageFactory.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrg = select_targets(\n",
    "    infiles=filenames,numproc=4,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['LRG'], backup=False\n",
    ")\n",
    "\n",
    "print(len(lrg))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "elg = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['ELG'], backup=False\n",
    ")\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 3.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 6.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 8.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 10.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 12.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 13.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 14.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 15.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.3 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  15.47\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "qso = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 5.8 secs/file; 1.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 5.8 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 5.6 secs/file; 5.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 5.6 secs/file; 7.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 5.6 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 5.6 secs/file; 11.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 5.6 secs/file; 13.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 5.6 secs/file; 14.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 5.6 secs/file; 16.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 5.5 secs/file; 18.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 5.5 secs/file; 20.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 5.5 secs/file; 22.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 5.5 secs/file; 23.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 5.5 secs/file; 25.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 5.5 secs/file; 27.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 5.5 secs/file; 29.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 5.5 secs/file; 31.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 5.5 secs/file; 33.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 5.5 secs/file; 35.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 5.5 secs/file; 36.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 5.5 secs/file; 38.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 5.5 secs/file; 40.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 5.5 secs/file; 42.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 5.5 secs/file; 44.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 5.5 secs/file; 45.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 5.5 secs/file; 47.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 5.5 secs/file; 49.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 5.5 secs/file; 50.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 5.4 secs/file; 52.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 5.4 secs/file; 54.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 5.4 secs/file; 56.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 5.4 secs/file; 58.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 5.4 secs/file; 59.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 5.4 secs/file; 61.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 5.4 secs/file; 63.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 5.4 secs/file; 65.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 5.4 secs/file; 67.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 5.4 secs/file; 68.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 5.4 secs/file; 70.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 5.4 secs/file; 72.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 5.4 secs/file; 74.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 5.4 secs/file; 75.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 5.4 secs/file; 77.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 5.4 secs/file; 79.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 5.4 secs/file; 81.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 5.4 secs/file; 82.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 5.4 secs/file; 84.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 5.4 secs/file; 86.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 5.4 secs/file; 88.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 5.4 secs/file; 90.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 5.4 secs/file; 92.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 5.4 secs/file; 93.7 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  94.57\n",
      "Hours taken for:  1050  bricks:  1.58\n",
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 5.1 secs/file; 1.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 5.1 secs/file; 3.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 5.0 secs/file; 5.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 5.0 secs/file; 6.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 5.1 secs/file; 8.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 5.1 secs/file; 10.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 5.0 secs/file; 11.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 5.0 secs/file; 13.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 5.1 secs/file; 15.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 5.0 secs/file; 16.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 5.0 secs/file; 18.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 5.0 secs/file; 20.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 5.0 secs/file; 21.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 5.0 secs/file; 23.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 5.0 secs/file; 25.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 5.1 secs/file; 26.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 5.1 secs/file; 28.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 5.1 secs/file; 30.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 5.1 secs/file; 32.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 5.1 secs/file; 33.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 5.0 secs/file; 35.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 5.0 secs/file; 37.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 5.1 secs/file; 38.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 5.0 secs/file; 40.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 5.0 secs/file; 41.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 5.0 secs/file; 43.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 5.0 secs/file; 45.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 5.0 secs/file; 46.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 5.0 secs/file; 48.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 5.0 secs/file; 49.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 5.0 secs/file; 51.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 5.0 secs/file; 53.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 5.0 secs/file; 54.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 5.0 secs/file; 56.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 5.0 secs/file; 58.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 5.0 secs/file; 59.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 5.0 secs/file; 61.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 5.0 secs/file; 63.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 5.0 secs/file; 64.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 5.0 secs/file; 66.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 5.0 secs/file; 68.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 5.0 secs/file; 69.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 5.0 secs/file; 71.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 5.0 secs/file; 72.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 5.0 secs/file; 74.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 5.0 secs/file; 76.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 5.0 secs/file; 77.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 5.0 secs/file; 79.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 5.0 secs/file; 81.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 5.0 secs/file; 82.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 5.0 secs/file; 84.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 5.0 secs/file; 86.1 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  86.9\n",
      "Hours taken for:  1050  bricks:  1.45\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "qso_rf = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='randomforest', nside=None, gaiasub=False,\n",
    "    tcnames= ['QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 3.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 6.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 8.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 10.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 12.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 12.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 14.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 14.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.2 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  15.31\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "res = select_targets(\n",
    "    infiles=filenames,numproc=1,qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames= ['LRG', 'ELG', 'QSO'], backup=False)\n",
    "\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 40569\n",
      "ELG: 152287\n"
     ]
    }
   ],
   "source": [
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211869\n",
      "LRG: 40569\n",
      "ELG: 152287\n",
      "QSO: 19013\n",
      "QSO_RF: 19907\n",
      "All: 206874\n"
     ]
    }
   ],
   "source": [
    "print(len(lrg) + len(elg) + len(qso))\n",
    "\n",
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))\n",
    "print(\"QSO:\", len(qso))\n",
    "print(\"QSO_RF:\", len(qso_rf))\n",
    "print(\"All:\", len(res))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    filenames.append(f'/Volumes/{device}/bricks_data/{area}/{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}