{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### File to evaluate difference in utilising isLRG directly and the full DESI pipeline\n",
    "\n",
    "##### Existing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from astropy.io import fits\n",
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from brick import Brick\n",
    "import telegram_send\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" File to download, process, classify and delete galaxies from DR9 all in one\"\"\"\n",
    "\n",
    "\"\"\" Defining area to download, how many bricks to download in one session and which storage to use (Astrodisk is the name of a hardrive)\"\"\"\n",
    "area = 'south'\n",
    "device = 'Astrostick'\n",
    "bricks_to_classify = 30000\n",
    "south_survey_is_south = True\n",
    "\n",
    "## ToDo: Create special folder in astrodisk with dedicated bricks\n",
    "hdulistBricksSouthSummary = fits.open('../../bricks_data/survey-bricks-dr9-south.fits')\n",
    "data_south = hdulistBricksSouthSummary[1].data\n",
    "brickname_south = data_south.field('brickname')\n",
    "brickid_south = data_south.field('brickid')\n",
    "south_survey_is_south = data_south.field('survey_primary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================== Process south ..... ==================================\n",
      "\n",
      "No of bricks to classify in south: 1051 \n",
      "Time taken for bricks left extraction:  0.0\n",
      " Brick south processed:  2443p257 , Brick  0  of  30000\n",
      " Brick south processed:  0531m550 , Brick  100  of  30000\n",
      " Brick south processed:  2133m022 , Brick  200  of  30000\n",
      " Brick south processed:  0813m195 , Brick  300  of  30000\n",
      " Brick south processed:  0254p060 , Brick  400  of  30000\n",
      " Brick south processed:  3142p100 , Brick  500  of  30000\n",
      " Brick south processed:  0171p265 , Brick  600  of  30000\n",
      " Brick south processed:  1295p062 , Brick  700  of  30000\n",
      " Brick south processed:  0405p090 , Brick  800  of  30000\n",
      " Brick south processed:  0346m290 , Brick  900  of  30000\n",
      " Brick south processed:  3500p065 , Brick  1000  of  30000\n",
      "\n",
      "=============================== Download south completed ==================================\n",
      "\n",
      "Minutes taken for:  1050  bricks:  15.77\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "# Everything is times in order to measure when the pipeline slows down\n",
    "start = time.time()\n",
    "\n",
    "print()\n",
    "print(f\"=============================== Process {area} ..... ==================================\")\n",
    "print()\n",
    "\n",
    "bricks_name = []\n",
    "bricks_path = []\n",
    "\n",
    "# Getting already downloaded files from the Harddrive:\n",
    "\n",
    "\n",
    "for filename in os.listdir(f'/Volumes/{device}/bricks_data/{area}/'):\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\n",
    "\n",
    "bricks_name.pop()\n",
    "bricks_path.pop()\n",
    "\"\"\"for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    brickn = filename.replace(\"tractor-\", \"\")\n",
    "    brickn = brickn.replace(\".fits\", \"\")\n",
    "    bricks_path.append(filename)\n",
    "    bricks_name.append(brickn)\"\"\"\n",
    "\n",
    "# Define empty Dataframes that will hold the information on stars and galaxies\n",
    "df_galaxy = pd.DataFrame(columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "df_stars = pd.DataFrame(columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "\n",
    "# Prints information on the  current session e.g. how many bricks are left --> all the code until here takes a few minutes to complete\n",
    "print(f\"No of bricks to classify in {area}: {len(bricks_name)} \")\n",
    "print(\"Time taken for bricks left extraction: \", round(((time.time() - start) / 60), 2))\n",
    "\n",
    "# There have been problems with very few bricks that were not found on the servers, this code is only to avoid the script from crashing here\n",
    "c = 0\n",
    "problem_bricks = []\n",
    "inter = time.time()\n",
    "\n",
    "# This is the actual loop doing the classification for the bricks that are missing from the catalogue:\n",
    "\n",
    "for i, brickname in enumerate(bricks_name):\n",
    "\n",
    "    # Download Brick\n",
    "\n",
    "    brickid = brickid_south[np.where(brickname_south == brickname)]\n",
    "\n",
    "    # North Bricks\n",
    "    # brickid = brickid_north[np.where(brickname_north == brickname)]\n",
    "\n",
    "    if len(brickid > 0):\n",
    "        brickid = brickid[0]\n",
    "    else:\n",
    "        brickid = 0\n",
    "\n",
    "    # Open Brick\n",
    "\n",
    "    #hdu = fits.open(f'../../bricks_data/tractor/tractor-{brickname}.fits')\n",
    "    hdu = fits.open(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "    data = hdu[1].data\n",
    "\n",
    "    # Define the Brick Object  --> in brick.py\n",
    "    brick = Brick(data)\n",
    "\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)]\n",
    "\n",
    "    south = south_survey_is_south[np.where(brickid_south == brickid)]\n",
    "    if len(south) > 0:\n",
    "        south = south[0]\n",
    "    else:\n",
    "        south = True\n",
    "\n",
    "    ## Enable this is classifying North Objects\n",
    "    # south = north_survey_is_south[np.where(brickid_north == brickid)][0]\n",
    "\n",
    "    # Initialise Brick Object\n",
    "    brick.initialise_brick_for_galaxy_classification(south)\n",
    "\n",
    "    # Classify Brick objects into categories --> takes under 1 second after optimisation\n",
    "    target_objects = brick.classify_galaxies()\n",
    "\n",
    "    # Appending one empty line per brick to be sure that all bricks are extracted\n",
    "    df_galaxy = df_galaxy.append({'BrickID': brickid, 'RA': np.nan, 'DEC': np.nan, 'LRG': 0, 'ELG': 0, 'QSO': 0},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    support_df = pd.DataFrame(target_objects,\n",
    "                              columns=['BrickID', 'RA', 'DEC', 'LRG', 'ELG', 'QSO'])\n",
    "\n",
    "    df_galaxy = df_galaxy.append(support_df)\n",
    "\n",
    "    # Repeat steps for stellar objects\n",
    "\n",
    "    brick.initialise_brick_for_stellar_density()\n",
    "\n",
    "    #stars = brick.get_stellar_objects()\n",
    "\n",
    "    #support_df = pd.DataFrame(stars, columns=['RA', 'DEC', 'GMAG', 'RMAG', 'ZMAG'])\n",
    "    #df_stars = df_stars.append(support_df)\n",
    "\n",
    "    # Every 100 objects, the newly classified objects are added to the existing catalogue to avoid massive reruns when the script crashes\n",
    "\n",
    "    \"\"\"if i % 100 == 0:\n",
    "        print()\n",
    "        print(i / (bricks_to_classify / 100), '%')\n",
    "        df_galaxy = df_galaxy.astype(\n",
    "            {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "        df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "        # df_galaxy.to_csv('../../bricks_data/galaxy_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        # df_stars.to_csv('../../bricks_data/stellar_catalogue_sample_profiling.csv', index=False, header=False)\n",
    "        df_galaxy = df_galaxy[0:0]\n",
    "        df_stars = df_stars[0:0]\"\"\"\n",
    "\n",
    "    # This script used to send me updates to my phone using a Telegram Bot, so i knew when it crashed or it was completed\n",
    "\n",
    "    # Remove Downloaded Brick\n",
    "    # os.remove(f'/Volumes/{device}/bricks_data/{area}/tractor-{brickname}.fits')\n",
    "\n",
    "    # Stop the loop when the defined number of bricks was classified, if this number is greater than remaining bricks, script will run till all bricks are finished\n",
    "    if i > bricks_to_classify:\n",
    "        break\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\" Brick {area} processed: \", brickname, \", Brick \", i, \" of \", bricks_to_classify)\n",
    "\n",
    "df_galaxy = df_galaxy.astype(\n",
    "    {'BrickID': 'int32', 'LRG': 'int8', 'ELG': 'int8', 'QSO': 'int8'})\n",
    "#df_galaxy.to_csv(f'../../bricks_data/galaxy_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_stars.to_csv(f'../../bricks_data/stellar_catalogue_{area}.csv', mode='a', index=False, header=False)\n",
    "#df_galaxy = df_galaxy[0:0]\n",
    "#df_stars = df_stars[0:0]\n",
    "print()\n",
    "print(f\"=============================== Download {area} completed ==================================\")\n",
    "print()\n",
    "\n",
    "# Prints session statistics upon completion\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "# message = f'++++++ Finished {bricks_to_classify} bricks. Avg. Bandwidths: {round(((time.time() - start) / bricks_to_classify), 2)} seconds per brick ++++++'\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0046m020\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 41081\n",
      "ELG: 154533\n",
      "QSO: 195119\n",
      "372459\n",
      "390733\n",
      "-18274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_galaxy.dropna(inplace=True)\n",
    "\n",
    "LRG = df_galaxy[df_galaxy.LRG == 1]\n",
    "print(\"LRG:\", len(LRG))\n",
    "\n",
    "ELG = df_galaxy[df_galaxy.ELG == 1]\n",
    "print(\"ELG:\", len(ELG))\n",
    "\n",
    "QSO = df_galaxy[df_galaxy.QSO == 1]\n",
    "print(\"QSO:\", len(QSO))\n",
    "\n",
    "print(len(df_galaxy))\n",
    "print(len(LRG) + len(ELG) + len(QSO))\n",
    "\n",
    "print(len(df_galaxy) - (len(LRG) + len(ELG) + len(QSO)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilising DesiHub Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from desitarget.cuts import select_targets\n",
    "\n",
    "filenames = []\n",
    "\n",
    "#path = f'/Volumes/{device}/bricks_data/{area}/'\n",
    "path = '../../bricks_data/tractor/'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if '.fits' not in filename:\n",
    "        continue\n",
    "    filenames.append(f'{path}/{filename}')\n",
    "print(len(filenames))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "res = select_targets(\n",
    "    infiles=filenames, numproc=1, qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames=['LRG', 'ELG', 'QSO'], backup=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = [('RELEASE', '>i2'), ('BRICKID', '>i4'), ('BRICKNAME', 'S8'), ('BRICK_OBJID', '>i4'), ('MORPHTYPE', 'S4'), ('RA', '>f8'), ('RA_IVAR', '>f4'), ('DEC', '>f8'), ('DEC_IVAR', '>f4'), ('DCHISQ', '>f4', (5,)), ('EBV', '>f4'), ('FLUX_G', '>f4'), ('FLUX_R', '>f4'), ('FLUX_Z', '>f4'), ('FLUX_IVAR_G', '>f4'), ('FLUX_IVAR_R', '>f4'), ('FLUX_IVAR_Z', '>f4'), ('MW_TRANSMISSION_G', '>f4'), ('MW_TRANSMISSION_R', '>f4'), ('MW_TRANSMISSION_Z', '>f4'), ('FRACFLUX_G', '>f4'), ('FRACFLUX_R', '>f4'), ('FRACFLUX_Z', '>f4'), ('FRACMASKED_G', '>f4'), ('FRACMASKED_R', '>f4'), ('FRACMASKED_Z', '>f4'), ('FRACIN_G', '>f4'), ('FRACIN_R', '>f4'), ('FRACIN_Z', '>f4'), ('NOBS_G', '>i2'), ('NOBS_R', '>i2'), ('NOBS_Z', '>i2'), ('PSFDEPTH_G', '>f4'), ('PSFDEPTH_R', '>f4'), ('PSFDEPTH_Z', '>f4'), ('GALDEPTH_G', '>f4'), ('GALDEPTH_R', '>f4'), ('GALDEPTH_Z', '>f4'), ('FLUX_W1', '>f4'), ('FLUX_W2', '>f4'), ('FLUX_W3', '>f4'), ('FLUX_W4', '>f4'), ('FLUX_IVAR_W1', '>f4'), ('FLUX_IVAR_W2', '>f4'), ('FLUX_IVAR_W3', '>f4'), ('FLUX_IVAR_W4', '>f4'), ('MW_TRANSMISSION_W1', '>f4'), ('MW_TRANSMISSION_W2', '>f4'), ('MW_TRANSMISSION_W3', '>f4'), ('MW_TRANSMISSION_W4', '>f4'), ('ALLMASK_G', '>i2'), ('ALLMASK_R', '>i2'), ('ALLMASK_Z', '>i2'), ('FIBERFLUX_G', '>f4'), ('FIBERFLUX_R', '>f4'), ('FIBERFLUX_Z', '>f4'), ('FIBERTOTFLUX_G', '>f4'), ('FIBERTOTFLUX_R', '>f4'), ('FIBERTOTFLUX_Z', '>f4'), ('REF_EPOCH', '>f4'), ('WISEMASK_W1', 'u1'), ('WISEMASK_W2', 'u1'), ('MASKBITS', '>i2'), ('LC_FLUX_W1', '>f4', (15,)), ('LC_FLUX_W2', '>f4', (15,)), ('LC_FLUX_IVAR_W1', '>f4', (15,)), ('LC_FLUX_IVAR_W2', '>f4', (15,)), ('LC_NOBS_W1', '>i2', (15,)), ('LC_NOBS_W2', '>i2', (15,)), ('LC_MJD_W1', '>f8', (15,)), ('LC_MJD_W2', '>f8', (15,)), ('SHAPE_R', '>f4'), ('SHAPE_E1', '>f4'), ('SHAPE_E2', '>f4'), ('SHAPE_R_IVAR', '>f4'), ('SHAPE_E1_IVAR', '>f4'), ('SHAPE_E2_IVAR', '>f4'), ('SERSIC', '>f4'), ('SERSIC_IVAR', '>f4'), ('REF_ID', '>i8'), ('REF_CAT', 'S2'), ('GAIA_PHOT_G_MEAN_MAG', '>f4'), ('GAIA_PHOT_G_MEAN_FLUX_OVER_ERROR', '>f4'), ('GAIA_PHOT_BP_MEAN_MAG', '>f4'), ('GAIA_PHOT_BP_MEAN_FLUX_OVER_ERROR', '>f4'), ('GAIA_PHOT_RP_MEAN_MAG', '>f4'), ('GAIA_PHOT_RP_MEAN_FLUX_OVER_ERROR', '>f4'), ('GAIA_PHOT_BP_RP_EXCESS_FACTOR', '>f4'), ('GAIA_ASTROMETRIC_EXCESS_NOISE', '>f4'), ('GAIA_DUPLICATED_SOURCE', '?'), ('GAIA_ASTROMETRIC_SIGMA5D_MAX', '>f4'), ('GAIA_ASTROMETRIC_PARAMS_SOLVED', 'i1'), ('PARALLAX', '>f4'), ('PARALLAX_IVAR', '>f4'), ('PMRA', '>f4'), ('PMRA_IVAR', '>f4'), ('PMDEC', '>f4'), ('PMDEC_IVAR', '>f4'), ('PHOTSYS', '<U1'), ('TARGETID', '>i8'), ('DESI_TARGET', '>i8'), ('BGS_TARGET', '>i8'), ('MWS_TARGET', '>i8'), ('SUBPRIORITY', '>f8'), ('OBSCONDITIONS', '>i8'), ('PRIORITY_INIT_DARK', '>i8'), ('NUMOBS_INIT_DARK', '>i8'), ('PRIORITY_INIT_BRIGHT', '>i8'), ('NUMOBS_INIT_BRIGHT', '>i8'), ('PRIORITY_INIT_BACKUP', '>i8'), ('NUMOBS_INIT_BACKUP', '>i8')]\n",
    "\n",
    "print(len(cols))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELEASE: 9010 : <class 'numpy.int16'>\n",
      "BRICKID: 328928 : <class 'numpy.int32'>\n",
      "BRICKNAME: b'0001m002' : <class 'numpy.bytes_'>\n",
      "BRICK_OBJID: 3 : <class 'numpy.int32'>\n",
      "MORPHTYPE: b'EXP' : <class 'numpy.bytes_'>\n",
      "RA: 2.6321134110392527e-05 : <class 'numpy.float64'>\n",
      "RA_IVAR: 533174714368.0 : <class 'numpy.float32'>\n",
      "DEC: -0.2764820789058644 : <class 'numpy.float64'>\n",
      "DEC_IVAR: 269623934976.0 : <class 'numpy.float32'>\n",
      "DCHISQ: [16063.554 19630.223 20872.037 21205.998 21222.172] : <class 'numpy.ndarray'>\n",
      "EBV: 0.033942051231861115 : <class 'numpy.float32'>\n",
      "FLUX_G: 1.2683279514312744 : <class 'numpy.float32'>\n",
      "FLUX_R: 4.2349724769592285 : <class 'numpy.float32'>\n",
      "FLUX_Z: 9.841989517211914 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_G: 1138.33642578125 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_R: 919.9418334960938 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_Z: 93.57672119140625 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_G: 0.9044073820114136 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_R: 0.9345578551292419 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_Z: 0.9628496170043945 : <class 'numpy.float32'>\n",
      "FRACFLUX_G: 0.015316125936806202 : <class 'numpy.float32'>\n",
      "FRACFLUX_R: 0.0008044614223763347 : <class 'numpy.float32'>\n",
      "FRACFLUX_Z: 0.0006294545019045472 : <class 'numpy.float32'>\n",
      "FRACMASKED_G: 0.16594873368740082 : <class 'numpy.float32'>\n",
      "FRACMASKED_R: 0.002800221787765622 : <class 'numpy.float32'>\n",
      "FRACMASKED_Z: 0.004122273996472359 : <class 'numpy.float32'>\n",
      "FRACIN_G: 1.0000001192092896 : <class 'numpy.float32'>\n",
      "FRACIN_R: 1.0 : <class 'numpy.float32'>\n",
      "FRACIN_Z: 1.0 : <class 'numpy.float32'>\n",
      "NOBS_G: 8 : <class 'numpy.int16'>\n",
      "NOBS_R: 8 : <class 'numpy.int16'>\n",
      "NOBS_Z: 7 : <class 'numpy.int16'>\n",
      "PSFDEPTH_G: 2610.4638671875 : <class 'numpy.float32'>\n",
      "PSFDEPTH_R: 2647.658935546875 : <class 'numpy.float32'>\n",
      "PSFDEPTH_Z: 246.2958526611328 : <class 'numpy.float32'>\n",
      "GALDEPTH_G: 1625.1475830078125 : <class 'numpy.float32'>\n",
      "GALDEPTH_R: 1435.4541015625 : <class 'numpy.float32'>\n",
      "GALDEPTH_Z: 130.22938537597656 : <class 'numpy.float32'>\n",
      "FLUX_W1: 49.150543212890625 : <class 'numpy.float32'>\n",
      "FLUX_W2: 44.62909698486328 : <class 'numpy.float32'>\n",
      "FLUX_W3: 42.11628341674805 : <class 'numpy.float32'>\n",
      "FLUX_W4: -827.371337890625 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_W1: 1.7236219644546509 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_W2: 0.4838968813419342 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_W3: 0.0006575150182470679 : <class 'numpy.float32'>\n",
      "FLUX_IVAR_W4: 9.626007340557408e-06 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_W1: 0.9942643642425537 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_W2: 0.9964736700057983 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_W3: 0.9992468953132629 : <class 'numpy.float32'>\n",
      "MW_TRANSMISSION_W4: 0.9997155666351318 : <class 'numpy.float32'>\n",
      "ALLMASK_G: 0 : <class 'numpy.int16'>\n",
      "ALLMASK_R: 0 : <class 'numpy.int16'>\n",
      "ALLMASK_Z: 0 : <class 'numpy.int16'>\n",
      "FIBERFLUX_G: 0.5578415989875793 : <class 'numpy.float32'>\n",
      "FIBERFLUX_R: 1.8626444339752197 : <class 'numpy.float32'>\n",
      "FIBERFLUX_Z: 4.328747272491455 : <class 'numpy.float32'>\n",
      "FIBERTOTFLUX_G: 0.5580182671546936 : <class 'numpy.float32'>\n",
      "FIBERTOTFLUX_R: 1.8629769086837769 : <class 'numpy.float32'>\n",
      "FIBERTOTFLUX_Z: 4.329250335693359 : <class 'numpy.float32'>\n",
      "REF_EPOCH: 0.0 : <class 'numpy.float32'>\n",
      "WISEMASK_W1: 33 : <class 'numpy.uint8'>\n",
      "WISEMASK_W2: 32 : <class 'numpy.uint8'>\n",
      "MASKBITS: 2816 : <class 'numpy.int16'>\n",
      "LC_FLUX_W1: [40.811623 45.88989  43.41646  46.031868 45.135185 47.54146  44.88717\n",
      " 52.798203 50.106236 51.58524  47.02751  47.15758  52.99815  51.66781\n",
      " 49.136158] : <class 'numpy.ndarray'>\n",
      "LC_FLUX_W2: [50.635464 51.561764 54.26772  36.638477 44.97748  31.317495 50.091007\n",
      " 39.40023  51.764114 34.474876 45.812042 41.57274  53.390053 33.0347\n",
      " 47.904644] : <class 'numpy.ndarray'>\n",
      "LC_FLUX_IVAR_W1: [0.17229208 0.20676084 0.23180076 0.18913926 0.1987882  0.20712903\n",
      " 0.24402767 0.14622244 0.2598118  0.20056665 0.24488197 0.16915505\n",
      " 0.20062456 0.16813791 0.25414938] : <class 'numpy.ndarray'>\n",
      "LC_FLUX_IVAR_W2: [0.04966743 0.04947893 0.04451691 0.04199985 0.04076623 0.04714753\n",
      " 0.04881112 0.0288746  0.04092222 0.03711238 0.04570061 0.03382246\n",
      " 0.04140823 0.0284045  0.04458009] : <class 'numpy.ndarray'>\n",
      "LC_NOBS_W1: [ 9 12 14 10 11 11 12  9 16 11 12 10 10 11 12] : <class 'numpy.ndarray'>\n",
      "LC_NOBS_W2: [10 12 14 11 11 12 12  9 13 11 12 11 11 11 12] : <class 'numpy.ndarray'>\n",
      "LC_MJD_W1: [55368.45278979 55548.18669039 56645.42586916 56833.33774764\n",
      " 57010.21050665 57195.14794965 57369.3954468  57559.29981492\n",
      " 57729.98371882 57926.46970933 58092.00260836 58290.5381891\n",
      " 58452.65774165 58654.71785134 58816.91426742] : <class 'numpy.ndarray'>\n",
      "LC_MJD_W2: [55368.45278979 55548.18669039 56645.42586916 56833.33774764\n",
      " 57010.21050665 57195.14794965 57369.3954468  57559.29981492\n",
      " 57729.98371882 57926.46970933 58092.00260836 58290.5381891\n",
      " 58452.65774165 58654.71785134 58816.91426742] : <class 'numpy.ndarray'>\n",
      "SHAPE_R: 0.9093317985534668 : <class 'numpy.float32'>\n",
      "SHAPE_E1: 0.3411591649055481 : <class 'numpy.float32'>\n",
      "SHAPE_E2: -0.3402707278728485 : <class 'numpy.float32'>\n",
      "SHAPE_R_IVAR: 13296.818359375 : <class 'numpy.float32'>\n",
      "SHAPE_E1_IVAR: 8971.0400390625 : <class 'numpy.float32'>\n",
      "SHAPE_E2_IVAR: 8753.5908203125 : <class 'numpy.float32'>\n",
      "SERSIC: 1.0 : <class 'numpy.float32'>\n",
      "SERSIC_IVAR: 0.0 : <class 'numpy.float32'>\n",
      "REF_ID: 0 : <class 'numpy.int64'>\n",
      "REF_CAT: b'' : <class 'numpy.bytes_'>\n",
      "GAIA_PHOT_G_MEAN_MAG: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_G_MEAN_FLUX_OVER_ERROR: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_BP_MEAN_MAG: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_BP_MEAN_FLUX_OVER_ERROR: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_RP_MEAN_MAG: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_RP_MEAN_FLUX_OVER_ERROR: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_PHOT_BP_RP_EXCESS_FACTOR: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_ASTROMETRIC_EXCESS_NOISE: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_DUPLICATED_SOURCE: False : <class 'numpy.bool_'>\n",
      "GAIA_ASTROMETRIC_SIGMA5D_MAX: 0.0 : <class 'numpy.float32'>\n",
      "GAIA_ASTROMETRIC_PARAMS_SOLVED: 0 : <class 'numpy.int8'>\n",
      "PARALLAX: 0.0 : <class 'numpy.float32'>\n",
      "PARALLAX_IVAR: 0.0 : <class 'numpy.float32'>\n",
      "PMRA: 0.0 : <class 'numpy.float32'>\n",
      "PMRA_IVAR: 0.0 : <class 'numpy.float32'>\n",
      "PMDEC: 0.0 : <class 'numpy.float32'>\n",
      "PMDEC_IVAR: 0.0 : <class 'numpy.float32'>\n",
      "PHOTSYS: S : <class 'numpy.str_'>\n",
      "TARGETID: 39627778689073155 : <class 'numpy.int64'>\n",
      "DESI_TARGET: 65537 : <class 'numpy.int64'>\n",
      "BGS_TARGET: 0 : <class 'numpy.int64'>\n",
      "MWS_TARGET: 0 : <class 'numpy.int64'>\n",
      "SUBPRIORITY: 0.0 : <class 'numpy.float64'>\n",
      "OBSCONDITIONS: 1 : <class 'numpy.int64'>\n",
      "PRIORITY_INIT_DARK: 3200 : <class 'numpy.int64'>\n",
      "NUMOBS_INIT_DARK: 2 : <class 'numpy.int64'>\n",
      "PRIORITY_INIT_BRIGHT: -1 : <class 'numpy.int64'>\n",
      "NUMOBS_INIT_BRIGHT: -1 : <class 'numpy.int64'>\n",
      "PRIORITY_INIT_BACKUP: -1 : <class 'numpy.int64'>\n",
      "NUMOBS_INIT_BACKUP: -1 : <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res[0])):\n",
    "        print(f'{cols[i][0]}: {res[0][i]} : {type(res[0][i])}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['LRG', 'LRG_SOUTH']\n",
      "['ELG', 'ELG_LOP', 'ELG_SOUTH', 'ELG_LOP_SOUTH']\n",
      "['ELG', 'ELG_LOP', 'ELG_HIP', 'ELG_SOUTH', 'ELG_LOP_SOUTH']\n",
      "['QSO', 'QSO_SOUTH']\n",
      "['ELG', 'ELG_VLO', 'ELG_SOUTH', 'ELG_VLO_SOUTH']\n",
      "['ELG', 'ELG_HIP', 'ELG_VLO', 'ELG_SOUTH', 'ELG_VLO_SOUTH']\n",
      "['ELG', 'QSO', 'ELG_VLO', 'ELG_SOUTH', 'QSO_SOUTH', 'ELG_VLO_SOUTH']\n",
      "['ELG', 'QSO', 'ELG_LOP', 'ELG_HIP', 'ELG_SOUTH', 'QSO_SOUTH', 'ELG_LOP_SOUTH']\n",
      "['ELG', 'QSO', 'ELG_LOP', 'ELG_SOUTH', 'QSO_SOUTH', 'ELG_LOP_SOUTH']\n",
      "['LRG', 'QSO', 'LRG_SOUTH', 'QSO_SOUTH']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from desitarget.targetmask import desi_mask\n",
    "\n",
    "targets = set()\n",
    "for j in range(len(res)):\n",
    "    for i in range(len(res[0])):\n",
    "        #print(f'{cols[i][0]}: {res[0][i]}')\n",
    "\n",
    "\n",
    "        if cols[i][0] == 'DESI_TARGET':\n",
    "            #print(f'{cols[i][0]}: {type(res[j][i])}')\n",
    "\n",
    "            targets.add(res[j][i])\n",
    "\n",
    "\n",
    "print(type(desi_mask.bitname(1)))\n",
    "def desitarget_bitcode_2_str(bitcode) -> str:\n",
    "\n",
    "    bina = (bin(bitcode))\n",
    "    bina = bina[2:]\n",
    "\n",
    "    categories = []\n",
    "\n",
    "    for i, bit in enumerate(reversed(bina)):\n",
    "        if bit == '1':\n",
    "            categories.append(desi_mask.bitname(i))\n",
    "\n",
    "    return categories\n",
    "\n",
    "\n",
    "\n",
    "for object in targets:\n",
    "    print(desitarget_bitcode_2_str(object))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adapt to extract:\n",
    "\n",
    "1. Different columns needed for redshift analysis\n",
    "2. Separate LRG, ELG, QSO and Laymen Break Dropouts\n",
    "3. Parallelise Runs\n",
    "\n",
    "\n",
    "Bits:\n",
    "\n",
    "#- DESI primary survey target bit mask: dark survey + calib +\n",
    "desi_mask:\n",
    "    - [LRG,         0, \"LRG\", {obsconditions: DARK}]\n",
    "    - [ELG,         1, \"ELG\", {obsconditions: DARK}]\n",
    "    - [QSO,         2, \"QSO\", {obsconditions: DARK}]\n",
    "\n",
    "    #- ADM QSO sub-classes. Used in SV but ultimately deprecated for the Main Survey.\n",
    "    - [QSO_HIZ,     4, \"QSO selected using high-redshift Random Forest (informational bit)\", {obsconditions: DARK}]\n",
    "\n",
    "    # ADM ELG sub-classes\n",
    "    - [ELG_LOP,     5, \"ELG at standard (ELG) priority\",                   {obsconditions: DARK}]\n",
    "    - [ELG_HIP,     6, \"ELG randomly increased to higher (LRG) priority\",  {obsconditions: DARK}]\n",
    "    - [ELG_VLO,     7, \"Very-low priority ELG (filler)\",                   {obsconditions: DARK}]\n",
    "\n",
    "    #- North vs. South selections\n",
    "    - [LRG_NORTH,          8, \"LRG cuts tuned for Bok/Mosaic data\",                                        {obsconditions: DARK}]\n",
    "    - [ELG_NORTH,          9, \"ELG cuts tuned for Bok/Mosaic data\",                                        {obsconditions: DARK}]\n",
    "    - [QSO_NORTH,         10, \"QSO cuts tuned for Bok/Mosaic data\",                                        {obsconditions: DARK}]\n",
    "    - [ELG_LOP_NORTH,     11, \"ELG at standard (ELG) priority tuned for Bok/Mosaic data\",                  {obsconditions: DARK}]\n",
    "    - [ELG_VLO_NORTH,     12, \"Very-low priority ELG (filler) tuned for Bok/Mosaic data\",                  {obsconditions: DARK}]\n",
    "\n",
    "    - [LRG_SOUTH,         16, \"LRG cuts tuned for DECam data\",                                             {obsconditions: DARK}]\n",
    "    - [ELG_SOUTH,         17, \"ELG cuts tuned for DECam data\",                                             {obsconditions: DARK}]\n",
    "    - [QSO_SOUTH,         18, \"QSO cuts tuned for DECam data\",                                             {obsconditions: DARK}]\n",
    "    - [ELG_LOP_SOUTH,     19, \"ELG at standard (ELG) priority tuned for DECam data\",                       {obsconditions: DARK}]\n",
    "    - [ELG_VLO_SOUTH,     20, \"Very-low priority ELG (filler) tuned for DECam data\",                       {obsconditions: DARK}]\n",
    "\n",
    "    #- Calibration targets\n",
    "    - [SKY,         32, \"Blank sky locations\",                                       {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n",
    "    - [STD_FAINT,   33, \"Standard stars for dark/gray conditions\",                   {obsconditions: DARK}]\n",
    "    - [STD_WD,      34, \"White Dwarf stars\",                                         {obsconditions: DARK|BRIGHT}]\n",
    "    - [STD_BRIGHT,  35, \"Standard stars for BRIGHT conditions\",                      {obsconditions: BRIGHT}]\n",
    "    - [BAD_SKY,     36, \"Blank sky locations that are imperfect but still useable\",  {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n",
    "    - [SUPP_SKY,    37, \"SKY is based on Gaia-avoidance (SKY will be set, too)\",     {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n",
    "\n",
    "    #- Reserving some bits that we may not use\n",
    "    # - [STD_FAINT_BEST,    38, \"High quality faint standard stars\",                 {obsconditions: DARK}]\n",
    "    # - [STD_BRIGHT_BEST,   39, \"High quality bright standard stars\",                {obsconditions: BRIGHT}]\n",
    "\n",
    "    #- Reserved convenience bits that can, e.g., be set downstream of desitarget\n",
    "    - [NO_TARGET,           49, \"No known target at this location\",                  {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n",
    "\n",
    "    #- Related to bright object masking\n",
    "    - [BRIGHT_OBJECT,       50, \"Known bright object to avoid\",                      {obsconditions: APOCALYPSE}]\n",
    "    - [IN_BRIGHT_OBJECT,    51, \"Too near a bright object; DO NOT OBSERVE\",          {obsconditions: APOCALYPSE}]\n",
    "    - [NEAR_BRIGHT_OBJECT,  52, \"Near a bright object but ok to observe\",            {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n",
    "\n",
    "    #- A bit for another survey is set\n",
    "    - [BGS_ANY,             60, \"Any BGS bit is set\",                                {obsconditions: IGNORE}]\n",
    "    - [MWS_ANY,             61, \"Any MWS bit is set\",                                {obsconditions: IGNORE}]\n",
    "    - [SCND_ANY,            62, \"Any secondary bit is set\",                          {obsconditions: DARK|GRAY|BRIGHT|BACKUP|TWILIGHT12|TWILIGHT18}]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "elg = select_targets(\n",
    "    infiles=filenames, numproc=1, qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames=['ELG'], backup=False\n",
    ")\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 3.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 6.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 8.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 10.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 12.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 13.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 14.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 15.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.3 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  15.47\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "qso = select_targets(\n",
    "    infiles=filenames, numproc=1, qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames=['QSO'], backup=False)\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 5.8 secs/file; 1.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 5.8 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 5.6 secs/file; 5.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 5.6 secs/file; 7.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 5.6 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 5.6 secs/file; 11.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 5.6 secs/file; 13.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 5.6 secs/file; 14.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 5.6 secs/file; 16.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 5.5 secs/file; 18.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 5.5 secs/file; 20.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 5.5 secs/file; 22.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 5.5 secs/file; 23.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 5.5 secs/file; 25.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 5.5 secs/file; 27.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 5.5 secs/file; 29.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 5.5 secs/file; 31.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 5.5 secs/file; 33.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 5.5 secs/file; 35.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 5.5 secs/file; 36.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 5.5 secs/file; 38.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 5.5 secs/file; 40.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 5.5 secs/file; 42.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 5.5 secs/file; 44.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 5.5 secs/file; 45.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 5.5 secs/file; 47.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 5.5 secs/file; 49.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 5.5 secs/file; 50.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 5.4 secs/file; 52.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 5.4 secs/file; 54.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 5.4 secs/file; 56.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 5.4 secs/file; 58.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 5.4 secs/file; 59.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 5.4 secs/file; 61.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 5.4 secs/file; 63.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 5.4 secs/file; 65.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 5.4 secs/file; 67.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 5.4 secs/file; 68.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 5.4 secs/file; 70.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 5.4 secs/file; 72.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 5.4 secs/file; 74.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 5.4 secs/file; 75.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 5.4 secs/file; 77.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 5.4 secs/file; 79.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 5.4 secs/file; 81.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 5.4 secs/file; 82.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 5.4 secs/file; 84.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 5.4 secs/file; 86.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 5.4 secs/file; 88.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 5.4 secs/file; 90.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 5.4 secs/file; 92.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 5.4 secs/file; 93.7 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  94.57\n",
      "Hours taken for:  1050  bricks:  1.58\n",
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 5.1 secs/file; 1.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 5.1 secs/file; 3.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 5.0 secs/file; 5.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 5.0 secs/file; 6.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 5.1 secs/file; 8.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 5.1 secs/file; 10.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 5.0 secs/file; 11.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 5.0 secs/file; 13.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 5.1 secs/file; 15.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 5.0 secs/file; 16.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 5.0 secs/file; 18.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 5.0 secs/file; 20.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 5.0 secs/file; 21.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 5.0 secs/file; 23.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 5.0 secs/file; 25.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 5.1 secs/file; 26.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 5.1 secs/file; 28.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 5.1 secs/file; 30.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 5.1 secs/file; 32.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 5.1 secs/file; 33.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 5.0 secs/file; 35.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 5.0 secs/file; 37.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 5.1 secs/file; 38.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 5.0 secs/file; 40.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 5.0 secs/file; 41.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 5.0 secs/file; 43.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 5.0 secs/file; 45.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 5.0 secs/file; 46.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 5.0 secs/file; 48.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 5.0 secs/file; 49.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 5.0 secs/file; 51.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 5.0 secs/file; 53.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 5.0 secs/file; 54.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 5.0 secs/file; 56.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 5.0 secs/file; 58.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 5.0 secs/file; 59.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 5.0 secs/file; 61.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 5.0 secs/file; 63.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 5.0 secs/file; 64.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 5.0 secs/file; 66.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 5.0 secs/file; 68.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 5.0 secs/file; 69.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 5.0 secs/file; 71.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 5.0 secs/file; 72.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 5.0 secs/file; 74.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 5.0 secs/file; 76.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 5.0 secs/file; 77.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 5.0 secs/file; 79.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 5.0 secs/file; 81.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 5.0 secs/file; 82.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 5.0 secs/file; 84.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 5.0 secs/file; 86.1 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  86.9\n",
      "Hours taken for:  1050  bricks:  1.45\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "qso_rf = select_targets(\n",
    "    infiles=filenames, numproc=1, qso_selection='randomforest', nside=None, gaiasub=False,\n",
    "    tcnames=['QSO'], backup=False)\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cuts.py:2942:select_targets: Running on the main survey\n",
      "INFO:cuts.py:3059:_update_status: 20/1051 files; 0.9 secs/file; 0.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 40/1051 files; 0.9 secs/file; 0.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 60/1051 files; 0.9 secs/file; 0.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 80/1051 files; 0.9 secs/file; 1.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 100/1051 files; 0.9 secs/file; 1.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 120/1051 files; 0.9 secs/file; 1.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 140/1051 files; 0.9 secs/file; 2.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 160/1051 files; 0.9 secs/file; 2.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 180/1051 files; 0.9 secs/file; 2.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 200/1051 files; 0.9 secs/file; 3.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 220/1051 files; 0.9 secs/file; 3.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 240/1051 files; 0.9 secs/file; 3.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 260/1051 files; 0.9 secs/file; 3.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 280/1051 files; 0.9 secs/file; 4.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 300/1051 files; 0.9 secs/file; 4.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 320/1051 files; 0.9 secs/file; 4.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 340/1051 files; 0.9 secs/file; 5.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 360/1051 files; 0.9 secs/file; 5.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 380/1051 files; 0.9 secs/file; 5.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 400/1051 files; 0.9 secs/file; 6.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 420/1051 files; 0.9 secs/file; 6.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 440/1051 files; 0.9 secs/file; 6.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 460/1051 files; 0.9 secs/file; 6.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 480/1051 files; 0.9 secs/file; 7.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 500/1051 files; 0.9 secs/file; 7.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 520/1051 files; 0.9 secs/file; 7.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 540/1051 files; 0.9 secs/file; 8.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 560/1051 files; 0.9 secs/file; 8.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 580/1051 files; 0.9 secs/file; 8.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 600/1051 files; 0.9 secs/file; 8.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 620/1051 files; 0.9 secs/file; 9.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 640/1051 files; 0.9 secs/file; 9.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 660/1051 files; 0.9 secs/file; 9.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 680/1051 files; 0.9 secs/file; 10.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 700/1051 files; 0.9 secs/file; 10.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 720/1051 files; 0.9 secs/file; 10.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 740/1051 files; 0.9 secs/file; 10.8 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 760/1051 files; 0.9 secs/file; 11.1 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 780/1051 files; 0.9 secs/file; 11.5 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 800/1051 files; 0.9 secs/file; 11.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 820/1051 files; 0.9 secs/file; 12.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 840/1051 files; 0.9 secs/file; 12.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 860/1051 files; 0.9 secs/file; 12.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 880/1051 files; 0.9 secs/file; 12.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 900/1051 files; 0.9 secs/file; 13.2 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 920/1051 files; 0.9 secs/file; 13.4 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 940/1051 files; 0.9 secs/file; 13.7 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 960/1051 files; 0.9 secs/file; 14.0 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 980/1051 files; 0.9 secs/file; 14.3 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1000/1051 files; 0.9 secs/file; 14.6 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1020/1051 files; 0.9 secs/file; 14.9 total mins elapsed\n",
      "INFO:cuts.py:3059:_update_status: 1040/1051 files; 0.9 secs/file; 15.2 total mins elapsed\n",
      "Minutes taken for:  1050  bricks:  15.31\n",
      "Hours taken for:  1050  bricks:  0.26\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "res = select_targets(\n",
    "    infiles=filenames, numproc=1, qso_selection='colorcuts', nside=None, gaiasub=False,\n",
    "    tcnames=['LRG', 'ELG', 'QSO'], backup=False)\n",
    "\n",
    "print(\"Minutes taken for: \", i, \" bricks: \", round(((time.time() - start) / 60), 2))\n",
    "print(\"Hours taken for: \", i, \" bricks: \", round(((time.time() - start) / 3600), 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 40569\n",
      "ELG: 152287\n"
     ]
    }
   ],
   "source": [
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211869\n",
      "LRG: 40569\n",
      "ELG: 152287\n",
      "QSO: 19013\n",
      "QSO_RF: 19907\n",
      "All: 206874\n"
     ]
    }
   ],
   "source": [
    "print(len(lrg) + len(elg) + len(qso))\n",
    "\n",
    "print(\"LRG:\", len(lrg))\n",
    "print(\"ELG:\", len(elg))\n",
    "print(\"QSO:\", len(qso))\n",
    "print(\"QSO_RF:\", len(qso_rf))\n",
    "print(\"All:\", len(res))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(f'../../bricks_data/tractor/'):\n",
    "if '.fits' not in filename:\n",
    "    continue\n",
    "filenames.append(f'/Volumes/{device}/bricks_data/{area}/{filename}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Work on Adapting the DesiTarget Pipeline to return different types of objects: --> not creating fork for lack of wifi:\n",
    "Logic of Select_Targets:\n",
    "1. Check whether bounded box is passed and sanitise inputs\n",
    "2. for x in infiles:\n",
    "    A. targets.append(_update_status(_select_targets_file(x)))\n",
    "    2. targets = np.concatenate(targets)\n",
    "    3. For file, process targets in file, print results, concat all target arrays\n",
    "\n",
    "3. Remove gaiacuts\n",
    "\n",
    "\n",
    "Changes:\n",
    "- Process returned array to extract relevant information\n",
    "- Distinguish between different types of galaxies\n",
    "- Introduce Lyman Beak Galaxies\n",
    "-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}