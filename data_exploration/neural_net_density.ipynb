{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First attempt at building a Neural Network to learn a non-linear F(s)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.metrics\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268046 entries, 0 to 268045\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   lrg_density        268046 non-null  float64\n",
      " 1   elg_density        268046 non-null  float64\n",
      " 2   qso_density        268046 non-null  float64\n",
      " 3   stellar_density    268046 non-null  float64\n",
      " 4   airmass_galaxy     268046 non-null  float64\n",
      " 5   fwhm_galaxy        268046 non-null  float64\n",
      " 6   ebv_galaxy         268046 non-null  float64\n",
      " 7   ccdnphotom_galaxy  268046 non-null  float64\n",
      " 8   ccdskysb_galaxy_g  268046 non-null  float64\n",
      " 9   ccdskysb_galaxy_r  268046 non-null  float64\n",
      " 10  ccdskysb_galaxy_z  268046 non-null  float64\n",
      " 11  exptime_galaxy_g   268046 non-null  float64\n",
      " 12  exptime_galaxy_r   268046 non-null  float64\n",
      " 13  exptime_galaxy_z   268046 non-null  float64\n",
      " 14  meansky_galaxy_g   268046 non-null  float64\n",
      " 15  meansky_galaxy_r   268046 non-null  float64\n",
      " 16  meansky_galaxy_z   268046 non-null  float64\n",
      " 17  galdepth_galaxy_g  268046 non-null  float64\n",
      " 18  galdepth_galaxy_r  268046 non-null  float64\n",
      " 19  galdepth_galaxy_z  268046 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 40.9 MB\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Data\n",
    "df = pd.read_csv('../bricks_data/dataset_geometric.csv')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining The Dataset Class Inheriting from Torch.dataset to be able to use a dataloader for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class DensitySurvey(Dataset):\n",
    "    def __init__(self, df, galaxy_type):\n",
    "        self.data = df#[0:1000]\n",
    "        # Extracting Targets and Input\n",
    "        if galaxy_type == \"LRG\":\n",
    "            self.target = self.data['lrg_density'].to_numpy(copy=True)\n",
    "        if galaxy_type == \"ELG\":\n",
    "            self.target = self.data['elg_density'].to_numpy(copy=True)\n",
    "        if galaxy_type == \"QSO\":\n",
    "            self.target = self.data['qso_density'].to_numpy(copy=True)\n",
    "        self.input = self.data.drop(columns=['lrg_density','elg_density','qso_density']).to_numpy(copy=True)\n",
    "\n",
    "        # Scaling\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        self.input = scaler.fit_transform(self.input)\n",
    "        self.target = scaler.fit_transform(self.target.reshape(-1, 1))\n",
    "        print(self.input.shape)\n",
    "        print(self.target.shape)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.input[idx]).float(), torch.tensor(self.target[idx]).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179590, 17)\n",
      "(179590, 1)\n",
      "(88456, 17)\n",
      "(88456, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../bricks_data/dataset_geometric.csv')\n",
    "train_df, test_df = train_test_split(df, test_size=0.33, random_state=44, shuffle=True)\n",
    "traindata = DensitySurvey(train_df, 'LRG')\n",
    "testdata = DensitySurvey(test_df, 'LRG')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179590\n",
      "88456\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(traindata.__len__())\n",
    "print(testdata.__len__())\n",
    "\n",
    "x,y = traindata.__getitem__(3)\n",
    "\n",
    "print(x.dtype, y.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model and Hyperparameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature = 17, n_hidden = 10, n_output = 1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature,n_hidden)\n",
    "        #self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.predict(out)\n",
    "        return out\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "model = Net().to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 500 #very low, but computational power not sufficient for more iterations\n",
    "batch = 1024\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Epoch 0 :  0.8100595716387033\n",
      "Loss for Epoch 10 :  0.07056161339278333\n",
      "Loss for Epoch 20 :  0.06039096834138036\n",
      "Loss for Epoch 30 :  0.05801052146125585\n",
      "Loss for Epoch 40 :  0.05740677454741672\n",
      "Loss for Epoch 50 :  0.057137125622830354\n",
      "Loss for Epoch 60 :  0.056651875740499236\n",
      "Loss for Epoch 70 :  0.0563907187897712\n",
      "Loss for Epoch 80 :  0.05639348727709148\n",
      "Loss for Epoch 90 :  0.05624635229469277\n",
      "Loss for Epoch 100 :  0.055991054730839096\n",
      "Loss for Epoch 110 :  0.055804325587814674\n",
      "Loss for Epoch 120 :  0.055838042666437104\n",
      "Loss for Epoch 130 :  0.05575022878474556\n",
      "Loss for Epoch 140 :  0.055506179080111906\n",
      "Loss for Epoch 150 :  0.055427626764867455\n",
      "Loss for Epoch 160 :  0.05517887548194267\n",
      "Loss for Epoch 170 :  0.05539186035457533\n",
      "Loss for Epoch 180 :  0.05497705929155927\n",
      "Loss for Epoch 190 :  0.05512102137436159\n",
      "Loss for Epoch 200 :  0.055056203171261586\n",
      "Loss for Epoch 210 :  0.05486024085257668\n",
      "Loss for Epoch 220 :  0.054864193734829314\n",
      "Loss for Epoch 230 :  0.05484406650066376\n",
      "Loss for Epoch 240 :  0.05464098619995639\n",
      "Loss for Epoch 250 :  0.054608279606327415\n",
      "Loss for Epoch 260 :  0.05391103573492728\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    loss_per_epoch = 0\n",
    "\n",
    "    #loading the training data from trainset and shuffling for each epoch\n",
    "    trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "    for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "        #Put Model into train mode\n",
    "        model.train()\n",
    "\n",
    "        #Extract inputs and associated labels from dataloader batch\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        #Predict outputs (forward pass)\n",
    "        predictions =  model(inputs)\n",
    "\n",
    "        #Compute Loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        #Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        #Perform one step of gradient descent\n",
    "        optimiser.step()\n",
    "\n",
    "        #Append loss to the general loss for this one epoch\n",
    "        loss_per_epoch += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "time_end = time.time()\n",
    "time_passed = time_end - time_start\n",
    "print()\n",
    "print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = np.array([])\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=batch, shuffle=False)\n",
    "\n",
    "\n",
    "for batch_no in testloader:\n",
    "\n",
    "    #Split dataloader\n",
    "    inputs = batch_no[0].to(device)\n",
    "    labels = batch_no[1].to(device)\n",
    "\n",
    "    #Forward pass through the trained network\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    #Get predictions and append to label array + count number of correct and total\n",
    "    y_pred = np.append(y_pred, outputs.numpy())\n",
    "\n",
    "y_gold = testdata.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.r2_score(y_gold, y_pred))\n",
    "print(metrics.mean_squared_error(y_gold, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}