{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First attempt at building a Neural Network to learn a non-linear F(s)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268046 entries, 0 to 268045\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   lrg_density        268046 non-null  float64\n",
      " 1   elg_density        268046 non-null  float64\n",
      " 2   qso_density        268046 non-null  float64\n",
      " 3   stellar_density    268046 non-null  float64\n",
      " 4   airmass_galaxy     268046 non-null  float64\n",
      " 5   fwhm_galaxy        268046 non-null  float64\n",
      " 6   ebv_galaxy         268046 non-null  float64\n",
      " 7   ccdnphotom_galaxy  268046 non-null  float64\n",
      " 8   ccdskysb_galaxy_g  268046 non-null  float64\n",
      " 9   ccdskysb_galaxy_r  268046 non-null  float64\n",
      " 10  ccdskysb_galaxy_z  268046 non-null  float64\n",
      " 11  exptime_galaxy_g   268046 non-null  float64\n",
      " 12  exptime_galaxy_r   268046 non-null  float64\n",
      " 13  exptime_galaxy_z   268046 non-null  float64\n",
      " 14  meansky_galaxy_g   268046 non-null  float64\n",
      " 15  meansky_galaxy_r   268046 non-null  float64\n",
      " 16  meansky_galaxy_z   268046 non-null  float64\n",
      " 17  galdepth_galaxy_g  268046 non-null  float64\n",
      " 18  galdepth_galaxy_r  268046 non-null  float64\n",
      " 19  galdepth_galaxy_z  268046 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 40.9 MB\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Data\n",
    "df = pd.read_csv('../bricks_data/dataset_geometric.csv')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining The Dataset Class Inheriting from Torch.dataset to be able to use a dataloader for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "class DensitySurvey(Dataset):\n",
    "    def __init__(self, df, galaxy_type):\n",
    "        self.data = df[0:1000]\n",
    "        # Extracting Targets and Input\n",
    "        if galaxy_type == \"LRG\":\n",
    "            self.target = self.data['lrg_density'].to_numpy(copy=True)\n",
    "        if galaxy_type == \"ELG\":\n",
    "            self.target = self.data['elg_density'].to_numpy(copy=True)\n",
    "        if galaxy_type == \"QSO\":\n",
    "            self.target = self.data['qso_density'].to_numpy(copy=True)\n",
    "        self.input = self.data.drop(columns=['lrg_density','elg_density','qso_density']).to_numpy(copy=True)\n",
    "\n",
    "        # Scaling\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        self.input = scaler.fit_transform(self.input)\n",
    "        self.target = scaler.fit_transform(self.target.reshape(-1, 1))\n",
    "        print(self.input.shape)\n",
    "        print(self.target.shape)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.input[idx]).float(), torch.tensor(self.target[idx]).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17)\n",
      "(1000, 1)\n",
      "(1000, 17)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../bricks_data/dataset_geometric.csv')\n",
    "train_df, test_df = train_test_split(df, test_size=0.33, random_state=44, shuffle=True)\n",
    "traindata = DensitySurvey(train_df, 'LRG')\n",
    "testdata = DensitySurvey(test_df, 'LRG')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(traindata.__len__())\n",
    "print(testdata.__len__())\n",
    "\n",
    "x,y = traindata.__getitem__(3)\n",
    "\n",
    "print(x.dtype, y.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model and Hyperparameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature = 17, n_hidden = 10, n_output = 1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature,n_hidden)\n",
    "        #self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.predict(out)\n",
    "        return out\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "model = Net().to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Defining Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Defining Hyperparemeters\n",
    "no_epochs = 500 #very low, but computational power not sufficient for more iterations\n",
    "batch = 1024\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Using the Adam Method for Stochastic Optimisation\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Epoch 0 :  0.06564584374427795\n",
      "Loss for Epoch 10 :  0.02809840440750122\n",
      "Loss for Epoch 20 :  0.011636683717370033\n",
      "Loss for Epoch 30 :  0.00951817724853754\n",
      "Loss for Epoch 40 :  0.009426706470549107\n",
      "Loss for Epoch 50 :  0.008790063671767712\n",
      "Loss for Epoch 60 :  0.008521865122020245\n",
      "Loss for Epoch 70 :  0.008186805993318558\n",
      "Loss for Epoch 80 :  0.007976675406098366\n",
      "Loss for Epoch 90 :  0.007786992471665144\n",
      "Loss for Epoch 100 :  0.0076213921420276165\n",
      "Loss for Epoch 110 :  0.007462238427251577\n",
      "Loss for Epoch 120 :  0.0073154340498149395\n",
      "Loss for Epoch 130 :  0.007178941275924444\n",
      "Loss for Epoch 140 :  0.007050578016787767\n",
      "Loss for Epoch 150 :  0.006928657181560993\n",
      "Loss for Epoch 160 :  0.006811904720962048\n",
      "Loss for Epoch 170 :  0.006700402125716209\n",
      "Loss for Epoch 180 :  0.006594594102352858\n",
      "Loss for Epoch 190 :  0.00649344502016902\n",
      "Loss for Epoch 200 :  0.006397258955985308\n",
      "Loss for Epoch 210 :  0.006305833347141743\n",
      "Loss for Epoch 220 :  0.006218860857188702\n",
      "Loss for Epoch 230 :  0.006137189455330372\n",
      "Loss for Epoch 240 :  0.006060055922716856\n",
      "Loss for Epoch 250 :  0.005987120326608419\n",
      "Loss for Epoch 260 :  0.005918626673519611\n",
      "Loss for Epoch 270 :  0.005854052025824785\n",
      "Loss for Epoch 280 :  0.005792427342385054\n",
      "Loss for Epoch 290 :  0.0057340357452631\n",
      "Loss for Epoch 300 :  0.0056786141358315945\n",
      "Loss for Epoch 310 :  0.0056260633282363415\n",
      "Loss for Epoch 320 :  0.005576394032686949\n",
      "Loss for Epoch 330 :  0.005529424175620079\n",
      "Loss for Epoch 340 :  0.005484828259795904\n",
      "Loss for Epoch 350 :  0.005442394874989986\n",
      "Loss for Epoch 360 :  0.0054016076028347015\n",
      "Loss for Epoch 370 :  0.005363408010452986\n",
      "Loss for Epoch 380 :  0.005327458027750254\n",
      "Loss for Epoch 390 :  0.005293451715260744\n",
      "Loss for Epoch 400 :  0.005261349491775036\n",
      "Loss for Epoch 410 :  0.005231039598584175\n",
      "Loss for Epoch 420 :  0.005202359985560179\n",
      "Loss for Epoch 430 :  0.005175376310944557\n",
      "Loss for Epoch 440 :  0.005148442927747965\n",
      "Loss for Epoch 450 :  0.005119383800774813\n",
      "Loss for Epoch 460 :  0.005091254599392414\n",
      "Loss for Epoch 470 :  0.005065897945314646\n",
      "Loss for Epoch 480 :  0.005044653080403805\n",
      "Loss for Epoch 490 :  0.00502478564158082\n",
      "\n",
      "0.13087 minutes (7.85 seconds) taken to train the model\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    loss_per_epoch = 0\n",
    "\n",
    "    #loading the training data from trainset and shuffling for each epoch\n",
    "    trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch, shuffle = True)\n",
    "\n",
    "    for i, batch_no in enumerate(trainloader, 0):\n",
    "\n",
    "        #Put Model into train mode\n",
    "        model.train()\n",
    "\n",
    "        #Extract inputs and associated labels from dataloader batch\n",
    "        inputs = batch_no[0].to(device)\n",
    "        labels = batch_no[1].to(device)\n",
    "\n",
    "        #Zero-out the gradients before backward pass (pytorch stores the gradients)\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        #Predict outputs (forward pass)\n",
    "        predictions =  model(inputs)\n",
    "\n",
    "        #Compute Loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        #Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        #Perform one step of gradient descent\n",
    "        optimiser.step()\n",
    "\n",
    "        #Append loss to the general loss for this one epoch\n",
    "        loss_per_epoch += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Loss for Epoch\", epoch, \": \", loss_per_epoch)\n",
    "\n",
    "time_end = time.time()\n",
    "time_passed = time_end - time_start\n",
    "print()\n",
    "print(f\"{time_passed/60:.5} minutes ({time_passed:.3} seconds) taken to train the model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}